{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S9VpKXBnCHVe",
        "6FEfJVaxNc3J",
        "qlMCFKFbN6rN",
        "zG_XEdMEgpAZ",
        "vWYwg4BVvBBK"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "613c6c806daf46319d1e602da47b30fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c57941002394b38b42ed09d9665dc8b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_83ac602760ff4ddc91f10e837ac4f8cb",
              "IPY_MODEL_3d18f5061089470aa44ed39fba0f4331"
            ]
          }
        },
        "3c57941002394b38b42ed09d9665dc8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83ac602760ff4ddc91f10e837ac4f8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_defd1856a09241d193ac24d3c5ed9a5b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbe3b124e7fd4a21947678be2d74be88"
          }
        },
        "3d18f5061089470aa44ed39fba0f4331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92ca26ce609740aeb460eff00179b97e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:20&lt;00:00, 54.53it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57aed8b86d5f466b8a3fe3ecb663c875"
          }
        },
        "defd1856a09241d193ac24d3c5ed9a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbe3b124e7fd4a21947678be2d74be88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92ca26ce609740aeb460eff00179b97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57aed8b86d5f466b8a3fe3ecb663c875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71ddf4d9012942d98bced49225cc7d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4b52d2ea9fb24dd1ac1a8767dd93a95a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b037f766ba44f418c5f4c0d269e3237",
              "IPY_MODEL_10eb283847cd4aed86f71aced67c816c"
            ]
          }
        },
        "4b52d2ea9fb24dd1ac1a8767dd93a95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b037f766ba44f418c5f4c0d269e3237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_935a09d4bdba4a7b81970e07b8734fe3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67608dc2caa54df5bc732b9d6771e2e2"
          }
        },
        "10eb283847cd4aed86f71aced67c816c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9b55b1f29dc4fc4b11580015d267728",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:09&lt;00:00, 59.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e030dbc357794b61bb4a66687cede582"
          }
        },
        "935a09d4bdba4a7b81970e07b8734fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67608dc2caa54df5bc732b9d6771e2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9b55b1f29dc4fc4b11580015d267728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e030dbc357794b61bb4a66687cede582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63ba42eae1644f39b9ed4a79af995bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_feecb300e7e74f81b1073a619d101329",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec61ff17f4a34ff3b47394d2cc3abf80",
              "IPY_MODEL_ad2bb51d8b3848d2a12a9c0e3a023e88"
            ]
          }
        },
        "feecb300e7e74f81b1073a619d101329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec61ff17f4a34ff3b47394d2cc3abf80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_058c74b86a6440ac87739e5fca3cc240",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7650415994b4ee8a115a368d01faa77"
          }
        },
        "ad2bb51d8b3848d2a12a9c0e3a023e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d778e72c2274afebf820d827db2fe59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:08&lt;00:00, 59.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07668001abac4ca5a3387ffb7bebca98"
          }
        },
        "058c74b86a6440ac87739e5fca3cc240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7650415994b4ee8a115a368d01faa77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d778e72c2274afebf820d827db2fe59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07668001abac4ca5a3387ffb7bebca98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a54515ac1299487cbdfa8e7be31df5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6feaea78e8945838ddc1867f4240ae5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_edd91820e5754ddc8da842e90d8521d7",
              "IPY_MODEL_f41528a9fefd482492fba6f6c4a8fa6f"
            ]
          }
        },
        "d6feaea78e8945838ddc1867f4240ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edd91820e5754ddc8da842e90d8521d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b4f86be822445d28dec93dc7156171b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a4e6ea6761d407f98bac65ae4d5c117"
          }
        },
        "f41528a9fefd482492fba6f6c4a8fa6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c144550f8b74c629c8f01fa0d06fc7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:28&lt;00:00, 51.54it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9434fe9f5a4d4a5fb03b9627fe20a898"
          }
        },
        "0b4f86be822445d28dec93dc7156171b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a4e6ea6761d407f98bac65ae4d5c117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c144550f8b74c629c8f01fa0d06fc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9434fe9f5a4d4a5fb03b9627fe20a898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dfaa7106a81463cb573b0203f7a100a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_322d0b9f9dce49459b64fb9be273e980",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6759e5fbf7e94190bbba7f8fdc9293ef",
              "IPY_MODEL_ca0371bc4dfc4b758b0fd58b0ef65ea8"
            ]
          }
        },
        "322d0b9f9dce49459b64fb9be273e980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6759e5fbf7e94190bbba7f8fdc9293ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_423474da0f0f4faebdc5a21495d30887",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a082e8dab62403b990a23f1291b03de"
          }
        },
        "ca0371bc4dfc4b758b0fd58b0ef65ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18d5a6f36921467caf14320531d5dc24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:09&lt;00:00, 59.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e36d9c63516f4ae88268e8a82f38ba81"
          }
        },
        "423474da0f0f4faebdc5a21495d30887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a082e8dab62403b990a23f1291b03de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18d5a6f36921467caf14320531d5dc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e36d9c63516f4ae88268e8a82f38ba81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3814d5a79a204e91bb1f6eef44c9127c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_836d534ab9dd41e1a49464c78ebc246b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58be044fa8a44fd5937d68c527f330e6",
              "IPY_MODEL_1f74e8ccf7614eeab175d22974a73826"
            ]
          }
        },
        "836d534ab9dd41e1a49464c78ebc246b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58be044fa8a44fd5937d68c527f330e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f26049eda0434f3495dc7d8de40a02f1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70bbc3b9b5ab429aa9f647cc48d1a21b"
          }
        },
        "1f74e8ccf7614eeab175d22974a73826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94611d5444cc43caab867e4636d4904c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [04:46&lt;00:00, 26.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92a1deeda5414e0ea51d4f7b524f55b8"
          }
        },
        "f26049eda0434f3495dc7d8de40a02f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70bbc3b9b5ab429aa9f647cc48d1a21b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94611d5444cc43caab867e4636d4904c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92a1deeda5414e0ea51d4f7b524f55b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c79b251b6a9943ff813f76614dedf009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_62aff14e81d040d88b8e8ed87c290b6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ab590a13a3d42efa7df5133fdf3c925",
              "IPY_MODEL_a139164f62684b9f88cfe7d92ea68118"
            ]
          }
        },
        "62aff14e81d040d88b8e8ed87c290b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ab590a13a3d42efa7df5133fdf3c925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d185b4b587f84b41b7508937179a3ee8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e308fc7c1f3b4608be7c454b3c50dcc3"
          }
        },
        "a139164f62684b9f88cfe7d92ea68118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db9b43a3dd0f4df5aac5b28006c41622",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:32&lt;00:00, 50.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c95f1e470e8431aabfb51c499d659f1"
          }
        },
        "d185b4b587f84b41b7508937179a3ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e308fc7c1f3b4608be7c454b3c50dcc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db9b43a3dd0f4df5aac5b28006c41622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c95f1e470e8431aabfb51c499d659f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e68c8f4583974059bfd2caab5c122087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3e33a8ce22bc43fda1044e39da1cc1ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f187c9a99f74dd5b35b38c54ac27b99",
              "IPY_MODEL_e25fe10433e34cdebcafbcdea8ac7847"
            ]
          }
        },
        "3e33a8ce22bc43fda1044e39da1cc1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f187c9a99f74dd5b35b38c54ac27b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e73ecf83e0bf4aa0a0fb78a79980fc91",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51cdae16da2649ca84667adbb71dbd91"
          }
        },
        "e25fe10433e34cdebcafbcdea8ac7847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6932d62bca9c439bbe2f09ba5b8ce6f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:23&lt;00:00, 53.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e634524740ab402d8634d6e0776a1954"
          }
        },
        "e73ecf83e0bf4aa0a0fb78a79980fc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51cdae16da2649ca84667adbb71dbd91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6932d62bca9c439bbe2f09ba5b8ce6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e634524740ab402d8634d6e0776a1954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "674686b1eb624b46ab87783fe263afaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44dfbf7592a94b7d9e70b1b91a60d2e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e3025872ddde45bdb0f96b1df0b11c9b",
              "IPY_MODEL_b9e833f275ca43ab9aa97a3bfd3c4df0"
            ]
          }
        },
        "44dfbf7592a94b7d9e70b1b91a60d2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3025872ddde45bdb0f96b1df0b11c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fda51ff6eb6b4d63b4b8c8fc58211228",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2a35cda03654af3b8af9abe65b5fd03"
          }
        },
        "b9e833f275ca43ab9aa97a3bfd3c4df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b331b9e574045d5a2b9f9e510d5fce8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [01:24&lt;00:00, 90.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7b42c9cdc5e43a0991a1dd69536eb79"
          }
        },
        "fda51ff6eb6b4d63b4b8c8fc58211228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2a35cda03654af3b8af9abe65b5fd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b331b9e574045d5a2b9f9e510d5fce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7b42c9cdc5e43a0991a1dd69536eb79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e159abbd0ed4cee8eb05151c95f8460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_76ace7e2de4944ca9ae1db8af516616e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c239732924346baaf0e0eae26f76636",
              "IPY_MODEL_569dd0283197484e88a5b2e2f0c3586a"
            ]
          }
        },
        "76ace7e2de4944ca9ae1db8af516616e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c239732924346baaf0e0eae26f76636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c49fe9ab2714b0e997d846438aaa93a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76fff07eab4b491daf0327eafe6b0165"
          }
        },
        "569dd0283197484e88a5b2e2f0c3586a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e818bf45330847919931bfee9a12f9c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [04:03&lt;00:00, 31.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fff937f7af3a43dc8b659683b0ea7ece"
          }
        },
        "5c49fe9ab2714b0e997d846438aaa93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76fff07eab4b491daf0327eafe6b0165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e818bf45330847919931bfee9a12f9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fff937f7af3a43dc8b659683b0ea7ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "991b018c9f3f43f397cc0fa8830c539d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a280a20b174c42d29c1c397ad995351e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d00d6b65b52b4863b2e52925cc71cab4",
              "IPY_MODEL_d85c0ae9c4f949108d9febfc6cf805d9"
            ]
          }
        },
        "a280a20b174c42d29c1c397ad995351e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d00d6b65b52b4863b2e52925cc71cab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2566157c49e2494fab6cbb610f1544e5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5253e59126d1435e98cd5ec70216fc60"
          }
        },
        "d85c0ae9c4f949108d9febfc6cf805d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50e37b338e94425588624f8ef1a55661",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [04:32&lt;00:00, 28.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_353ec56bd03f4193a6fee30ea7ce4623"
          }
        },
        "2566157c49e2494fab6cbb610f1544e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5253e59126d1435e98cd5ec70216fc60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50e37b338e94425588624f8ef1a55661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "353ec56bd03f4193a6fee30ea7ce4623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ac70212f7f44486a74fc1f372e66447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8a80cb4c336492f8ab12f0f18fd4ec5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f1d7f6911b84763b51fecf916efa92c",
              "IPY_MODEL_98bdba9f1e3b402f9b507f8be2d98e73"
            ]
          }
        },
        "c8a80cb4c336492f8ab12f0f18fd4ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f1d7f6911b84763b51fecf916efa92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95527021bdb742448084c4b693806ef0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb91f480bbcc4bf69989beaccdec8730"
          }
        },
        "98bdba9f1e3b402f9b507f8be2d98e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7215d2356e7e4936aae2cfd1acab1e4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:19&lt;00:00, 55.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e699e8b42b6b45aab24b0083e1e56c83"
          }
        },
        "95527021bdb742448084c4b693806ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb91f480bbcc4bf69989beaccdec8730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7215d2356e7e4936aae2cfd1acab1e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e699e8b42b6b45aab24b0083e1e56c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "156748ac21c34d4f90d4a99588fb155f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3bcd33f9747e4de79ce36fc3159f0b2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_156e6f68ca804eb6ad3f45e5d6217413",
              "IPY_MODEL_dcae2102735947a8b8f35b80bb11d362"
            ]
          }
        },
        "3bcd33f9747e4de79ce36fc3159f0b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "156e6f68ca804eb6ad3f45e5d6217413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_06df8274cd8e442b8c08efb17a54605f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ae6dabed9ff44ed839f2f3f291834b1"
          }
        },
        "dcae2102735947a8b8f35b80bb11d362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc69878798344780b6b60ff677d2ce2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:31&lt;00:00, 50.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b423e1b551a462ab1f44ee74abccdbd"
          }
        },
        "06df8274cd8e442b8c08efb17a54605f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ae6dabed9ff44ed839f2f3f291834b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc69878798344780b6b60ff677d2ce2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b423e1b551a462ab1f44ee74abccdbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23310760df854e5eaddad6e0ea6313e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42b955e6abd8412dbf39909f1f6a7be8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d86f982e5be14c6aac7b18cf831a7ccb",
              "IPY_MODEL_78d2003f7c3f4a46a360713231793e4b"
            ]
          }
        },
        "42b955e6abd8412dbf39909f1f6a7be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d86f982e5be14c6aac7b18cf831a7ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ad3df69308b4011a89fec3241cc2ef3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdf4f943ba484db69a84bf8857bfca96"
          }
        },
        "78d2003f7c3f4a46a360713231793e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0c8071ba266483abd013741364d119d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:55&lt;00:00, 43.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a731b99cb57424b98df259815687fe3"
          }
        },
        "6ad3df69308b4011a89fec3241cc2ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdf4f943ba484db69a84bf8857bfca96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0c8071ba266483abd013741364d119d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a731b99cb57424b98df259815687fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fe2785d14a943caa9841f36ff2e3b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f0c6a391b42048dfb8fc33bbf5931a93",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a1b06c7970043d5b21edeb340c08c68",
              "IPY_MODEL_c149c874623842c28b513a6b3bbd3372"
            ]
          }
        },
        "f0c6a391b42048dfb8fc33bbf5931a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a1b06c7970043d5b21edeb340c08c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_945327b64c3d4099afc6d749fbcbd506",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0d400e9e9b842db8087a08654b48026"
          }
        },
        "c149c874623842c28b513a6b3bbd3372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_674dfbe7b4f34bdea267ffcb132dc448",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [02:32&lt;00:00, 50.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fcecd77349a4f2685c2aaaa9438fa17"
          }
        },
        "945327b64c3d4099afc6d749fbcbd506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0d400e9e9b842db8087a08654b48026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "674dfbe7b4f34bdea267ffcb132dc448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fcecd77349a4f2685c2aaaa9438fa17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "295bf42a22474fc6bba8d648ffc6b418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce62385ebe1a4a67bb25f92c84868205",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d6c7732c5b404f1ca18383aa7292778c",
              "IPY_MODEL_27f464b82ccc400bb05379d276ebe00f"
            ]
          }
        },
        "ce62385ebe1a4a67bb25f92c84868205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6c7732c5b404f1ca18383aa7292778c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b48bbdfbbff1499580fbfcae47f0ec52",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57389ac1c2ee4d2b939e97636c737df9"
          }
        },
        "27f464b82ccc400bb05379d276ebe00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a5e969d0758b4b99bf267c8b43026189",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [04:06&lt;00:00, 31.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d568660c8fe9403fb0d66c0e26553de1"
          }
        },
        "b48bbdfbbff1499580fbfcae47f0ec52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57389ac1c2ee4d2b939e97636c737df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5e969d0758b4b99bf267c8b43026189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d568660c8fe9403fb0d66c0e26553de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb755f25cc8d4d418252fa01861a7379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f11ffdeabdc24b288ca9d91e064c8aa2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56d7cb9cb8114223bec9801a4a43d0da",
              "IPY_MODEL_c75335563c074307947522ea6ad1a2f3"
            ]
          }
        },
        "f11ffdeabdc24b288ca9d91e064c8aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56d7cb9cb8114223bec9801a4a43d0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a695bd6f189d45e993cf50ab07d22f39",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b6f4ae9c85448f5926fd3871e4ae7bc"
          }
        },
        "c75335563c074307947522ea6ad1a2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1bd9e17519cd49358fdffb2eb9d6c2b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7662/7662 [04:33&lt;00:00, 28.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23f309d1551e48e1abbb0fe3d8a35948"
          }
        },
        "a695bd6f189d45e993cf50ab07d22f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b6f4ae9c85448f5926fd3871e4ae7bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bd9e17519cd49358fdffb2eb9d6c2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23f309d1551e48e1abbb0fe3d8a35948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86fe5c073bd94e739d74cdc44382e94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_28eae147cc7448d0b8aa7efe2507f02c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7656a3453ab64648b090891f0b9f2bf6",
              "IPY_MODEL_2537e877664b442ba8efd12ab563de14"
            ]
          }
        },
        "28eae147cc7448d0b8aa7efe2507f02c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7656a3453ab64648b090891f0b9f2bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_be306d3793b9405eaede74f429917303",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 917,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 917,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdb0ab4e68f54ba9a4284e630329b3cd"
          }
        },
        "2537e877664b442ba8efd12ab563de14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5db9a0d3d5ff46a995aa7eb0bd58cabf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 917/917 [00:17&lt;00:00, 51.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_edf99566d90347cbb8788c37b59b7d38"
          }
        },
        "be306d3793b9405eaede74f429917303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdb0ab4e68f54ba9a4284e630329b3cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5db9a0d3d5ff46a995aa7eb0bd58cabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "edf99566d90347cbb8788c37b59b7d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "842d1b06f7624464954203fb630a4a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8e30f6cc3f64281bce9ea3974cce84a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07ae6c76eafa4077846b4544d26fff52",
              "IPY_MODEL_8f96c02a3d6a45ebb38f0e39f2d8ac7d"
            ]
          }
        },
        "d8e30f6cc3f64281bce9ea3974cce84a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07ae6c76eafa4077846b4544d26fff52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2f3ad6020c548628679f5acbba8d61d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 917,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 917,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8ba1198e5554ebdabed33770781887a"
          }
        },
        "8f96c02a3d6a45ebb38f0e39f2d8ac7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57102e5731f84ec0bc6dde49ab52d3f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 917/917 [00:15&lt;00:00, 58.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3696d9cf629f4282a327690017398ad6"
          }
        },
        "c2f3ad6020c548628679f5acbba8d61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8ba1198e5554ebdabed33770781887a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57102e5731f84ec0bc6dde49ab52d3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3696d9cf629f4282a327690017398ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "765c5d6055034d3cab4189b56ac7d5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1aa81f13d954cbaa19cd3c17aba3944",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_888cd25d91944426a94532028fc01ffb",
              "IPY_MODEL_f2e69c390fb4447abe4205d9124f9df5"
            ]
          }
        },
        "b1aa81f13d954cbaa19cd3c17aba3944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "888cd25d91944426a94532028fc01ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c860045fba844d0abd86ff315c95a05",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 917,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 917,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5280c650801348eeaedbbeec0d892a6a"
          }
        },
        "f2e69c390fb4447abe4205d9124f9df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ed63131aa9c24536b29c996d21eb16fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 917/917 [00:15&lt;00:00, 60.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df58851b69964172ad8f238fa0cfed63"
          }
        },
        "9c860045fba844d0abd86ff315c95a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5280c650801348eeaedbbeec0d892a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed63131aa9c24536b29c996d21eb16fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df58851b69964172ad8f238fa0cfed63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1432f432ec3457fadf897239d40024a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85a06207a10d4c2cbf2c220d27eba1b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_170964149ff74a2f851c54ec63a3a513",
              "IPY_MODEL_71cee4a5a7bf45a08e7b0f39731a48e2"
            ]
          }
        },
        "85a06207a10d4c2cbf2c220d27eba1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "170964149ff74a2f851c54ec63a3a513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4fd389de63ec47669edea3d0a9234896",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 917,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 917,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_177f0b91a1334a70984153e9c3bd49c9"
          }
        },
        "71cee4a5a7bf45a08e7b0f39731a48e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df0bc0f166a84d48a26bb98f706e647a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 917/917 [00:17&lt;00:00, 53.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_936f54d27cea4f92baf288ba18ee7eba"
          }
        },
        "4fd389de63ec47669edea3d0a9234896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "177f0b91a1334a70984153e9c3bd49c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df0bc0f166a84d48a26bb98f706e647a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "936f54d27cea4f92baf288ba18ee7eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f459ff3fa2f4a35a20b1476154bbf85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32995de1bfa14a0cbf3f17b5811b8a6a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a6f2b4efc1444df380e3a269e12e9256",
              "IPY_MODEL_b9173054f4c346d399a0a79be9c61add"
            ]
          }
        },
        "32995de1bfa14a0cbf3f17b5811b8a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6f2b4efc1444df380e3a269e12e9256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ccd2ad864a0e4e019963cc96b82cd567",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 917,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 917,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e03a90b3680f451ab6aae47761fa6b4f"
          }
        },
        "b9173054f4c346d399a0a79be9c61add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7acaf10cc42446c29c62963d70aae7ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 917/917 [00:15&lt;00:00, 58.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66d8b1b1fecc4d9dbdda77f781b9e1b2"
          }
        },
        "ccd2ad864a0e4e019963cc96b82cd567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e03a90b3680f451ab6aae47761fa6b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7acaf10cc42446c29c62963d70aae7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66d8b1b1fecc4d9dbdda77f781b9e1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJbYXou6chZf",
        "outputId": "2d7703b2-fe20-4121-e0c6-e11d10c69ccb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 12 11:06:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ-g1BUq0Odo"
      },
      "source": [
        "##Competition Dataset\n",
        "\n",
        "https://github.com/MMU-TDMLab/CompLex\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syVRBRdQSElX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca65909-524d-48c3-89ba-c432368fa7f4"
      },
      "source": [
        "import os\n",
        "%cd /content/\n",
        "if os.path.exists(\"/content/CompLex\") == False:\n",
        "    os.system(\"git clone https://github.com/MMU-TDMLab/CompLex.git\")\n",
        "if os.path.exists(\"/content/train\") == False:\n",
        "    os.system(\"mkdir /content/train\")\n",
        "    os.system(\"cp /content/CompLex/train/lcp_single_train.tsv /content/train\")\n",
        "    os.system(\"cp /content/CompLex/trial/lcp_single_trial.tsv /content/train\")\n",
        "    os.system(\"cp /content/CompLex/test-labels/lcp_single_test.tsv /content/\")\n",
        "    os.system(\"cp /content/CompLex/train/lcp_multi_train.tsv /content/train\")\n",
        "    os.system(\"cp /content/CompLex/trial/lcp_multi_trial.tsv /content/train\")\n",
        "    os.system(\"cp /content/CompLex/test-labels/lcp_multi_test.tsv /content/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r_vDzCbWEzF"
      },
      "source": [
        "# dependencies\n",
        "\n",
        "%%capture\n",
        "!pip install transformers\n",
        "!sudo pip install catboost\n",
        "!pip install syllables\n",
        "!pip install wordfreq\n",
        "!pip install textstat\n",
        "!pip install PyDictionary\n",
        "!pip install mega.py"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhB7WGB_-XNF",
        "outputId": "e3c39697-a22a-4e78-98b4-c23729e5c81e"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "repo_name = \"CS60075-Team-2-Task-1\"\n",
        "\n",
        "if os.path.exists(repo_name) == False:\n",
        "    user = input('Git Username: ')\n",
        "    password = getpass('Git Password: ')\n",
        "    password = urllib.parse.quote(password) # your password is converted into url format\n",
        "    repo_user = \"abhi1nandy2\"\n",
        "\n",
        "    cmd_string = 'git clone https://{0}:{1}@github.com/{2}/{3}.git'.format(user, password, repo_user, repo_name)\n",
        "\n",
        "    os.system(cmd_string)\n",
        "    cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Git Username: abhi1nandy2\n",
            "Git Password: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9VpKXBnCHVe"
      },
      "source": [
        "##Fine-tuning Transformer \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y45WouixIC42"
      },
      "source": [
        "![Transformer_reg.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbSeCoQc-up0",
        "outputId": "b510d88f-c801-43a9-9a00-c74dc8b2346b"
      },
      "source": [
        "%cd /content/CS60075-Team-2-Task-1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CS60075-Team-2-Task-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4YSbzRD-si9",
        "outputId": "29309e71-6b33-4a80-b9c1-d0ea9d695d2e"
      },
      "source": [
        "!python our_approach.py --mode single"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 05:06:17.361871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]\n",
            "Downloading: 100% 567/567 [00:00<00:00, 922kB/s]\n",
            "\n",
            "Downloading: 100% 798k/798k [00:00<00:00, 35.3MB/s]\n",
            "\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 23.7MB/s]\n",
            "\n",
            "Downloading: 100% 239/239 [00:00<00:00, 423kB/s]\n",
            "\n",
            "Downloading: 100% 125/125 [00:00<00:00, 219kB/s]\n",
            "\n",
            "  0% 0/7662 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "\n",
            "  4% 317/7662 [00:00<00:02, 3166.75it/s]\u001b[A\n",
            "  9% 667/7662 [00:00<00:02, 3259.75it/s]\u001b[A\n",
            " 13% 993/7662 [00:00<00:02, 3259.56it/s]\u001b[A\n",
            " 17% 1322/7662 [00:00<00:01, 3267.56it/s]\u001b[A\n",
            " 22% 1689/7662 [00:00<00:01, 3377.54it/s]\u001b[A\n",
            " 27% 2060/7662 [00:00<00:01, 3468.34it/s]\u001b[A\n",
            " 32% 2451/7662 [00:00<00:01, 3588.37it/s]\u001b[A\n",
            " 36% 2786/7662 [00:00<00:01, 3191.77it/s]\u001b[A\n",
            " 40% 3097/7662 [00:00<00:01, 2982.59it/s]\u001b[A\n",
            " 44% 3406/7662 [00:01<00:01, 3011.89it/s]\u001b[A\n",
            " 48% 3705/7662 [00:01<00:01, 3000.07it/s]\u001b[A\n",
            " 52% 4007/7662 [00:01<00:01, 3003.73it/s]\u001b[A\n",
            " 56% 4322/7662 [00:01<00:01, 3046.02it/s]\u001b[A\n",
            " 61% 4647/7662 [00:01<00:00, 3102.77it/s]\u001b[A\n",
            " 65% 4958/7662 [00:01<00:00, 3074.26it/s]\u001b[A\n",
            " 69% 5280/7662 [00:01<00:00, 3116.02it/s]\u001b[A\n",
            " 73% 5592/7662 [00:01<00:00, 3111.43it/s]\u001b[A\n",
            " 77% 5904/7662 [00:01<00:00, 3050.95it/s]\u001b[A\n",
            " 81% 6210/7662 [00:01<00:00, 2996.80it/s]\u001b[A\n",
            " 85% 6517/7662 [00:02<00:00, 3017.69it/s]\u001b[A\n",
            " 89% 6820/7662 [00:02<00:00, 2921.41it/s]\u001b[A\n",
            " 93% 7125/7662 [00:02<00:00, 2958.61it/s]\u001b[A\n",
            "100% 7662/7662 [00:02<00:00, 3105.70it/s]\n",
            "Original:  Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass. river\n",
            "torch.Size([7662, 256]) torch.Size([7662, 256]) torch.Size([7662, 256]) torch.Size([7662])\n",
            "\n",
            "  0% 0/421 [00:00<?, ?it/s]\u001b[A\n",
            "100% 421/421 [00:00<00:00, 3367.93it/s]\n",
            "Original:  They will not hurt nor destroy in all my holy mountain; for the earth will be full of the knowledge of Yahweh, as the waters cover the sea. sea\n",
            "torch.Size([421, 256]) torch.Size([421, 256]) torch.Size([421, 256]) torch.Size([421])\n",
            "\n",
            "  0% 0/917 [00:00<?, ?it/s]\u001b[A\n",
            " 39% 354/917 [00:00<00:00, 3533.96it/s]\u001b[A\n",
            "100% 917/917 [00:00<00:00, 3181.15it/s]\n",
            "Original:  But he, beckoning to them with his hand to be silent, declared to them how the Lord had brought him out of the prison. hand\n",
            "torch.Size([917, 256]) torch.Size([917, 256]) torch.Size([917, 256]) torch.Size([917])\n",
            "7662 421 917\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Downloading:   0% 0.00/499M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 4.45M/499M [00:00<00:11, 44.5MB/s]\u001b[A\n",
            "Downloading:   2% 10.9M/499M [00:00<00:09, 49.0MB/s]\u001b[A\n",
            "Downloading:   3% 17.0M/499M [00:00<00:09, 52.1MB/s]\u001b[A\n",
            "Downloading:   5% 23.4M/499M [00:00<00:08, 55.3MB/s]\u001b[A\n",
            "Downloading:   6% 29.9M/499M [00:00<00:08, 57.9MB/s]\u001b[A\n",
            "Downloading:   7% 36.2M/499M [00:00<00:07, 59.2MB/s]\u001b[A\n",
            "Downloading:   9% 42.9M/499M [00:00<00:07, 61.3MB/s]\u001b[A\n",
            "Downloading:  10% 49.3M/499M [00:00<00:07, 62.2MB/s]\u001b[A\n",
            "Downloading:  11% 55.4M/499M [00:00<00:07, 59.3MB/s]\u001b[A\n",
            "Downloading:  12% 61.9M/499M [00:01<00:07, 61.2MB/s]\u001b[A\n",
            "Downloading:  14% 68.3M/499M [00:01<00:06, 61.7MB/s]\u001b[A\n",
            "Downloading:  15% 74.8M/499M [00:01<00:06, 62.8MB/s]\u001b[A\n",
            "Downloading:  16% 81.6M/499M [00:01<00:06, 64.2MB/s]\u001b[A\n",
            "Downloading:  18% 88.2M/499M [00:01<00:06, 64.7MB/s]\u001b[A\n",
            "Downloading:  19% 94.8M/499M [00:01<00:06, 65.1MB/s]\u001b[A\n",
            "Downloading:  20% 102M/499M [00:01<00:06, 65.9MB/s] \u001b[A\n",
            "Downloading:  22% 108M/499M [00:01<00:05, 66.0MB/s]\u001b[A\n",
            "Downloading:  23% 115M/499M [00:01<00:05, 65.4MB/s]\u001b[A\n",
            "Downloading:  24% 121M/499M [00:01<00:06, 58.9MB/s]\u001b[A\n",
            "Downloading:  26% 127M/499M [00:02<00:06, 56.3MB/s]\u001b[A\n",
            "Downloading:  27% 134M/499M [00:02<00:06, 58.2MB/s]\u001b[A\n",
            "Downloading:  28% 140M/499M [00:02<00:06, 59.1MB/s]\u001b[A\n",
            "Downloading:  29% 146M/499M [00:02<00:05, 60.6MB/s]\u001b[A\n",
            "Downloading:  31% 152M/499M [00:02<00:05, 60.3MB/s]\u001b[A\n",
            "Downloading:  32% 158M/499M [00:02<00:05, 59.2MB/s]\u001b[A\n",
            "Downloading:  33% 164M/499M [00:02<00:05, 59.5MB/s]\u001b[A\n",
            "Downloading:  34% 170M/499M [00:02<00:05, 57.1MB/s]\u001b[A\n",
            "Downloading:  35% 176M/499M [00:02<00:05, 57.4MB/s]\u001b[A\n",
            "Downloading:  36% 182M/499M [00:02<00:05, 57.7MB/s]\u001b[A\n",
            "Downloading:  38% 189M/499M [00:03<00:05, 59.7MB/s]\u001b[A\n",
            "Downloading:  39% 195M/499M [00:03<00:04, 61.1MB/s]\u001b[A\n",
            "Downloading:  40% 201M/499M [00:03<00:04, 61.8MB/s]\u001b[A\n",
            "Downloading:  42% 208M/499M [00:03<00:04, 62.4MB/s]\u001b[A\n",
            "Downloading:  43% 214M/499M [00:03<00:04, 63.6MB/s]\u001b[A\n",
            "Downloading:  44% 221M/499M [00:03<00:04, 63.8MB/s]\u001b[A\n",
            "Downloading:  46% 228M/499M [00:03<00:04, 64.9MB/s]\u001b[A\n",
            "Downloading:  47% 234M/499M [00:03<00:04, 64.6MB/s]\u001b[A\n",
            "Downloading:  48% 241M/499M [00:03<00:03, 65.0MB/s]\u001b[A\n",
            "Downloading:  50% 247M/499M [00:04<00:03, 63.9MB/s]\u001b[A\n",
            "Downloading:  51% 254M/499M [00:04<00:03, 62.4MB/s]\u001b[A\n",
            "Downloading:  52% 260M/499M [00:04<00:04, 55.6MB/s]\u001b[A\n",
            "Downloading:  53% 266M/499M [00:04<00:04, 57.7MB/s]\u001b[A\n",
            "Downloading:  55% 273M/499M [00:04<00:03, 59.3MB/s]\u001b[A\n",
            "Downloading:  56% 279M/499M [00:04<00:03, 59.4MB/s]\u001b[A\n",
            "Downloading:  57% 285M/499M [00:04<00:03, 60.7MB/s]\u001b[A\n",
            "Downloading:  58% 291M/499M [00:04<00:03, 60.8MB/s]\u001b[A\n",
            "Downloading:  60% 297M/499M [00:04<00:03, 60.4MB/s]\u001b[A\n",
            "Downloading:  61% 303M/499M [00:04<00:03, 61.1MB/s]\u001b[A\n",
            "Downloading:  62% 310M/499M [00:05<00:03, 60.9MB/s]\u001b[A\n",
            "Downloading:  63% 316M/499M [00:05<00:02, 62.0MB/s]\u001b[A\n",
            "Downloading:  65% 322M/499M [00:05<00:02, 61.4MB/s]\u001b[A\n",
            "Downloading:  66% 329M/499M [00:05<00:02, 63.4MB/s]\u001b[A\n",
            "Downloading:  67% 336M/499M [00:05<00:02, 63.9MB/s]\u001b[A\n",
            "Downloading:  69% 342M/499M [00:05<00:02, 63.8MB/s]\u001b[A\n",
            "Downloading:  70% 349M/499M [00:05<00:02, 65.1MB/s]\u001b[A\n",
            "Downloading:  71% 356M/499M [00:05<00:02, 65.7MB/s]\u001b[A\n",
            "Downloading:  73% 362M/499M [00:05<00:02, 65.6MB/s]\u001b[A\n",
            "Downloading:  74% 369M/499M [00:05<00:01, 65.5MB/s]\u001b[A\n",
            "Downloading:  75% 375M/499M [00:06<00:01, 65.4MB/s]\u001b[A\n",
            "Downloading:  77% 382M/499M [00:06<00:01, 66.6MB/s]\u001b[A\n",
            "Downloading:  78% 389M/499M [00:06<00:01, 64.6MB/s]\u001b[A\n",
            "Downloading:  79% 396M/499M [00:06<00:01, 65.6MB/s]\u001b[A\n",
            "Downloading:  81% 403M/499M [00:06<00:01, 66.7MB/s]\u001b[A\n",
            "Downloading:  82% 409M/499M [00:06<00:01, 65.8MB/s]\u001b[A\n",
            "Downloading:  83% 416M/499M [00:06<00:01, 59.6MB/s]\u001b[A\n",
            "Downloading:  85% 422M/499M [00:06<00:01, 59.2MB/s]\u001b[A\n",
            "Downloading:  86% 428M/499M [00:06<00:01, 60.5MB/s]\u001b[A\n",
            "Downloading:  87% 435M/499M [00:07<00:01, 60.8MB/s]\u001b[A\n",
            "Downloading:  88% 441M/499M [00:07<00:00, 61.9MB/s]\u001b[A\n",
            "Downloading:  90% 448M/499M [00:07<00:00, 63.4MB/s]\u001b[A\n",
            "Downloading:  91% 454M/499M [00:07<00:00, 64.1MB/s]\u001b[A\n",
            "Downloading:  92% 461M/499M [00:07<00:00, 65.2MB/s]\u001b[A\n",
            "Downloading:  94% 468M/499M [00:07<00:00, 66.0MB/s]\u001b[A\n",
            "Downloading:  95% 475M/499M [00:07<00:00, 55.9MB/s]\u001b[A\n",
            "Downloading:  96% 480M/499M [00:07<00:00, 56.6MB/s]\u001b[A\n",
            "Downloading:  98% 487M/499M [00:07<00:00, 58.7MB/s]\u001b[A\n",
            "Downloading: 100% 499M/499M [00:08<00:00, 61.8MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at abhi1nandy2/Europarl-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0853, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 3.4236044883728027\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(421,)\n",
            "(421,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.78\n",
            "\n",
            " 25% 1/4 [05:45<17:16, 345.61s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0095, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.9822088479995728\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(421,)\n",
            "(421,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.79\n",
            "\n",
            " 50% 2/4 [11:33<11:32, 346.24s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.5942754745483398\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(421,)\n",
            "(421,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.81\n",
            "\n",
            " 75% 3/4 [17:21<05:46, 346.79s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.459889531135559\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(421,)\n",
            "(421,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.80\n",
            "\n",
            "100% 4/4 [23:09<00:00, 347.41s/it]\n",
            "0.806493033298082\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(917,)\n",
            "(917,)\n",
            "0.7309891100587168\n",
            "8it [23:41, 177.72s/it]\n",
            "Downloading: 100% 385/385 [00:00<00:00, 557kB/s]\n",
            "\n",
            "Downloading: 100% 213k/213k [00:00<00:00, 18.8MB/s]\n",
            "\n",
            "  0% 0/7662 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 354/7662 [00:00<00:02, 3536.02it/s]\u001b[A\n",
            "  9% 699/7662 [00:00<00:01, 3506.75it/s]\u001b[A\n",
            " 13% 1024/7662 [00:00<00:01, 3423.76it/s]\u001b[A\n",
            " 18% 1375/7662 [00:00<00:01, 3448.83it/s]\u001b[A\n",
            " 23% 1741/7662 [00:00<00:01, 3508.39it/s]\u001b[A\n",
            " 27% 2075/7662 [00:00<00:01, 3453.40it/s]\u001b[A\n",
            " 31% 2394/7662 [00:00<00:01, 3367.13it/s]\u001b[A\n",
            " 36% 2729/7662 [00:00<00:01, 3360.62it/s]\u001b[A\n",
            " 40% 3046/7662 [00:00<00:01, 3156.40it/s]\u001b[A\n",
            " 44% 3359/7662 [00:01<00:01, 3147.16it/s]\u001b[A\n",
            " 48% 3674/7662 [00:01<00:01, 3146.50it/s]\u001b[A\n",
            " 52% 3984/7662 [00:01<00:01, 3026.36it/s]\u001b[A\n",
            " 56% 4284/7662 [00:01<00:01, 2999.53it/s]\u001b[A\n",
            " 60% 4590/7662 [00:01<00:01, 3015.45it/s]\u001b[A\n",
            " 64% 4891/7662 [00:01<00:00, 3010.15it/s]\u001b[A\n",
            " 68% 5209/7662 [00:01<00:00, 3057.35it/s]\u001b[A\n",
            " 72% 5535/7662 [00:01<00:00, 3111.88it/s]\u001b[A\n",
            " 76% 5847/7662 [00:01<00:00, 3111.06it/s]\u001b[A\n",
            " 80% 6159/7662 [00:01<00:00, 3082.53it/s]\u001b[A\n",
            " 85% 6484/7662 [00:02<00:00, 3130.91it/s]\u001b[A\n",
            " 89% 6798/7662 [00:02<00:00, 3056.84it/s]\u001b[A\n",
            " 93% 7118/7662 [00:02<00:00, 3096.46it/s]\u001b[A\n",
            "100% 7662/7662 [00:02<00:00, 3164.83it/s]\n",
            "Original:  Behold, there came up out of the river seven cattle, sleek and fat, and they fed in the marsh grass. river\n",
            "torch.Size([7662, 256]) torch.Size([7662, 256]) torch.Size([7662, 256]) torch.Size([7662])\n",
            "\n",
            "  0% 0/421 [00:00<?, ?it/s]\u001b[A\n",
            "100% 421/421 [00:00<00:00, 3188.36it/s]\n",
            "Original:  They will not hurt nor destroy in all my holy mountain; for the earth will be full of the knowledge of Yahweh, as the waters cover the sea. sea\n",
            "torch.Size([421, 256]) torch.Size([421, 256]) torch.Size([421, 256]) torch.Size([421])\n",
            "\n",
            "  0% 0/917 [00:00<?, ?it/s]\u001b[A\n",
            " 39% 360/917 [00:00<00:00, 3592.76it/s]\u001b[A\n",
            "100% 917/917 [00:00<00:00, 3093.93it/s]\n",
            "Original:  But he, beckoning to them with his hand to be silent, declared to them how the Lord had brought him out of the prison. hand\n",
            "torch.Size([917, 256]) torch.Size([917, 256]) torch.Size([917, 256]) torch.Size([917])\n",
            "7662 421 917\n",
            "\n",
            "Downloading:   0% 0.00/436M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 3.34M/436M [00:00<00:12, 33.4MB/s]\u001b[A\n",
            "Downloading:   2% 10.0M/436M [00:00<00:10, 39.3MB/s]\u001b[A\n",
            "Downloading:   4% 16.8M/436M [00:00<00:09, 43.0MB/s]\u001b[A\n",
            "Downloading:   5% 20.3M/436M [00:00<00:11, 36.2MB/s]\u001b[A\n",
            "Downloading:   5% 23.6M/436M [00:00<00:13, 29.9MB/s]\u001b[A\n",
            "Downloading:   7% 28.8M/436M [00:00<00:11, 34.3MB/s]\u001b[A\n",
            "Downloading:   8% 35.8M/436M [00:00<00:09, 40.5MB/s]\u001b[A\n",
            "Downloading:   9% 40.5M/436M [00:00<00:09, 42.1MB/s]\u001b[A\n",
            "Downloading:  10% 45.1M/436M [00:01<00:09, 40.1MB/s]\u001b[A\n",
            "Downloading:  12% 51.9M/436M [00:01<00:08, 45.7MB/s]\u001b[A\n",
            "Downloading:  13% 58.6M/436M [00:01<00:07, 50.6MB/s]\u001b[A\n",
            "Downloading:  15% 65.3M/436M [00:01<00:06, 54.5MB/s]\u001b[A\n",
            "Downloading:  16% 71.2M/436M [00:01<00:06, 53.4MB/s]\u001b[A\n",
            "Downloading:  18% 77.3M/436M [00:01<00:06, 55.5MB/s]\u001b[A\n",
            "Downloading:  19% 83.9M/436M [00:01<00:06, 50.3MB/s]\u001b[A\n",
            "Downloading:  21% 89.9M/436M [00:01<00:06, 53.1MB/s]\u001b[A\n",
            "Downloading:  22% 95.5M/436M [00:01<00:07, 46.2MB/s]\u001b[A\n",
            "Downloading:  23% 101M/436M [00:02<00:08, 39.9MB/s] \u001b[A\n",
            "Downloading:  24% 106M/436M [00:02<00:07, 43.1MB/s]\u001b[A\n",
            "Downloading:  26% 112M/436M [00:02<00:06, 47.1MB/s]\u001b[A\n",
            "Downloading:  27% 117M/436M [00:02<00:06, 48.1MB/s]\u001b[A\n",
            "Downloading:  28% 124M/436M [00:02<00:06, 51.4MB/s]\u001b[A\n",
            "Downloading:  30% 129M/436M [00:02<00:06, 47.7MB/s]\u001b[A\n",
            "Downloading:  31% 135M/436M [00:02<00:05, 50.2MB/s]\u001b[A\n",
            "Downloading:  32% 141M/436M [00:02<00:05, 52.7MB/s]\u001b[A\n",
            "Downloading:  34% 146M/436M [00:03<00:06, 43.5MB/s]\u001b[A\n",
            "Downloading:  35% 151M/436M [00:03<00:06, 40.9MB/s]\u001b[A\n",
            "Downloading:  36% 155M/436M [00:03<00:07, 35.8MB/s]\u001b[A\n",
            "Downloading:  37% 159M/436M [00:03<00:07, 36.0MB/s]\u001b[A\n",
            "Downloading:  38% 166M/436M [00:03<00:06, 41.8MB/s]\u001b[A\n",
            "Downloading:  39% 171M/436M [00:03<00:09, 29.1MB/s]\u001b[A\n",
            "Downloading:  40% 176M/436M [00:03<00:07, 34.0MB/s]\u001b[A\n",
            "Downloading:  41% 181M/436M [00:04<00:08, 31.2MB/s]\u001b[A\n",
            "Downloading:  42% 185M/436M [00:04<00:09, 27.0MB/s]\u001b[A\n",
            "Downloading:  44% 191M/436M [00:04<00:07, 32.5MB/s]\u001b[A\n",
            "Downloading:  45% 195M/436M [00:04<00:08, 29.3MB/s]\u001b[A\n",
            "Downloading:  46% 201M/436M [00:04<00:06, 34.5MB/s]\u001b[A\n",
            "Downloading:  47% 206M/436M [00:04<00:06, 38.0MB/s]\u001b[A\n",
            "Downloading:  48% 210M/436M [00:04<00:06, 32.4MB/s]\u001b[A\n",
            "Downloading:  50% 216M/436M [00:05<00:05, 37.5MB/s]\u001b[A\n",
            "Downloading:  51% 221M/436M [00:05<00:07, 30.0MB/s]\u001b[A\n",
            "Downloading:  52% 226M/436M [00:05<00:06, 32.4MB/s]\u001b[A\n",
            "Downloading:  53% 233M/436M [00:05<00:05, 37.8MB/s]\u001b[A\n",
            "Downloading:  54% 237M/436M [00:05<00:04, 40.1MB/s]\u001b[A\n",
            "Downloading:  56% 243M/436M [00:05<00:04, 43.8MB/s]\u001b[A\n",
            "Downloading:  57% 248M/436M [00:05<00:04, 45.8MB/s]\u001b[A\n",
            "Downloading:  58% 253M/436M [00:05<00:04, 41.0MB/s]\u001b[A\n",
            "Downloading:  59% 259M/436M [00:06<00:03, 45.0MB/s]\u001b[A\n",
            "Downloading:  61% 264M/436M [00:06<00:04, 42.0MB/s]\u001b[A\n",
            "Downloading:  62% 268M/436M [00:06<00:04, 37.3MB/s]\u001b[A\n",
            "Downloading:  63% 274M/436M [00:06<00:03, 41.3MB/s]\u001b[A\n",
            "Downloading:  64% 280M/436M [00:06<00:03, 46.2MB/s]\u001b[A\n",
            "Downloading:  66% 287M/436M [00:06<00:02, 50.3MB/s]\u001b[A\n",
            "Downloading:  67% 293M/436M [00:06<00:02, 54.2MB/s]\u001b[A\n",
            "Downloading:  69% 300M/436M [00:06<00:02, 56.4MB/s]\u001b[A\n",
            "Downloading:  70% 305M/436M [00:07<00:02, 43.8MB/s]\u001b[A\n",
            "Downloading:  71% 311M/436M [00:07<00:03, 37.0MB/s]\u001b[A\n",
            "Downloading:  73% 317M/436M [00:07<00:02, 42.0MB/s]\u001b[A\n",
            "Downloading:  74% 323M/436M [00:07<00:02, 47.3MB/s]\u001b[A\n",
            "Downloading:  75% 329M/436M [00:07<00:02, 41.1MB/s]\u001b[A\n",
            "Downloading:  77% 335M/436M [00:07<00:02, 46.1MB/s]\u001b[A\n",
            "Downloading:  78% 341M/436M [00:07<00:01, 47.9MB/s]\u001b[A\n",
            "Downloading:  79% 346M/436M [00:07<00:01, 47.0MB/s]\u001b[A\n",
            "Downloading:  81% 352M/436M [00:08<00:01, 50.5MB/s]\u001b[A\n",
            "Downloading:  82% 358M/436M [00:08<00:01, 52.9MB/s]\u001b[A\n",
            "Downloading:  84% 365M/436M [00:08<00:01, 56.1MB/s]\u001b[A\n",
            "Downloading:  85% 371M/436M [00:08<00:01, 58.5MB/s]\u001b[A\n",
            "Downloading:  87% 377M/436M [00:08<00:01, 56.2MB/s]\u001b[A\n",
            "Downloading:  88% 383M/436M [00:08<00:00, 56.3MB/s]\u001b[A\n",
            "Downloading:  89% 389M/436M [00:08<00:00, 56.7MB/s]\u001b[A\n",
            "Downloading:  91% 396M/436M [00:08<00:00, 59.2MB/s]\u001b[A\n",
            "Downloading:  92% 402M/436M [00:08<00:00, 60.1MB/s]\u001b[A\n",
            "Downloading:  94% 408M/436M [00:09<00:00, 54.5MB/s]\u001b[A\n",
            "Downloading:  95% 413M/436M [00:09<00:00, 51.3MB/s]\u001b[A\n",
            "Downloading:  96% 419M/436M [00:09<00:00, 50.6MB/s]\u001b[A\n",
            "Downloading:  98% 426M/436M [00:09<00:00, 54.2MB/s]\u001b[A\n",
            "Downloading: 100% 436M/436M [00:09<00:00, 45.8MB/s]\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0682, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 3.5506439208984375\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(421,)\n",
            "(421,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.73\n",
            "\n",
            " 25% 1/4 [05:48<17:26, 348.80s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 2.4301791191101074\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(421,)\n",
            "(421,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.72\n",
            "\n",
            " 50% 2/4 [11:36<11:37, 348.55s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.7707339525222778\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(421,)\n",
            "(421,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.72\n",
            "\n",
            " 75% 3/4 [17:24<05:48, 348.41s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.457958698272705\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(421,)\n",
            "(421,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.72\n",
            "\n",
            "100% 4/4 [23:12<00:00, 348.15s/it]\n",
            "0.7269529522063644\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(917,)\n",
            "(917,)\n",
            "0.7125065615610116\n",
            "9it [47:26, 316.23s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2G0P99FeOnd",
        "outputId": "5f1f41d0-b2a5-4f8f-f9fe-6d5997d0db80"
      },
      "source": [
        "!python our_approach.py --mode multi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 06:58:05.844349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]\n",
            "Downloading: 100% 433/433 [00:00<00:00, 646kB/s]\n",
            "\n",
            "Downloading:   0% 0.00/232k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:  16% 36.9k/232k [00:00<00:00, 302kB/s]\u001b[A\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 925kB/s]\n",
            "\n",
            "Downloading:   0% 0.00/466k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   8% 36.9k/466k [00:00<00:01, 306kB/s]\u001b[A\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 1.49MB/s]\n",
            "\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 39.1kB/s]\n",
            "\n",
            "  0% 0/1517 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "\n",
            " 28% 429/1517 [00:00<00:00, 4287.07it/s]\u001b[A\n",
            " 54% 825/1517 [00:00<00:00, 4182.08it/s]\u001b[A\n",
            " 78% 1178/1517 [00:00<00:00, 3956.34it/s]\u001b[A\n",
            "100% 1517/1517 [00:00<00:00, 3780.18it/s]\n",
            "Original:  but the seventh day is a Sabbath to Yahweh your God, in which you shall not do any work, you, nor your son, nor your daughter, nor your male servant, nor your female servant, nor your ox, nor your donkey, nor any of your livestock, nor your stranger who is within your gates; that your male servant and your female servant may rest as well as you. seventh day\n",
            "torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517])\n",
            "\n",
            "100% 99/99 [00:00<00:00, 4201.94it/s]\n",
            "Original:  The name of one son was Gershom, for Moses said, \"I have lived as a foreigner in a foreign land\". foreign land\n",
            "torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99])\n",
            "\n",
            "100% 184/184 [00:00<00:00, 4437.60it/s]\n",
            "Original:  for he had an only daughter, about twelve years of age, and she was dying. only daughter\n",
            "torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184])\n",
            "1517 99 184\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Downloading:   0% 0.00/440M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 4.62M/440M [00:00<00:09, 46.2MB/s]\u001b[A\n",
            "Downloading:   3% 12.0M/440M [00:00<00:08, 52.1MB/s]\u001b[A\n",
            "Downloading:   4% 18.9M/440M [00:00<00:07, 56.2MB/s]\u001b[A\n",
            "Downloading:   6% 26.0M/440M [00:00<00:06, 60.0MB/s]\u001b[A\n",
            "Downloading:   8% 33.5M/440M [00:00<00:06, 63.8MB/s]\u001b[A\n",
            "Downloading:   9% 40.8M/440M [00:00<00:06, 66.3MB/s]\u001b[A\n",
            "Downloading:  11% 48.0M/440M [00:00<00:05, 68.0MB/s]\u001b[A\n",
            "Downloading:  13% 55.5M/440M [00:00<00:05, 69.8MB/s]\u001b[A\n",
            "Downloading:  14% 62.9M/440M [00:00<00:05, 71.0MB/s]\u001b[A\n",
            "Downloading:  16% 70.3M/440M [00:01<00:05, 71.9MB/s]\u001b[A\n",
            "Downloading:  18% 77.6M/440M [00:01<00:05, 72.3MB/s]\u001b[A\n",
            "Downloading:  19% 84.8M/440M [00:01<00:04, 71.8MB/s]\u001b[A\n",
            "Downloading:  21% 92.4M/440M [00:01<00:04, 72.8MB/s]\u001b[A\n",
            "Downloading:  23% 99.6M/440M [00:01<00:04, 72.1MB/s]\u001b[A\n",
            "Downloading:  24% 107M/440M [00:01<00:04, 72.6MB/s] \u001b[A\n",
            "Downloading:  26% 114M/440M [00:01<00:04, 73.1MB/s]\u001b[A\n",
            "Downloading:  28% 122M/440M [00:01<00:04, 67.5MB/s]\u001b[A\n",
            "Downloading:  29% 129M/440M [00:01<00:05, 62.1MB/s]\u001b[A\n",
            "Downloading:  31% 135M/440M [00:01<00:04, 62.9MB/s]\u001b[A\n",
            "Downloading:  32% 142M/440M [00:02<00:04, 63.8MB/s]\u001b[A\n",
            "Downloading:  34% 148M/440M [00:02<00:04, 63.3MB/s]\u001b[A\n",
            "Downloading:  35% 155M/440M [00:02<00:04, 64.2MB/s]\u001b[A\n",
            "Downloading:  37% 161M/440M [00:02<00:04, 63.3MB/s]\u001b[A\n",
            "Downloading:  38% 168M/440M [00:02<00:04, 64.7MB/s]\u001b[A\n",
            "Downloading:  40% 175M/440M [00:02<00:04, 65.9MB/s]\u001b[A\n",
            "Downloading:  41% 182M/440M [00:02<00:03, 67.4MB/s]\u001b[A\n",
            "Downloading:  43% 189M/440M [00:02<00:03, 68.4MB/s]\u001b[A\n",
            "Downloading:  45% 197M/440M [00:02<00:03, 70.6MB/s]\u001b[A\n",
            "Downloading:  46% 204M/440M [00:02<00:03, 67.1MB/s]\u001b[A\n",
            "Downloading:  48% 211M/440M [00:03<00:03, 67.7MB/s]\u001b[A\n",
            "Downloading:  49% 218M/440M [00:03<00:03, 67.9MB/s]\u001b[A\n",
            "Downloading:  51% 225M/440M [00:03<00:03, 68.4MB/s]\u001b[A\n",
            "Downloading:  53% 231M/440M [00:03<00:03, 68.0MB/s]\u001b[A\n",
            "Downloading:  54% 238M/440M [00:03<00:02, 68.6MB/s]\u001b[A\n",
            "Downloading:  56% 246M/440M [00:03<00:02, 70.9MB/s]\u001b[A\n",
            "Downloading:  58% 254M/440M [00:03<00:02, 72.9MB/s]\u001b[A\n",
            "Downloading:  59% 261M/440M [00:03<00:02, 72.9MB/s]\u001b[A\n",
            "Downloading:  61% 269M/440M [00:03<00:02, 74.5MB/s]\u001b[A\n",
            "Downloading:  63% 277M/440M [00:04<00:02, 72.8MB/s]\u001b[A\n",
            "Downloading:  64% 284M/440M [00:04<00:02, 71.0MB/s]\u001b[A\n",
            "Downloading:  66% 291M/440M [00:04<00:02, 70.0MB/s]\u001b[A\n",
            "Downloading:  68% 298M/440M [00:04<00:02, 57.0MB/s]\u001b[A\n",
            "Downloading:  69% 305M/440M [00:04<00:02, 60.2MB/s]\u001b[A\n",
            "Downloading:  71% 312M/440M [00:04<00:02, 63.2MB/s]\u001b[A\n",
            "Downloading:  72% 319M/440M [00:04<00:01, 65.3MB/s]\u001b[A\n",
            "Downloading:  74% 326M/440M [00:04<00:01, 66.9MB/s]\u001b[A\n",
            "Downloading:  76% 333M/440M [00:04<00:01, 68.0MB/s]\u001b[A\n",
            "Downloading:  77% 340M/440M [00:05<00:01, 65.5MB/s]\u001b[A\n",
            "Downloading:  79% 347M/440M [00:05<00:01, 66.3MB/s]\u001b[A\n",
            "Downloading:  80% 354M/440M [00:05<00:01, 67.7MB/s]\u001b[A\n",
            "Downloading:  82% 361M/440M [00:05<00:01, 67.6MB/s]\u001b[A\n",
            "Downloading:  84% 368M/440M [00:05<00:01, 65.8MB/s]\u001b[A\n",
            "Downloading:  85% 375M/440M [00:05<00:00, 68.2MB/s]\u001b[A\n",
            "Downloading:  87% 383M/440M [00:05<00:00, 69.5MB/s]\u001b[A\n",
            "Downloading:  89% 390M/440M [00:05<00:00, 71.1MB/s]\u001b[A\n",
            "Downloading:  90% 397M/440M [00:05<00:00, 70.3MB/s]\u001b[A\n",
            "Downloading:  92% 404M/440M [00:05<00:00, 68.4MB/s]\u001b[A\n",
            "Downloading:  93% 412M/440M [00:06<00:00, 70.1MB/s]\u001b[A\n",
            "Downloading:  95% 419M/440M [00:06<00:00, 71.9MB/s]\u001b[A\n",
            "Downloading:  97% 427M/440M [00:06<00:00, 72.4MB/s]\u001b[A\n",
            "Downloading: 100% 440M/440M [00:06<00:00, 68.6MB/s]\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0518, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.039490818977356\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.65\n",
            "\n",
            " 25% 1/4 [00:37<01:52, 37.61s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.6569604277610779\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.70\n",
            "\n",
            " 50% 2/4 [01:15<01:15, 37.59s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.5018596649169922\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.72\n",
            "\n",
            " 75% 3/4 [01:52<00:37, 37.59s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.441691130399704\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.72\n",
            "\n",
            "100% 4/4 [02:30<00:00, 37.56s/it]\n",
            "0.7238195080165314\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(184,)\n",
            "(184,)\n",
            "0.7917586143370344\n",
            "1it [02:47, 167.24s/it]\n",
            "Downloading: 100% 549/549 [00:00<00:00, 748kB/s]\n",
            "\n",
            "Downloading:   0% 0.00/232k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:  16% 36.9k/232k [00:00<00:00, 301kB/s]\u001b[A\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 922kB/s]\n",
            "\n",
            "Downloading: 100% 112/112 [00:00<00:00, 193kB/s]\n",
            "\n",
            "Downloading: 100% 252/252 [00:00<00:00, 436kB/s]\n",
            "\n",
            "  0% 0/1517 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 329/1517 [00:00<00:00, 3280.94it/s]\u001b[A\n",
            " 43% 656/1517 [00:00<00:00, 3275.28it/s]\u001b[A\n",
            " 62% 940/1517 [00:00<00:00, 3129.96it/s]\u001b[A\n",
            "100% 1517/1517 [00:00<00:00, 3121.55it/s]\n",
            "Original:  but the seventh day is a Sabbath to Yahweh your God, in which you shall not do any work, you, nor your son, nor your daughter, nor your male servant, nor your female servant, nor your ox, nor your donkey, nor any of your livestock, nor your stranger who is within your gates; that your male servant and your female servant may rest as well as you. seventh day\n",
            "torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517])\n",
            "\n",
            "100% 99/99 [00:00<00:00, 3490.05it/s]\n",
            "Original:  The name of one son was Gershom, for Moses said, \"I have lived as a foreigner in a foreign land\". foreign land\n",
            "torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99])\n",
            "\n",
            "100% 184/184 [00:00<00:00, 3485.73it/s]\n",
            "Original:  for he had an only daughter, about twelve years of age, and she was dying. only daughter\n",
            "torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184])\n",
            "1517 99 184\n",
            "\n",
            "Downloading:   0% 0.00/438M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 5.30M/438M [00:00<00:08, 53.0MB/s]\u001b[A\n",
            "Downloading:   3% 12.6M/438M [00:00<00:07, 57.7MB/s]\u001b[A\n",
            "Downloading:   4% 19.7M/438M [00:00<00:06, 61.1MB/s]\u001b[A\n",
            "Downloading:   6% 26.8M/438M [00:00<00:06, 63.9MB/s]\u001b[A\n",
            "Downloading:   8% 33.9M/438M [00:00<00:06, 65.8MB/s]\u001b[A\n",
            "Downloading:   9% 41.0M/438M [00:00<00:05, 67.4MB/s]\u001b[A\n",
            "Downloading:  11% 48.1M/438M [00:00<00:05, 68.4MB/s]\u001b[A\n",
            "Downloading:  12% 54.7M/438M [00:00<00:05, 67.6MB/s]\u001b[A\n",
            "Downloading:  14% 61.2M/438M [00:00<00:05, 66.3MB/s]\u001b[A\n",
            "Downloading:  16% 68.6M/438M [00:01<00:05, 68.5MB/s]\u001b[A\n",
            "Downloading:  17% 75.7M/438M [00:01<00:05, 69.3MB/s]\u001b[A\n",
            "Downloading:  19% 82.7M/438M [00:01<00:05, 69.4MB/s]\u001b[A\n",
            "Downloading:  21% 90.1M/438M [00:01<00:04, 70.8MB/s]\u001b[A\n",
            "Downloading:  22% 97.5M/438M [00:01<00:04, 71.7MB/s]\u001b[A\n",
            "Downloading:  24% 105M/438M [00:01<00:04, 69.3MB/s] \u001b[A\n",
            "Downloading:  25% 112M/438M [00:01<00:05, 62.5MB/s]\u001b[A\n",
            "Downloading:  27% 118M/438M [00:01<00:05, 62.8MB/s]\u001b[A\n",
            "Downloading:  28% 125M/438M [00:01<00:04, 64.5MB/s]\u001b[A\n",
            "Downloading:  30% 132M/438M [00:01<00:04, 65.4MB/s]\u001b[A\n",
            "Downloading:  32% 139M/438M [00:02<00:04, 66.8MB/s]\u001b[A\n",
            "Downloading:  33% 146M/438M [00:02<00:04, 67.5MB/s]\u001b[A\n",
            "Downloading:  35% 152M/438M [00:02<00:04, 65.9MB/s]\u001b[A\n",
            "Downloading:  36% 159M/438M [00:02<00:04, 65.1MB/s]\u001b[A\n",
            "Downloading:  38% 166M/438M [00:02<00:04, 66.3MB/s]\u001b[A\n",
            "Downloading:  39% 173M/438M [00:02<00:04, 65.8MB/s]\u001b[A\n",
            "Downloading:  41% 180M/438M [00:02<00:03, 67.3MB/s]\u001b[A\n",
            "Downloading:  43% 187M/438M [00:02<00:03, 68.9MB/s]\u001b[A\n",
            "Downloading:  44% 194M/438M [00:02<00:03, 69.2MB/s]\u001b[A\n",
            "Downloading:  46% 201M/438M [00:02<00:03, 69.6MB/s]\u001b[A\n",
            "Downloading:  48% 208M/438M [00:03<00:03, 70.3MB/s]\u001b[A\n",
            "Downloading:  49% 215M/438M [00:03<00:03, 70.5MB/s]\u001b[A\n",
            "Downloading:  51% 223M/438M [00:03<00:03, 71.6MB/s]\u001b[A\n",
            "Downloading:  52% 230M/438M [00:03<00:02, 71.9MB/s]\u001b[A\n",
            "Downloading:  54% 237M/438M [00:03<00:02, 71.9MB/s]\u001b[A\n",
            "Downloading:  56% 244M/438M [00:03<00:02, 70.6MB/s]\u001b[A\n",
            "Downloading:  57% 252M/438M [00:03<00:02, 71.7MB/s]\u001b[A\n",
            "Downloading:  59% 259M/438M [00:03<00:02, 71.9MB/s]\u001b[A\n",
            "Downloading:  61% 266M/438M [00:03<00:02, 62.7MB/s]\u001b[A\n",
            "Downloading:  62% 273M/438M [00:04<00:02, 64.0MB/s]\u001b[A\n",
            "Downloading:  64% 280M/438M [00:04<00:02, 64.9MB/s]\u001b[A\n",
            "Downloading:  65% 287M/438M [00:04<00:02, 66.7MB/s]\u001b[A\n",
            "Downloading:  67% 294M/438M [00:04<00:02, 68.3MB/s]\u001b[A\n",
            "Downloading:  69% 301M/438M [00:04<00:02, 66.9MB/s]\u001b[A\n",
            "Downloading:  70% 308M/438M [00:04<00:02, 64.6MB/s]\u001b[A\n",
            "Downloading:  72% 314M/438M [00:04<00:01, 64.7MB/s]\u001b[A\n",
            "Downloading:  73% 321M/438M [00:04<00:01, 63.8MB/s]\u001b[A\n",
            "Downloading:  75% 328M/438M [00:04<00:01, 65.3MB/s]\u001b[A\n",
            "Downloading:  76% 335M/438M [00:04<00:01, 67.6MB/s]\u001b[A\n",
            "Downloading:  78% 342M/438M [00:05<00:01, 66.8MB/s]\u001b[A\n",
            "Downloading:  80% 349M/438M [00:05<00:01, 67.6MB/s]\u001b[A\n",
            "Downloading:  81% 356M/438M [00:05<00:01, 69.5MB/s]\u001b[A\n",
            "Downloading:  83% 363M/438M [00:05<00:01, 70.2MB/s]\u001b[A\n",
            "Downloading:  85% 371M/438M [00:05<00:00, 71.1MB/s]\u001b[A\n",
            "Downloading:  86% 378M/438M [00:05<00:00, 70.7MB/s]\u001b[A\n",
            "Downloading:  88% 385M/438M [00:05<00:00, 71.3MB/s]\u001b[A\n",
            "Downloading:  90% 392M/438M [00:05<00:00, 72.0MB/s]\u001b[A\n",
            "Downloading:  91% 400M/438M [00:05<00:00, 64.3MB/s]\u001b[A\n",
            "Downloading:  93% 406M/438M [00:05<00:00, 65.3MB/s]\u001b[A\n",
            "Downloading:  94% 414M/438M [00:06<00:00, 66.8MB/s]\u001b[A\n",
            "Downloading:  96% 420M/438M [00:06<00:00, 66.3MB/s]\u001b[A\n",
            "Downloading:  98% 427M/438M [00:06<00:00, 67.8MB/s]\u001b[A\n",
            "Downloading: 100% 438M/438M [00:06<00:00, 67.8MB/s]\n",
            "Some weights of BertModel were not initialized from the model checkpoint at lukabor/europarl-mlm and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.9255833625793457\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.02\n",
            "  Pearson Correlation: 0.58\n",
            "\n",
            " 25% 1/4 [00:37<01:52, 37.56s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.5171562433242798\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.70\n",
            "\n",
            " 50% 2/4 [01:15<01:15, 37.57s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.38286569714546204\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.74\n",
            "\n",
            " 75% 3/4 [01:52<00:37, 37.58s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.32274356484413147\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.74\n",
            "\n",
            "100% 4/4 [02:30<00:00, 37.58s/it]\n",
            "0.7426850133854827\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(184,)\n",
            "(184,)\n",
            "0.8007602635181418\n",
            "2it [05:31, 166.37s/it]\n",
            "Downloading: 100% 567/567 [00:00<00:00, 655kB/s]\n",
            "\n",
            "Downloading:   0% 0.00/798k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   5% 36.9k/798k [00:00<00:02, 309kB/s]\u001b[A\n",
            "Downloading: 100% 798k/798k [00:00<00:00, 2.47MB/s]\n",
            "\n",
            "Downloading:   0% 0.00/456k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   8% 36.9k/456k [00:00<00:01, 305kB/s]\u001b[A\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 1.46MB/s]\n",
            "\n",
            "Downloading: 100% 239/239 [00:00<00:00, 403kB/s]\n",
            "\n",
            "Downloading: 100% 125/125 [00:00<00:00, 189kB/s]\n",
            "\n",
            "  0% 0/1517 [00:00<?, ?it/s]\u001b[A\n",
            " 23% 355/1517 [00:00<00:00, 3546.53it/s]\u001b[A\n",
            " 42% 635/1517 [00:00<00:00, 3283.08it/s]\u001b[A\n",
            " 62% 937/1517 [00:00<00:00, 3197.53it/s]\u001b[A\n",
            "100% 1517/1517 [00:00<00:00, 3136.97it/s]\n",
            "Original:  but the seventh day is a Sabbath to Yahweh your God, in which you shall not do any work, you, nor your son, nor your daughter, nor your male servant, nor your female servant, nor your ox, nor your donkey, nor any of your livestock, nor your stranger who is within your gates; that your male servant and your female servant may rest as well as you. seventh day\n",
            "torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517])\n",
            "\n",
            "100% 99/99 [00:00<00:00, 3422.40it/s]\n",
            "Original:  The name of one son was Gershom, for Moses said, \"I have lived as a foreigner in a foreign land\". foreign land\n",
            "torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99])\n",
            "\n",
            "100% 184/184 [00:00<00:00, 3153.64it/s]\n",
            "Original:  for he had an only daughter, about twelve years of age, and she was dying. only daughter\n",
            "torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184])\n",
            "1517 99 184\n",
            "\n",
            "Downloading:   0% 0.00/499M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 5.41M/499M [00:00<00:09, 54.1MB/s]\u001b[A\n",
            "Downloading:   2% 12.2M/499M [00:00<00:08, 57.7MB/s]\u001b[A\n",
            "Downloading:   4% 18.2M/499M [00:00<00:08, 58.4MB/s]\u001b[A\n",
            "Downloading:   5% 24.8M/499M [00:00<00:07, 60.3MB/s]\u001b[A\n",
            "Downloading:   6% 32.2M/499M [00:00<00:07, 64.0MB/s]\u001b[A\n",
            "Downloading:   8% 39.3M/499M [00:00<00:06, 65.9MB/s]\u001b[A\n",
            "Downloading:   9% 47.0M/499M [00:00<00:06, 68.9MB/s]\u001b[A\n",
            "Downloading:  11% 54.9M/499M [00:00<00:06, 71.6MB/s]\u001b[A\n",
            "Downloading:  12% 62.3M/499M [00:00<00:06, 72.4MB/s]\u001b[A\n",
            "Downloading:  14% 69.4M/499M [00:01<00:05, 71.7MB/s]\u001b[A\n",
            "Downloading:  15% 76.9M/499M [00:01<00:05, 72.5MB/s]\u001b[A\n",
            "Downloading:  17% 84.3M/499M [00:01<00:05, 73.0MB/s]\u001b[A\n",
            "Downloading:  18% 91.9M/499M [00:01<00:05, 74.0MB/s]\u001b[A\n",
            "Downloading:  20% 99.7M/499M [00:01<00:05, 75.1MB/s]\u001b[A\n",
            "Downloading:  21% 107M/499M [00:01<00:05, 71.8MB/s] \u001b[A\n",
            "Downloading:  23% 114M/499M [00:01<00:06, 63.7MB/s]\u001b[A\n",
            "Downloading:  24% 121M/499M [00:01<00:05, 65.2MB/s]\u001b[A\n",
            "Downloading:  26% 129M/499M [00:01<00:05, 67.4MB/s]\u001b[A\n",
            "Downloading:  27% 136M/499M [00:01<00:05, 69.4MB/s]\u001b[A\n",
            "Downloading:  29% 143M/499M [00:02<00:05, 68.3MB/s]\u001b[A\n",
            "Downloading:  30% 150M/499M [00:02<00:05, 69.1MB/s]\u001b[A\n",
            "Downloading:  32% 157M/499M [00:02<00:04, 68.9MB/s]\u001b[A\n",
            "Downloading:  33% 164M/499M [00:02<00:05, 66.3MB/s]\u001b[A\n",
            "Downloading:  34% 171M/499M [00:02<00:04, 67.1MB/s]\u001b[A\n",
            "Downloading:  36% 178M/499M [00:02<00:04, 67.3MB/s]\u001b[A\n",
            "Downloading:  37% 185M/499M [00:02<00:04, 64.8MB/s]\u001b[A\n",
            "Downloading:  38% 191M/499M [00:02<00:04, 64.5MB/s]\u001b[A\n",
            "Downloading:  40% 199M/499M [00:02<00:04, 67.1MB/s]\u001b[A\n",
            "Downloading:  41% 205M/499M [00:02<00:04, 67.6MB/s]\u001b[A\n",
            "Downloading:  43% 212M/499M [00:03<00:04, 66.8MB/s]\u001b[A\n",
            "Downloading:  44% 219M/499M [00:03<00:04, 67.0MB/s]\u001b[A\n",
            "Downloading:  45% 226M/499M [00:03<00:04, 66.0MB/s]\u001b[A\n",
            "Downloading:  47% 233M/499M [00:03<00:03, 67.5MB/s]\u001b[A\n",
            "Downloading:  48% 240M/499M [00:03<00:03, 66.6MB/s]\u001b[A\n",
            "Downloading:  49% 246M/499M [00:03<00:03, 64.8MB/s]\u001b[A\n",
            "Downloading:  51% 253M/499M [00:03<00:03, 64.7MB/s]\u001b[A\n",
            "Downloading:  52% 259M/499M [00:03<00:03, 63.5MB/s]\u001b[A\n",
            "Downloading:  53% 266M/499M [00:03<00:04, 53.0MB/s]\u001b[A\n",
            "Downloading:  54% 271M/499M [00:04<00:04, 53.4MB/s]\u001b[A\n",
            "Downloading:  56% 278M/499M [00:04<00:03, 57.9MB/s]\u001b[A\n",
            "Downloading:  57% 285M/499M [00:04<00:03, 60.2MB/s]\u001b[A\n",
            "Downloading:  58% 291M/499M [00:04<00:03, 60.4MB/s]\u001b[A\n",
            "Downloading:  60% 298M/499M [00:04<00:03, 63.0MB/s]\u001b[A\n",
            "Downloading:  61% 305M/499M [00:04<00:03, 62.2MB/s]\u001b[A\n",
            "Downloading:  62% 311M/499M [00:04<00:03, 62.4MB/s]\u001b[A\n",
            "Downloading:  64% 318M/499M [00:04<00:02, 63.7MB/s]\u001b[A\n",
            "Downloading:  65% 324M/499M [00:04<00:02, 64.3MB/s]\u001b[A\n",
            "Downloading:  66% 332M/499M [00:05<00:02, 66.8MB/s]\u001b[A\n",
            "Downloading:  68% 339M/499M [00:05<00:02, 68.1MB/s]\u001b[A\n",
            "Downloading:  69% 346M/499M [00:05<00:02, 68.9MB/s]\u001b[A\n",
            "Downloading:  71% 353M/499M [00:05<00:02, 69.0MB/s]\u001b[A\n",
            "Downloading:  72% 360M/499M [00:05<00:02, 68.5MB/s]\u001b[A\n",
            "Downloading:  73% 367M/499M [00:05<00:01, 68.2MB/s]\u001b[A\n",
            "Downloading:  75% 374M/499M [00:05<00:01, 69.9MB/s]\u001b[A\n",
            "Downloading:  76% 381M/499M [00:05<00:01, 71.0MB/s]\u001b[A\n",
            "Downloading:  78% 389M/499M [00:05<00:01, 70.4MB/s]\u001b[A\n",
            "Downloading:  79% 396M/499M [00:05<00:01, 69.3MB/s]\u001b[A\n",
            "Downloading:  81% 403M/499M [00:06<00:01, 62.4MB/s]\u001b[A\n",
            "Downloading:  82% 409M/499M [00:06<00:01, 64.0MB/s]\u001b[A\n",
            "Downloading:  83% 416M/499M [00:06<00:01, 66.1MB/s]\u001b[A\n",
            "Downloading:  85% 423M/499M [00:06<00:01, 64.4MB/s]\u001b[A\n",
            "Downloading:  86% 430M/499M [00:06<00:01, 64.3MB/s]\u001b[A\n",
            "Downloading:  87% 436M/499M [00:06<00:00, 64.1MB/s]\u001b[A\n",
            "Downloading:  89% 443M/499M [00:06<00:00, 64.5MB/s]\u001b[A\n",
            "Downloading:  90% 449M/499M [00:06<00:00, 64.4MB/s]\u001b[A\n",
            "Downloading:  91% 456M/499M [00:06<00:00, 64.7MB/s]\u001b[A\n",
            "Downloading:  93% 463M/499M [00:06<00:00, 66.0MB/s]\u001b[A\n",
            "Downloading:  94% 469M/499M [00:07<00:00, 65.5MB/s]\u001b[A\n",
            "Downloading:  96% 477M/499M [00:07<00:00, 68.3MB/s]\u001b[A\n",
            "Downloading:  97% 484M/499M [00:07<00:00, 69.6MB/s]\u001b[A\n",
            "Downloading:  98% 491M/499M [00:07<00:00, 68.2MB/s]\u001b[A\n",
            "Downloading: 100% 499M/499M [00:07<00:00, 66.6MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at abhi1nandy2/Bible-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.182541847229004\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.02\n",
            "  Pearson Correlation: 0.29\n",
            "\n",
            " 25% 1/4 [00:37<01:53, 37.73s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.77784264087677\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.02\n",
            "  Pearson Correlation: 0.57\n",
            "\n",
            " 50% 2/4 [01:15<01:15, 37.73s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.4991624355316162\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.68\n",
            "\n",
            " 75% 3/4 [01:53<00:37, 37.74s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.3886812925338745\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.68\n",
            "\n",
            "100% 4/4 [02:30<00:00, 37.73s/it]\n",
            "0.6808314284243389\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(184,)\n",
            "(184,)\n",
            "0.7819136097646937\n",
            "3it [08:18, 166.68s/it]\n",
            "Downloading: 100% 567/567 [00:00<00:00, 697kB/s]\n",
            "\n",
            "Downloading:   0% 0.00/798k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   5% 36.9k/798k [00:00<00:02, 298kB/s]\u001b[A\n",
            "Downloading: 100% 798k/798k [00:00<00:00, 2.37MB/s]\n",
            "\n",
            "Downloading:   0% 0.00/456k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   8% 36.9k/456k [00:00<00:01, 291kB/s]\u001b[A\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 1.39MB/s]\n",
            "\n",
            "Downloading: 100% 239/239 [00:00<00:00, 362kB/s]\n",
            "\n",
            "Downloading: 100% 125/125 [00:00<00:00, 185kB/s]\n",
            "\n",
            "  0% 0/1517 [00:00<?, ?it/s]\u001b[A\n",
            " 21% 322/1517 [00:00<00:00, 3212.37it/s]\u001b[A\n",
            " 40% 604/1517 [00:00<00:00, 3081.05it/s]\u001b[A\n",
            " 59% 896/1517 [00:00<00:00, 3028.59it/s]\u001b[A\n",
            " 80% 1208/1517 [00:00<00:00, 3055.20it/s]\u001b[A\n",
            "100% 1517/1517 [00:00<00:00, 3010.14it/s]\n",
            "Original:  but the seventh day is a Sabbath to Yahweh your God, in which you shall not do any work, you, nor your son, nor your daughter, nor your male servant, nor your female servant, nor your ox, nor your donkey, nor any of your livestock, nor your stranger who is within your gates; that your male servant and your female servant may rest as well as you. seventh day\n",
            "torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517])\n",
            "\n",
            "100% 99/99 [00:00<00:00, 3398.50it/s]\n",
            "Original:  The name of one son was Gershom, for Moses said, \"I have lived as a foreigner in a foreign land\". foreign land\n",
            "torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99])\n",
            "\n",
            "100% 184/184 [00:00<00:00, 3568.05it/s]\n",
            "Original:  for he had an only daughter, about twelve years of age, and she was dying. only daughter\n",
            "torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184])\n",
            "1517 99 184\n",
            "\n",
            "Downloading:   0% 0.00/499M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 3.78M/499M [00:00<00:13, 37.8MB/s]\u001b[A\n",
            "Downloading:   2% 8.31M/499M [00:00<00:12, 39.8MB/s]\u001b[A\n",
            "Downloading:   3% 14.8M/499M [00:00<00:10, 45.0MB/s]\u001b[A\n",
            "Downloading:   4% 22.3M/499M [00:00<00:09, 51.2MB/s]\u001b[A\n",
            "Downloading:   6% 29.9M/499M [00:00<00:08, 56.7MB/s]\u001b[A\n",
            "Downloading:   7% 36.0M/499M [00:00<00:07, 57.9MB/s]\u001b[A\n",
            "Downloading:   9% 43.4M/499M [00:00<00:07, 61.9MB/s]\u001b[A\n",
            "Downloading:  10% 50.9M/499M [00:00<00:06, 65.4MB/s]\u001b[A\n",
            "Downloading:  12% 57.9M/499M [00:00<00:06, 66.7MB/s]\u001b[A\n",
            "Downloading:  13% 65.0M/499M [00:01<00:06, 67.9MB/s]\u001b[A\n",
            "Downloading:  14% 71.8M/499M [00:01<00:06, 67.6MB/s]\u001b[A\n",
            "Downloading:  16% 78.6M/499M [00:01<00:06, 67.4MB/s]\u001b[A\n",
            "Downloading:  17% 86.1M/499M [00:01<00:05, 69.4MB/s]\u001b[A\n",
            "Downloading:  19% 93.7M/499M [00:01<00:05, 71.3MB/s]\u001b[A\n",
            "Downloading:  20% 101M/499M [00:01<00:05, 69.7MB/s] \u001b[A\n",
            "Downloading:  22% 108M/499M [00:01<00:06, 60.2MB/s]\u001b[A\n",
            "Downloading:  23% 114M/499M [00:01<00:06, 59.9MB/s]\u001b[A\n",
            "Downloading:  24% 121M/499M [00:01<00:06, 62.0MB/s]\u001b[A\n",
            "Downloading:  26% 127M/499M [00:01<00:05, 61.9MB/s]\u001b[A\n",
            "Downloading:  27% 134M/499M [00:02<00:05, 62.8MB/s]\u001b[A\n",
            "Downloading:  28% 140M/499M [00:02<00:05, 64.1MB/s]\u001b[A\n",
            "Downloading:  29% 147M/499M [00:02<00:05, 63.8MB/s]\u001b[A\n",
            "Downloading:  31% 153M/499M [00:02<00:05, 63.6MB/s]\u001b[A\n",
            "Downloading:  32% 160M/499M [00:02<00:05, 62.7MB/s]\u001b[A\n",
            "Downloading:  33% 167M/499M [00:02<00:05, 64.8MB/s]\u001b[A\n",
            "Downloading:  35% 173M/499M [00:02<00:05, 64.0MB/s]\u001b[A\n",
            "Downloading:  36% 180M/499M [00:02<00:04, 64.8MB/s]\u001b[A\n",
            "Downloading:  37% 187M/499M [00:02<00:04, 66.5MB/s]\u001b[A\n",
            "Downloading:  39% 194M/499M [00:02<00:04, 68.1MB/s]\u001b[A\n",
            "Downloading:  40% 201M/499M [00:03<00:04, 66.2MB/s]\u001b[A\n",
            "Downloading:  42% 208M/499M [00:03<00:04, 66.1MB/s]\u001b[A\n",
            "Downloading:  43% 214M/499M [00:03<00:04, 66.2MB/s]\u001b[A\n",
            "Downloading:  44% 221M/499M [00:03<00:04, 66.2MB/s]\u001b[A\n",
            "Downloading:  46% 228M/499M [00:03<00:03, 68.2MB/s]\u001b[A\n",
            "Downloading:  47% 235M/499M [00:03<00:03, 68.4MB/s]\u001b[A\n",
            "Downloading:  49% 242M/499M [00:03<00:03, 66.6MB/s]\u001b[A\n",
            "Downloading:  50% 249M/499M [00:03<00:03, 68.3MB/s]\u001b[A\n",
            "Downloading:  51% 256M/499M [00:03<00:04, 58.9MB/s]\u001b[A\n",
            "Downloading:  53% 262M/499M [00:04<00:04, 58.5MB/s]\u001b[A\n",
            "Downloading:  54% 268M/499M [00:04<00:03, 59.2MB/s]\u001b[A\n",
            "Downloading:  55% 274M/499M [00:04<00:03, 58.6MB/s]\u001b[A\n",
            "Downloading:  56% 281M/499M [00:04<00:03, 60.7MB/s]\u001b[A\n",
            "Downloading:  58% 288M/499M [00:04<00:03, 63.1MB/s]\u001b[A\n",
            "Downloading:  59% 294M/499M [00:04<00:03, 61.3MB/s]\u001b[A\n",
            "Downloading:  60% 301M/499M [00:04<00:03, 62.4MB/s]\u001b[A\n",
            "Downloading:  62% 308M/499M [00:04<00:02, 65.4MB/s]\u001b[A\n",
            "Downloading:  63% 315M/499M [00:04<00:02, 67.0MB/s]\u001b[A\n",
            "Downloading:  65% 322M/499M [00:04<00:02, 65.8MB/s]\u001b[A\n",
            "Downloading:  66% 329M/499M [00:05<00:02, 67.8MB/s]\u001b[A\n",
            "Downloading:  67% 336M/499M [00:05<00:02, 66.9MB/s]\u001b[A\n",
            "Downloading:  69% 343M/499M [00:05<00:02, 66.4MB/s]\u001b[A\n",
            "Downloading:  70% 350M/499M [00:05<00:02, 66.5MB/s]\u001b[A\n",
            "Downloading:  71% 356M/499M [00:05<00:02, 59.8MB/s]\u001b[A\n",
            "Downloading:  73% 363M/499M [00:05<00:02, 61.6MB/s]\u001b[A\n",
            "Downloading:  74% 370M/499M [00:05<00:02, 63.0MB/s]\u001b[A\n",
            "Downloading:  75% 376M/499M [00:05<00:01, 64.4MB/s]\u001b[A\n",
            "Downloading:  77% 383M/499M [00:05<00:01, 62.6MB/s]\u001b[A\n",
            "Downloading:  78% 390M/499M [00:06<00:01, 63.7MB/s]\u001b[A\n",
            "Downloading:  79% 396M/499M [00:06<00:01, 64.5MB/s]\u001b[A\n",
            "Downloading:  81% 403M/499M [00:06<00:01, 64.2MB/s]\u001b[A\n",
            "Downloading:  82% 409M/499M [00:06<00:01, 64.9MB/s]\u001b[A\n",
            "Downloading:  83% 416M/499M [00:06<00:01, 66.3MB/s]\u001b[A\n",
            "Downloading:  85% 423M/499M [00:06<00:01, 64.9MB/s]\u001b[A\n",
            "Downloading:  86% 431M/499M [00:06<00:01, 67.6MB/s]\u001b[A\n",
            "Downloading:  88% 438M/499M [00:06<00:00, 68.4MB/s]\u001b[A\n",
            "Downloading:  89% 445M/499M [00:06<00:00, 68.8MB/s]\u001b[A\n",
            "Downloading:  90% 451M/499M [00:06<00:00, 67.8MB/s]\u001b[A\n",
            "Downloading:  92% 458M/499M [00:07<00:00, 66.8MB/s]\u001b[A\n",
            "Downloading:  93% 465M/499M [00:07<00:00, 67.4MB/s]\u001b[A\n",
            "Downloading:  95% 473M/499M [00:07<00:00, 69.7MB/s]\u001b[A\n",
            "Downloading:  96% 480M/499M [00:07<00:00, 69.4MB/s]\u001b[A\n",
            "Downloading:  98% 487M/499M [00:07<00:00, 71.4MB/s]\u001b[A\n",
            "Downloading: 100% 499M/499M [00:07<00:00, 65.4MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at abhi1nandy2/Craft-bionlp-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.1889628171920776\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.02\n",
            "  Pearson Correlation: 0.24\n",
            "\n",
            " 25% 1/4 [00:37<01:53, 37.90s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.8700618147850037\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.02\n",
            "  Pearson Correlation: 0.54\n",
            "\n",
            " 50% 2/4 [01:15<01:15, 37.90s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.5158781409263611\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.68\n",
            "\n",
            " 75% 3/4 [01:53<00:37, 37.89s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0103, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.43578532338142395\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.69\n",
            "\n",
            "100% 4/4 [02:31<00:00, 37.90s/it]\n",
            "0.6890324118212722\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(184,)\n",
            "(184,)\n",
            "0.7899643771919683\n",
            "4it [11:07, 167.19s/it]\n",
            "Downloading: 100% 758/758 [00:00<00:00, 902kB/s]\n",
            "\n",
            "Downloading:   0% 0.00/232k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:  16% 36.9k/232k [00:00<00:00, 299kB/s]\u001b[A\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 916kB/s]\n",
            "\n",
            "Downloading: 100% 112/112 [00:00<00:00, 128kB/s]\n",
            "\n",
            "Downloading: 100% 252/252 [00:00<00:00, 382kB/s]\n",
            "\n",
            "  0% 0/1517 [00:00<?, ?it/s]\u001b[A\n",
            " 23% 343/1517 [00:00<00:00, 3421.50it/s]\u001b[A\n",
            " 45% 677/1517 [00:00<00:00, 3394.13it/s]\u001b[A\n",
            " 61% 928/1517 [00:00<00:00, 3068.79it/s]\u001b[A\n",
            "100% 1517/1517 [00:00<00:00, 3050.12it/s]\n",
            "Original:  but the seventh day is a Sabbath to Yahweh your God, in which you shall not do any work, you, nor your son, nor your daughter, nor your male servant, nor your female servant, nor your ox, nor your donkey, nor any of your livestock, nor your stranger who is within your gates; that your male servant and your female servant may rest as well as you. seventh day\n",
            "torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517])\n",
            "\n",
            "100% 99/99 [00:00<00:00, 2514.40it/s]\n",
            "Original:  The name of one son was Gershom, for Moses said, \"I have lived as a foreigner in a foreign land\". foreign land\n",
            "torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99])\n",
            "\n",
            "100% 184/184 [00:00<00:00, 3356.82it/s]\n",
            "Original:  for he had an only daughter, about twelve years of age, and she was dying. only daughter\n",
            "torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184])\n",
            "1517 99 184\n",
            "\n",
            "Downloading:   0% 0.00/438M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 4.67M/438M [00:00<00:09, 46.7MB/s]\u001b[A\n",
            "Downloading:   3% 11.0M/438M [00:00<00:08, 50.8MB/s]\u001b[A\n",
            "Downloading:   4% 17.2M/438M [00:00<00:07, 53.6MB/s]\u001b[A\n",
            "Downloading:   5% 23.2M/438M [00:00<00:07, 55.4MB/s]\u001b[A\n",
            "Downloading:   7% 30.2M/438M [00:00<00:06, 59.1MB/s]\u001b[A\n",
            "Downloading:   8% 37.0M/438M [00:00<00:06, 61.6MB/s]\u001b[A\n",
            "Downloading:  10% 43.9M/438M [00:00<00:06, 63.4MB/s]\u001b[A\n",
            "Downloading:  12% 50.7M/438M [00:00<00:05, 64.9MB/s]\u001b[A\n",
            "Downloading:  13% 57.6M/438M [00:00<00:05, 66.0MB/s]\u001b[A\n",
            "Downloading:  15% 64.1M/438M [00:01<00:05, 65.0MB/s]\u001b[A\n",
            "Downloading:  16% 71.3M/438M [00:01<00:05, 67.0MB/s]\u001b[A\n",
            "Downloading:  18% 78.3M/438M [00:01<00:05, 67.9MB/s]\u001b[A\n",
            "Downloading:  19% 85.1M/438M [00:01<00:05, 65.5MB/s]\u001b[A\n",
            "Downloading:  21% 92.4M/438M [00:01<00:05, 67.6MB/s]\u001b[A\n",
            "Downloading:  23% 99.2M/438M [00:01<00:05, 67.4MB/s]\u001b[A\n",
            "Downloading:  24% 106M/438M [00:01<00:05, 60.7MB/s] \u001b[A\n",
            "Downloading:  26% 113M/438M [00:01<00:05, 63.1MB/s]\u001b[A\n",
            "Downloading:  27% 119M/438M [00:01<00:05, 62.9MB/s]\u001b[A\n",
            "Downloading:  29% 126M/438M [00:01<00:05, 61.9MB/s]\u001b[A\n",
            "Downloading:  30% 133M/438M [00:02<00:04, 64.0MB/s]\u001b[A\n",
            "Downloading:  32% 139M/438M [00:02<00:04, 60.2MB/s]\u001b[A\n",
            "Downloading:  33% 145M/438M [00:02<00:04, 59.4MB/s]\u001b[A\n",
            "Downloading:  35% 151M/438M [00:02<00:04, 60.0MB/s]\u001b[A\n",
            "Downloading:  36% 157M/438M [00:02<00:04, 58.6MB/s]\u001b[A\n",
            "Downloading:  37% 164M/438M [00:02<00:04, 59.6MB/s]\u001b[A\n",
            "Downloading:  39% 170M/438M [00:02<00:04, 61.4MB/s]\u001b[A\n",
            "Downloading:  40% 176M/438M [00:02<00:04, 61.9MB/s]\u001b[A\n",
            "Downloading:  42% 183M/438M [00:02<00:03, 64.0MB/s]\u001b[A\n",
            "Downloading:  43% 190M/438M [00:02<00:03, 65.5MB/s]\u001b[A\n",
            "Downloading:  45% 197M/438M [00:03<00:03, 65.8MB/s]\u001b[A\n",
            "Downloading:  47% 204M/438M [00:03<00:03, 67.8MB/s]\u001b[A\n",
            "Downloading:  48% 211M/438M [00:03<00:03, 65.2MB/s]\u001b[A\n",
            "Downloading:  50% 218M/438M [00:03<00:03, 65.2MB/s]\u001b[A\n",
            "Downloading:  51% 225M/438M [00:03<00:03, 66.3MB/s]\u001b[A\n",
            "Downloading:  53% 231M/438M [00:03<00:03, 65.7MB/s]\u001b[A\n",
            "Downloading:  54% 238M/438M [00:03<00:02, 67.4MB/s]\u001b[A\n",
            "Downloading:  56% 245M/438M [00:03<00:03, 64.2MB/s]\u001b[A\n",
            "Downloading:  57% 252M/438M [00:03<00:03, 57.8MB/s]\u001b[A\n",
            "Downloading:  59% 258M/438M [00:04<00:03, 59.8MB/s]\u001b[A\n",
            "Downloading:  61% 265M/438M [00:04<00:02, 62.8MB/s]\u001b[A\n",
            "Downloading:  62% 272M/438M [00:04<00:02, 62.1MB/s]\u001b[A\n",
            "Downloading:  64% 278M/438M [00:04<00:02, 63.4MB/s]\u001b[A\n",
            "Downloading:  65% 285M/438M [00:04<00:02, 61.2MB/s]\u001b[A\n",
            "Downloading:  66% 291M/438M [00:04<00:02, 61.7MB/s]\u001b[A\n",
            "Downloading:  68% 298M/438M [00:04<00:02, 63.5MB/s]\u001b[A\n",
            "Downloading:  69% 304M/438M [00:04<00:02, 61.7MB/s]\u001b[A\n",
            "Downloading:  71% 311M/438M [00:04<00:01, 64.6MB/s]\u001b[A\n",
            "Downloading:  73% 318M/438M [00:05<00:01, 65.1MB/s]\u001b[A\n",
            "Downloading:  74% 325M/438M [00:05<00:01, 65.2MB/s]\u001b[A\n",
            "Downloading:  76% 332M/438M [00:05<00:01, 66.1MB/s]\u001b[A\n",
            "Downloading:  77% 338M/438M [00:05<00:01, 66.7MB/s]\u001b[A\n",
            "Downloading:  79% 345M/438M [00:05<00:01, 65.7MB/s]\u001b[A\n",
            "Downloading:  80% 352M/438M [00:05<00:01, 67.7MB/s]\u001b[A\n",
            "Downloading:  82% 360M/438M [00:05<00:01, 69.6MB/s]\u001b[A\n",
            "Downloading:  84% 367M/438M [00:05<00:01, 67.6MB/s]\u001b[A\n",
            "Downloading:  85% 374M/438M [00:05<00:00, 66.5MB/s]\u001b[A\n",
            "Downloading:  87% 380M/438M [00:05<00:00, 66.2MB/s]\u001b[A\n",
            "Downloading:  88% 387M/438M [00:06<00:00, 52.8MB/s]\u001b[A\n",
            "Downloading:  90% 393M/438M [00:06<00:00, 54.2MB/s]\u001b[A\n",
            "Downloading:  91% 399M/438M [00:06<00:00, 56.3MB/s]\u001b[A\n",
            "Downloading:  93% 405M/438M [00:06<00:00, 58.5MB/s]\u001b[A\n",
            "Downloading:  94% 412M/438M [00:06<00:00, 59.6MB/s]\u001b[A\n",
            "Downloading:  95% 418M/438M [00:06<00:00, 58.8MB/s]\u001b[A\n",
            "Downloading:  97% 424M/438M [00:06<00:00, 59.4MB/s]\u001b[A\n",
            "Downloading:  98% 430M/438M [00:06<00:00, 60.5MB/s]\u001b[A\n",
            "Downloading: 100% 438M/438M [00:06<00:00, 63.1MB/s]\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.0749882459640503\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.62\n",
            "\n",
            " 25% 1/4 [00:37<01:53, 37.80s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.6066279411315918\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.69\n",
            "\n",
            " 50% 2/4 [01:15<01:15, 37.81s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.45876169204711914\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.73\n",
            "\n",
            " 75% 3/4 [01:53<00:37, 37.82s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.40665730834007263\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.74\n",
            "\n",
            "100% 4/4 [02:31<00:00, 37.82s/it]\n",
            "0.7408232502919498\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(184,)\n",
            "(184,)\n",
            "0.7897449740595273\n",
            "5it [13:53, 166.99s/it]\n",
            "Downloading: 100% 385/385 [00:00<00:00, 516kB/s]\n",
            "\n",
            "Downloading:   0% 0.00/228k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:  16% 36.9k/228k [00:00<00:00, 302kB/s]\u001b[A\n",
            "Downloading: 100% 228k/228k [00:00<00:00, 908kB/s]\n",
            "\n",
            "  0% 0/1517 [00:00<?, ?it/s]\u001b[A\n",
            " 24% 357/1517 [00:00<00:00, 3560.37it/s]\u001b[A\n",
            " 46% 697/1517 [00:00<00:00, 3508.76it/s]\u001b[A\n",
            " 66% 998/1517 [00:00<00:00, 3340.33it/s]\u001b[A\n",
            "100% 1517/1517 [00:00<00:00, 3241.83it/s]\n",
            "Original:  but the seventh day is a Sabbath to Yahweh your God, in which you shall not do any work, you, nor your son, nor your daughter, nor your male servant, nor your female servant, nor your ox, nor your donkey, nor any of your livestock, nor your stranger who is within your gates; that your male servant and your female servant may rest as well as you. seventh day\n",
            "torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517])\n",
            "\n",
            "100% 99/99 [00:00<00:00, 3131.71it/s]\n",
            "Original:  The name of one son was Gershom, for Moses said, \"I have lived as a foreigner in a foreign land\". foreign land\n",
            "torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99])\n",
            "\n",
            "100% 184/184 [00:00<00:00, 2690.21it/s]\n",
            "Original:  for he had an only daughter, about twelve years of age, and she was dying. only daughter\n",
            "torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184])\n",
            "1517 99 184\n",
            "\n",
            "Downloading:   0% 0.00/442M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 4.83M/442M [00:00<00:09, 48.3MB/s]\u001b[A\n",
            "Downloading:   3% 11.2M/442M [00:00<00:08, 52.1MB/s]\u001b[A\n",
            "Downloading:   4% 16.7M/442M [00:00<00:08, 52.8MB/s]\u001b[A\n",
            "Downloading:   5% 22.8M/442M [00:00<00:07, 55.2MB/s]\u001b[A\n",
            "Downloading:   7% 29.1M/442M [00:00<00:07, 57.3MB/s]\u001b[A\n",
            "Downloading:   8% 35.1M/442M [00:00<00:07, 58.0MB/s]\u001b[A\n",
            "Downloading:   9% 41.7M/442M [00:00<00:06, 60.1MB/s]\u001b[A\n",
            "Downloading:  11% 48.8M/442M [00:00<00:06, 63.0MB/s]\u001b[A\n",
            "Downloading:  13% 55.4M/442M [00:00<00:06, 63.9MB/s]\u001b[A\n",
            "Downloading:  14% 62.5M/442M [00:01<00:05, 65.8MB/s]\u001b[A\n",
            "Downloading:  16% 69.9M/442M [00:01<00:05, 68.2MB/s]\u001b[A\n",
            "Downloading:  17% 76.7M/442M [00:01<00:05, 67.2MB/s]\u001b[A\n",
            "Downloading:  19% 83.5M/442M [00:01<00:05, 67.6MB/s]\u001b[A\n",
            "Downloading:  21% 90.7M/442M [00:01<00:05, 68.7MB/s]\u001b[A\n",
            "Downloading:  22% 97.5M/442M [00:01<00:05, 68.1MB/s]\u001b[A\n",
            "Downloading:  24% 104M/442M [00:01<00:05, 62.2MB/s] \u001b[A\n",
            "Downloading:  25% 111M/442M [00:01<00:05, 61.6MB/s]\u001b[A\n",
            "Downloading:  26% 117M/442M [00:01<00:05, 62.1MB/s]\u001b[A\n",
            "Downloading:  28% 124M/442M [00:01<00:04, 64.7MB/s]\u001b[A\n",
            "Downloading:  30% 131M/442M [00:02<00:04, 66.7MB/s]\u001b[A\n",
            "Downloading:  31% 138M/442M [00:02<00:04, 63.7MB/s]\u001b[A\n",
            "Downloading:  33% 145M/442M [00:02<00:04, 63.6MB/s]\u001b[A\n",
            "Downloading:  34% 151M/442M [00:02<00:04, 63.6MB/s]\u001b[A\n",
            "Downloading:  36% 157M/442M [00:02<00:04, 62.6MB/s]\u001b[A\n",
            "Downloading:  37% 164M/442M [00:02<00:04, 62.8MB/s]\u001b[A\n",
            "Downloading:  38% 170M/442M [00:02<00:04, 62.7MB/s]\u001b[A\n",
            "Downloading:  40% 176M/442M [00:02<00:04, 61.9MB/s]\u001b[A\n",
            "Downloading:  41% 183M/442M [00:02<00:04, 62.3MB/s]\u001b[A\n",
            "Downloading:  43% 189M/442M [00:02<00:04, 62.1MB/s]\u001b[A\n",
            "Downloading:  44% 195M/442M [00:03<00:04, 60.0MB/s]\u001b[A\n",
            "Downloading:  46% 202M/442M [00:03<00:03, 61.4MB/s]\u001b[A\n",
            "Downloading:  47% 208M/442M [00:03<00:03, 62.5MB/s]\u001b[A\n",
            "Downloading:  48% 214M/442M [00:03<00:03, 61.0MB/s]\u001b[A\n",
            "Downloading:  50% 222M/442M [00:03<00:03, 64.9MB/s]\u001b[A\n",
            "Downloading:  52% 230M/442M [00:03<00:03, 68.2MB/s]\u001b[A\n",
            "Downloading:  54% 237M/442M [00:03<00:03, 63.9MB/s]\u001b[A\n",
            "Downloading:  55% 243M/442M [00:03<00:03, 57.8MB/s]\u001b[A\n",
            "Downloading:  56% 250M/442M [00:03<00:03, 59.7MB/s]\u001b[A\n",
            "Downloading:  58% 256M/442M [00:04<00:03, 61.6MB/s]\u001b[A\n",
            "Downloading:  59% 263M/442M [00:04<00:02, 60.8MB/s]\u001b[A\n",
            "Downloading:  61% 269M/442M [00:04<00:02, 62.1MB/s]\u001b[A\n",
            "Downloading:  62% 276M/442M [00:04<00:02, 63.3MB/s]\u001b[A\n",
            "Downloading:  64% 282M/442M [00:04<00:02, 64.0MB/s]\u001b[A\n",
            "Downloading:  65% 290M/442M [00:04<00:02, 66.6MB/s]\u001b[A\n",
            "Downloading:  67% 297M/442M [00:04<00:02, 68.5MB/s]\u001b[A\n",
            "Downloading:  69% 304M/442M [00:04<00:02, 67.4MB/s]\u001b[A\n",
            "Downloading:  70% 311M/442M [00:04<00:01, 67.9MB/s]\u001b[A\n",
            "Downloading:  72% 318M/442M [00:04<00:01, 68.2MB/s]\u001b[A\n",
            "Downloading:  73% 324M/442M [00:05<00:01, 67.5MB/s]\u001b[A\n",
            "Downloading:  75% 332M/442M [00:05<00:01, 69.6MB/s]\u001b[A\n",
            "Downloading:  77% 339M/442M [00:05<00:01, 70.7MB/s]\u001b[A\n",
            "Downloading:  78% 346M/442M [00:05<00:01, 68.8MB/s]\u001b[A\n",
            "Downloading:  80% 353M/442M [00:05<00:01, 59.9MB/s]\u001b[A\n",
            "Downloading:  81% 360M/442M [00:05<00:01, 61.2MB/s]\u001b[A\n",
            "Downloading:  83% 366M/442M [00:05<00:01, 60.0MB/s]\u001b[A\n",
            "Downloading:  84% 373M/442M [00:05<00:01, 61.7MB/s]\u001b[A\n",
            "Downloading:  86% 379M/442M [00:05<00:01, 61.1MB/s]\u001b[A\n",
            "Downloading:  87% 385M/442M [00:06<00:00, 61.9MB/s]\u001b[A\n",
            "Downloading:  89% 392M/442M [00:06<00:00, 63.3MB/s]\u001b[A\n",
            "Downloading:  90% 398M/442M [00:06<00:00, 60.3MB/s]\u001b[A\n",
            "Downloading:  92% 405M/442M [00:06<00:00, 62.7MB/s]\u001b[A\n",
            "Downloading:  93% 412M/442M [00:06<00:00, 63.2MB/s]\u001b[A\n",
            "Downloading:  95% 418M/442M [00:06<00:00, 61.4MB/s]\u001b[A\n",
            "Downloading:  96% 424M/442M [00:06<00:00, 61.7MB/s]\u001b[A\n",
            "Downloading:  98% 431M/442M [00:06<00:00, 64.0MB/s]\u001b[A\n",
            "Downloading: 100% 442M/442M [00:06<00:00, 63.7MB/s]\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.9048094749450684\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.02\n",
            "  Pearson Correlation: 0.58\n",
            "\n",
            " 25% 1/4 [00:37<01:53, 37.94s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.5353527069091797\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.64\n",
            "\n",
            " 50% 2/4 [01:15<01:15, 37.91s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.4440617859363556\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.67\n",
            "\n",
            " 75% 3/4 [01:53<00:37, 37.89s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.36394569277763367\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.66\n",
            "\n",
            "100% 4/4 [02:31<00:00, 37.87s/it]\n",
            "0.6684505130725147\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(184,)\n",
            "(184,)\n",
            "0.7778933369015459\n",
            "6it [16:39, 166.68s/it]\n",
            "Downloading: 100% 512/512 [00:00<00:00, 580kB/s]\n",
            "\n",
            "Downloading:   0% 0.00/5.07M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 49.2k/5.07M [00:00<00:13, 372kB/s]\u001b[A\n",
            "Downloading:   5% 258k/5.07M [00:00<00:09, 482kB/s] \u001b[A\n",
            "Downloading:  21% 1.09M/5.07M [00:00<00:05, 667kB/s]\u001b[A\n",
            "Downloading: 100% 5.07M/5.07M [00:00<00:00, 9.30MB/s]\n",
            "\n",
            "Downloading:   0% 0.00/9.10M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   0% 41.0k/9.10M [00:00<00:27, 324kB/s]\u001b[A\n",
            "Downloading:   2% 201k/9.10M [00:00<00:21, 417kB/s] \u001b[A\n",
            "Downloading:   9% 856k/9.10M [00:00<00:14, 575kB/s]\u001b[A\n",
            "Downloading:  33% 3.02M/9.10M [00:00<00:07, 810kB/s]\u001b[A\n",
            "Downloading: 100% 9.10M/9.10M [00:00<00:00, 12.9MB/s]\n",
            "\n",
            "  0% 0/1517 [00:00<?, ?it/s]\u001b[A\n",
            " 21% 314/1517 [00:00<00:00, 3137.39it/s]\u001b[A\n",
            " 41% 618/1517 [00:00<00:00, 3106.31it/s]\u001b[A\n",
            " 59% 900/1517 [00:00<00:00, 3013.86it/s]\u001b[A\n",
            " 77% 1169/1517 [00:00<00:00, 2908.35it/s]\u001b[A\n",
            "100% 1517/1517 [00:00<00:00, 2882.04it/s]\n",
            "Original:  but the seventh day is a Sabbath to Yahweh your God, in which you shall not do any work, you, nor your son, nor your daughter, nor your male servant, nor your female servant, nor your ox, nor your donkey, nor any of your livestock, nor your stranger who is within your gates; that your male servant and your female servant may rest as well as you. seventh day\n",
            "torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517, 256]) torch.Size([1517])\n",
            "\n",
            "100% 99/99 [00:00<00:00, 3154.83it/s]\n",
            "Original:  The name of one son was Gershom, for Moses said, \"I have lived as a foreigner in a foreign land\". foreign land\n",
            "torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99, 256]) torch.Size([99])\n",
            "\n",
            "100% 184/184 [00:00<00:00, 2726.59it/s]\n",
            "Original:  for he had an only daughter, about twelve years of age, and she was dying. only daughter\n",
            "torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184, 256]) torch.Size([184])\n",
            "1517 99 184\n",
            "\n",
            "Downloading:   0% 0.00/1.12G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   0% 4.95M/1.12G [00:00<00:22, 49.5MB/s]\u001b[A\n",
            "Downloading:   1% 11.6M/1.12G [00:00<00:20, 53.5MB/s]\u001b[A\n",
            "Downloading:   2% 17.7M/1.12G [00:00<00:19, 55.7MB/s]\u001b[A\n",
            "Downloading:   2% 25.0M/1.12G [00:00<00:18, 59.8MB/s]\u001b[A\n",
            "Downloading:   3% 31.4M/1.12G [00:00<00:17, 61.1MB/s]\u001b[A\n",
            "Downloading:   3% 37.2M/1.12G [00:00<00:17, 60.1MB/s]\u001b[A\n",
            "Downloading:   4% 44.0M/1.12G [00:00<00:17, 62.2MB/s]\u001b[A\n",
            "Downloading:   5% 50.7M/1.12G [00:00<00:16, 63.6MB/s]\u001b[A\n",
            "Downloading:   5% 56.8M/1.12G [00:00<00:17, 61.8MB/s]\u001b[A\n",
            "Downloading:   6% 63.5M/1.12G [00:01<00:16, 63.3MB/s]\u001b[A\n",
            "Downloading:   6% 69.8M/1.12G [00:01<00:16, 62.7MB/s]\u001b[A\n",
            "Downloading:   7% 76.0M/1.12G [00:01<00:17, 59.2MB/s]\u001b[A\n",
            "Downloading:   7% 82.3M/1.12G [00:01<00:17, 60.3MB/s]\u001b[A\n",
            "Downloading:   8% 88.3M/1.12G [00:01<00:17, 59.0MB/s]\u001b[A\n",
            "Downloading:   8% 94.2M/1.12G [00:01<00:18, 54.5MB/s]\u001b[A\n",
            "Downloading:   9% 101M/1.12G [00:01<00:17, 58.1MB/s] \u001b[A\n",
            "Downloading:  10% 108M/1.12G [00:01<00:16, 60.9MB/s]\u001b[A\n",
            "Downloading:  10% 114M/1.12G [00:01<00:16, 61.7MB/s]\u001b[A\n",
            "Downloading:  11% 121M/1.12G [00:01<00:15, 62.6MB/s]\u001b[A\n",
            "Downloading:  11% 127M/1.12G [00:02<00:15, 63.1MB/s]\u001b[A\n",
            "Downloading:  12% 134M/1.12G [00:02<00:15, 61.7MB/s]\u001b[A\n",
            "Downloading:  13% 140M/1.12G [00:02<00:15, 62.7MB/s]\u001b[A\n",
            "Downloading:  13% 147M/1.12G [00:02<00:14, 65.1MB/s]\u001b[A\n",
            "Downloading:  14% 154M/1.12G [00:02<00:14, 65.6MB/s]\u001b[A\n",
            "Downloading:  14% 161M/1.12G [00:02<00:14, 66.8MB/s]\u001b[A\n",
            "Downloading:  15% 168M/1.12G [00:02<00:13, 67.7MB/s]\u001b[A\n",
            "Downloading:  16% 175M/1.12G [00:02<00:14, 66.5MB/s]\u001b[A\n",
            "Downloading:  16% 182M/1.12G [00:02<00:13, 68.1MB/s]\u001b[A\n",
            "Downloading:  17% 189M/1.12G [00:02<00:13, 66.5MB/s]\u001b[A\n",
            "Downloading:  18% 195M/1.12G [00:03<00:14, 62.7MB/s]\u001b[A\n",
            "Downloading:  18% 202M/1.12G [00:03<00:14, 63.9MB/s]\u001b[A\n",
            "Downloading:  19% 209M/1.12G [00:03<00:13, 65.6MB/s]\u001b[A\n",
            "Downloading:  19% 216M/1.12G [00:03<00:13, 64.3MB/s]\u001b[A\n",
            "Downloading:  20% 222M/1.12G [00:03<00:13, 64.7MB/s]\u001b[A\n",
            "Downloading:  21% 229M/1.12G [00:03<00:14, 61.7MB/s]\u001b[A\n",
            "Downloading:  21% 235M/1.12G [00:03<00:15, 57.7MB/s]\u001b[A\n",
            "Downloading:  22% 241M/1.12G [00:03<00:15, 58.3MB/s]\u001b[A\n",
            "Downloading:  22% 247M/1.12G [00:03<00:14, 60.2MB/s]\u001b[A\n",
            "Downloading:  23% 254M/1.12G [00:04<00:14, 61.3MB/s]\u001b[A\n",
            "Downloading:  23% 260M/1.12G [00:04<00:14, 59.6MB/s]\u001b[A\n",
            "Downloading:  24% 266M/1.12G [00:04<00:14, 60.0MB/s]\u001b[A\n",
            "Downloading:  24% 272M/1.12G [00:04<00:13, 61.0MB/s]\u001b[A\n",
            "Downloading:  25% 279M/1.12G [00:04<00:13, 61.0MB/s]\u001b[A\n",
            "Downloading:  26% 286M/1.12G [00:04<00:13, 63.5MB/s]\u001b[A\n",
            "Downloading:  26% 292M/1.12G [00:04<00:14, 57.3MB/s]\u001b[A\n",
            "Downloading:  27% 298M/1.12G [00:04<00:13, 59.3MB/s]\u001b[A\n",
            "Downloading:  27% 305M/1.12G [00:04<00:13, 62.3MB/s]\u001b[A\n",
            "Downloading:  28% 312M/1.12G [00:05<00:12, 62.7MB/s]\u001b[A\n",
            "Downloading:  29% 318M/1.12G [00:05<00:12, 62.2MB/s]\u001b[A\n",
            "Downloading:  29% 325M/1.12G [00:05<00:12, 62.9MB/s]\u001b[A\n",
            "Downloading:  30% 331M/1.12G [00:05<00:12, 61.7MB/s]\u001b[A\n",
            "Downloading:  30% 338M/1.12G [00:05<00:12, 63.5MB/s]\u001b[A\n",
            "Downloading:  31% 345M/1.12G [00:05<00:11, 65.7MB/s]\u001b[A\n",
            "Downloading:  32% 352M/1.12G [00:05<00:12, 63.5MB/s]\u001b[A\n",
            "Downloading:  32% 359M/1.12G [00:05<00:11, 66.4MB/s]\u001b[A\n",
            "Downloading:  33% 366M/1.12G [00:05<00:11, 68.1MB/s]\u001b[A\n",
            "Downloading:  33% 373M/1.12G [00:05<00:11, 66.1MB/s]\u001b[A\n",
            "Downloading:  34% 380M/1.12G [00:06<00:10, 67.5MB/s]\u001b[A\n",
            "Downloading:  35% 387M/1.12G [00:06<00:10, 68.8MB/s]\u001b[A\n",
            "Downloading:  35% 394M/1.12G [00:06<00:11, 62.5MB/s]\u001b[A\n",
            "Downloading:  36% 401M/1.12G [00:06<00:11, 61.7MB/s]\u001b[A\n",
            "Downloading:  37% 407M/1.12G [00:06<00:11, 63.0MB/s]\u001b[A\n",
            "Downloading:  37% 414M/1.12G [00:06<00:11, 63.8MB/s]\u001b[A\n",
            "Downloading:  38% 420M/1.12G [00:06<00:12, 55.4MB/s]\u001b[A\n",
            "Downloading:  38% 427M/1.12G [00:06<00:12, 57.3MB/s]\u001b[A\n",
            "Downloading:  39% 434M/1.12G [00:06<00:11, 60.7MB/s]\u001b[A\n",
            "Downloading:  39% 440M/1.12G [00:07<00:11, 61.0MB/s]\u001b[A\n",
            "Downloading:  40% 446M/1.12G [00:07<00:10, 62.1MB/s]\u001b[A\n",
            "Downloading:  41% 453M/1.12G [00:07<00:11, 58.5MB/s]\u001b[A\n",
            "Downloading:  41% 459M/1.12G [00:07<00:10, 60.2MB/s]\u001b[A\n",
            "Downloading:  42% 466M/1.12G [00:07<00:10, 61.3MB/s]\u001b[A\n",
            "Downloading:  42% 472M/1.12G [00:07<00:10, 59.8MB/s]\u001b[A\n",
            "Downloading:  43% 478M/1.12G [00:07<00:10, 61.4MB/s]\u001b[A\n",
            "Downloading:  44% 485M/1.12G [00:07<00:09, 63.8MB/s]\u001b[A\n",
            "Downloading:  44% 492M/1.12G [00:07<00:09, 63.0MB/s]\u001b[A\n",
            "Downloading:  45% 499M/1.12G [00:07<00:09, 65.6MB/s]\u001b[A\n",
            "Downloading:  45% 506M/1.12G [00:08<00:09, 67.1MB/s]\u001b[A\n",
            "Downloading:  46% 513M/1.12G [00:08<00:09, 66.2MB/s]\u001b[A\n",
            "Downloading:  47% 520M/1.12G [00:08<00:09, 65.3MB/s]\u001b[A\n",
            "Downloading:  47% 526M/1.12G [00:08<00:09, 65.4MB/s]\u001b[A\n",
            "Downloading:  48% 533M/1.12G [00:08<00:09, 62.5MB/s]\u001b[A\n",
            "Downloading:  48% 539M/1.12G [00:08<00:09, 62.0MB/s]\u001b[A\n",
            "Downloading:  49% 546M/1.12G [00:08<00:08, 63.4MB/s]\u001b[A\n",
            "Downloading:  49% 552M/1.12G [00:08<00:09, 60.5MB/s]\u001b[A\n",
            "Downloading:  50% 558M/1.12G [00:08<00:11, 50.2MB/s]\u001b[A\n",
            "Downloading:  51% 564M/1.12G [00:09<00:10, 53.2MB/s]\u001b[A\n",
            "Downloading:  51% 570M/1.12G [00:09<00:10, 54.1MB/s]\u001b[A\n",
            "Downloading:  52% 576M/1.12G [00:09<00:09, 56.5MB/s]\u001b[A\n",
            "Downloading:  52% 583M/1.12G [00:09<00:08, 59.9MB/s]\u001b[A\n",
            "Downloading:  53% 589M/1.12G [00:09<00:09, 58.1MB/s]\u001b[A\n",
            "Downloading:  53% 595M/1.12G [00:09<00:09, 56.7MB/s]\u001b[A\n",
            "Downloading:  54% 601M/1.12G [00:09<00:08, 58.3MB/s]\u001b[A\n",
            "Downloading:  54% 607M/1.12G [00:09<00:08, 58.8MB/s]\u001b[A\n",
            "Downloading:  55% 615M/1.12G [00:09<00:08, 61.9MB/s]\u001b[A\n",
            "Downloading:  56% 621M/1.12G [00:10<00:07, 62.6MB/s]\u001b[A\n",
            "Downloading:  56% 628M/1.12G [00:10<00:07, 65.6MB/s]\u001b[A\n",
            "Downloading:  57% 636M/1.12G [00:10<00:07, 67.5MB/s]\u001b[A\n",
            "Downloading:  58% 642M/1.12G [00:10<00:07, 64.4MB/s]\u001b[A\n",
            "Downloading:  58% 649M/1.12G [00:10<00:07, 63.3MB/s]\u001b[A\n",
            "Downloading:  59% 655M/1.12G [00:10<00:07, 57.6MB/s]\u001b[A\n",
            "Downloading:  59% 661M/1.12G [00:10<00:08, 54.5MB/s]\u001b[A\n",
            "Downloading:  60% 668M/1.12G [00:10<00:07, 57.9MB/s]\u001b[A\n",
            "Downloading:  60% 674M/1.12G [00:10<00:07, 57.9MB/s]\u001b[A\n",
            "Downloading:  61% 681M/1.12G [00:10<00:07, 60.4MB/s]\u001b[A\n",
            "Downloading:  62% 687M/1.12G [00:11<00:07, 60.1MB/s]\u001b[A\n",
            "Downloading:  62% 693M/1.12G [00:11<00:06, 60.7MB/s]\u001b[A\n",
            "Downloading:  63% 699M/1.12G [00:11<00:07, 57.5MB/s]\u001b[A\n",
            "Downloading:  63% 706M/1.12G [00:11<00:06, 60.1MB/s]\u001b[A\n",
            "Downloading:  64% 712M/1.12G [00:11<00:06, 60.1MB/s]\u001b[A\n",
            "Downloading:  64% 718M/1.12G [00:11<00:06, 57.8MB/s]\u001b[A\n",
            "Downloading:  65% 725M/1.12G [00:11<00:06, 61.0MB/s]\u001b[A\n",
            "Downloading:  66% 732M/1.12G [00:11<00:06, 63.9MB/s]\u001b[A\n",
            "Downloading:  66% 739M/1.12G [00:11<00:05, 63.6MB/s]\u001b[A\n",
            "Downloading:  67% 746M/1.12G [00:12<00:05, 66.7MB/s]\u001b[A\n",
            "Downloading:  68% 754M/1.12G [00:12<00:05, 69.1MB/s]\u001b[A\n",
            "Downloading:  68% 761M/1.12G [00:12<00:05, 67.3MB/s]\u001b[A\n",
            "Downloading:  69% 768M/1.12G [00:12<00:05, 66.8MB/s]\u001b[A\n",
            "Downloading:  69% 775M/1.12G [00:12<00:04, 68.3MB/s]\u001b[A\n",
            "Downloading:  70% 782M/1.12G [00:12<00:04, 67.0MB/s]\u001b[A\n",
            "Downloading:  71% 789M/1.12G [00:12<00:04, 69.4MB/s]\u001b[A\n",
            "Downloading:  71% 796M/1.12G [00:12<00:05, 57.7MB/s]\u001b[A\n",
            "Downloading:  72% 803M/1.12G [00:12<00:05, 60.1MB/s]\u001b[A\n",
            "Downloading:  73% 810M/1.12G [00:13<00:04, 62.4MB/s]\u001b[A\n",
            "Downloading:  73% 816M/1.12G [00:13<00:04, 61.0MB/s]\u001b[A\n",
            "Downloading:  74% 823M/1.12G [00:13<00:04, 62.0MB/s]\u001b[A\n",
            "Downloading:  74% 829M/1.12G [00:13<00:04, 61.9MB/s]\u001b[A\n",
            "Downloading:  75% 835M/1.12G [00:13<00:04, 59.5MB/s]\u001b[A\n",
            "Downloading:  75% 842M/1.12G [00:13<00:04, 60.7MB/s]\u001b[A\n",
            "Downloading:  76% 848M/1.12G [00:13<00:04, 61.8MB/s]\u001b[A\n",
            "Downloading:  77% 854M/1.12G [00:13<00:04, 62.0MB/s]\u001b[A\n",
            "Downloading:  77% 861M/1.12G [00:13<00:03, 64.6MB/s]\u001b[A\n",
            "Downloading:  78% 869M/1.12G [00:13<00:03, 66.4MB/s]\u001b[A\n",
            "Downloading:  78% 875M/1.12G [00:14<00:03, 64.9MB/s]\u001b[A\n",
            "Downloading:  79% 882M/1.12G [00:14<00:03, 66.8MB/s]\u001b[A\n",
            "Downloading:  80% 890M/1.12G [00:14<00:03, 68.3MB/s]\u001b[A\n",
            "Downloading:  80% 896M/1.12G [00:14<00:03, 64.8MB/s]\u001b[A\n",
            "Downloading:  81% 903M/1.12G [00:14<00:03, 66.3MB/s]\u001b[A\n",
            "Downloading:  82% 910M/1.12G [00:14<00:03, 66.7MB/s]\u001b[A\n",
            "Downloading:  82% 917M/1.12G [00:14<00:02, 67.3MB/s]\u001b[A\n",
            "Downloading:  83% 924M/1.12G [00:14<00:02, 66.7MB/s]\u001b[A\n",
            "Downloading:  83% 931M/1.12G [00:14<00:02, 67.3MB/s]\u001b[A\n",
            "Downloading:  84% 938M/1.12G [00:15<00:03, 59.1MB/s]\u001b[A\n",
            "Downloading:  85% 944M/1.12G [00:15<00:02, 58.7MB/s]\u001b[A\n",
            "Downloading:  85% 951M/1.12G [00:15<00:02, 61.9MB/s]\u001b[A\n",
            "Downloading:  86% 957M/1.12G [00:15<00:02, 59.9MB/s]\u001b[A\n",
            "Downloading:  86% 963M/1.12G [00:15<00:02, 60.8MB/s]\u001b[A\n",
            "Downloading:  87% 970M/1.12G [00:15<00:02, 62.8MB/s]\u001b[A\n",
            "Downloading:  88% 976M/1.12G [00:15<00:02, 58.5MB/s]\u001b[A\n",
            "Downloading:  88% 983M/1.12G [00:15<00:02, 59.7MB/s]\u001b[A\n",
            "Downloading:  89% 989M/1.12G [00:15<00:02, 61.5MB/s]\u001b[A\n",
            "Downloading:  89% 996M/1.12G [00:15<00:01, 62.2MB/s]\u001b[A\n",
            "Downloading:  90% 1.00G/1.12G [00:16<00:01, 62.3MB/s]\u001b[A\n",
            "Downloading:  90% 1.01G/1.12G [00:16<00:01, 65.1MB/s]\u001b[A\n",
            "Downloading:  91% 1.02G/1.12G [00:16<00:01, 67.1MB/s]\u001b[A\n",
            "Downloading:  92% 1.02G/1.12G [00:16<00:01, 65.5MB/s]\u001b[A\n",
            "Downloading:  92% 1.03G/1.12G [00:16<00:01, 67.4MB/s]\u001b[A\n",
            "Downloading:  93% 1.04G/1.12G [00:16<00:01, 68.4MB/s]\u001b[A\n",
            "Downloading:  94% 1.04G/1.12G [00:16<00:01, 67.1MB/s]\u001b[A\n",
            "Downloading:  94% 1.05G/1.12G [00:16<00:00, 68.1MB/s]\u001b[A\n",
            "Downloading:  95% 1.06G/1.12G [00:16<00:00, 63.7MB/s]\u001b[A\n",
            "Downloading:  95% 1.06G/1.12G [00:17<00:00, 64.3MB/s]\u001b[A\n",
            "Downloading:  96% 1.07G/1.12G [00:17<00:00, 64.6MB/s]\u001b[A\n",
            "Downloading:  97% 1.08G/1.12G [00:17<00:00, 60.4MB/s]\u001b[A\n",
            "Downloading:  97% 1.08G/1.12G [00:17<00:00, 55.4MB/s]\u001b[A\n",
            "Downloading:  98% 1.09G/1.12G [00:17<00:00, 58.1MB/s]\u001b[A\n",
            "Downloading:  98% 1.10G/1.12G [00:17<00:00, 57.8MB/s]\u001b[A\n",
            "Downloading:  99% 1.10G/1.12G [00:17<00:00, 61.4MB/s]\u001b[A\n",
            "Downloading: 100% 1.12G/1.12G [00:17<00:00, 62.5MB/s]\n",
            "cuda:0\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 1.1793396472930908\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.02\n",
            "  Pearson Correlation: 0.30\n",
            "\n",
            " 25% 1/4 [00:40<02:00, 40.23s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.9386360049247742\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.02\n",
            "  Pearson Correlation: 0.55\n",
            "\n",
            " 50% 2/4 [01:19<01:20, 40.01s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.7026215195655823\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.68\n",
            "\n",
            " 75% 3/4 [01:59<00:39, 39.87s/it]\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Total Train Loss = 0.5363127589225769\n",
            "#############    Validation Set Stats\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(99,)\n",
            "(99,)\n",
            "  L2 loss: 0.01\n",
            "  Pearson Correlation: 0.68\n",
            "\n",
            "100% 4/4 [02:38<00:00, 39.71s/it]\n",
            "0.6786932760582465\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "(184,)\n",
            "(184,)\n",
            "0.74349929069022\n",
            "9it [19:50, 132.24s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRgMSr7RRhaj",
        "outputId": "de0a53be-8812-4551-e704-38d94c978f54"
      },
      "source": [
        "%cd /content/CS60075-Team-2-Task-1/\n",
        "!git status"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CS60075-Team-2-Task-1\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoNwLisqMNhe",
        "outputId": "59919c9e-2c2b-478b-a948-b2bc878eb4ac"
      },
      "source": [
        "%cd /content/CS60075-Team-2-Task-1/\n",
        "!git add .\n",
        "!git config --global user.email \"nandyabhilash@gmail.com\"\n",
        "!git config --global user.name \"abhi1nandy2\"\n",
        "!git commit -m  \"Added submission\"\n",
        "!git push origin main"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[main 83862cf] Added submission\n",
            " 2 files changed, 184 insertions(+)\n",
            " create mode 100644 CodaLab_submissions/multi_sub.csv\n",
            " create mode 100644 CodaLab_submissions/multi_sub.zip\n",
            "Counting objects: 5, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 11.77 KiB | 11.77 MiB/s, done.\n",
            "Total 5 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/abhi1nandy2/CS60075-Team-2-Task-1.git\n",
            "   4781424..83862cf  main -> main\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FEfJVaxNc3J"
      },
      "source": [
        "## Evaluation of fine-tuned transformer models' outputs using average and max pooling\n",
        "\n",
        "> NOTE: Results might differ a bit, if you again train, due to the random nature of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_1l50E8J93A"
      },
      "source": [
        "from itertools import compress, product\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def combinations(items):\n",
        "    return ( set(compress(items,mask)) for mask in product(*[[0,1]]*len(items)) )\n",
        "    # alternative:                      ...in product([0,1], repeat=len(items)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Noqets2-NA9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f353f13f-a884-4e56-dc8f-c8024022f672"
      },
      "source": [
        "from scipy.stats import pearsonr \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "mode = \"single\"\n",
        "\n",
        "#using N predictions - avg\n",
        "\n",
        "df3 = pd.read_csv('/content/lcp_{}_test.tsv'.format(mode), delimiter = \"\\t\", quoting = csv.QUOTE_NONE, encoding = 'utf-8', keep_default_na=False)\n",
        "\n",
        "all_num_list = [1,2,3,4,5,6,7,8,9]\n",
        "combs = list(combinations(all_num_list))\n",
        "\n",
        "combs = [list(item) for item in combs if len(item) != 0]\n",
        "print(len(combs), 2**(len(all_num_list)) - 1)\n",
        "\n",
        "def get_avg_pearsonr(num_list):\n",
        "\n",
        "    for idx_, num in enumerate(num_list):\n",
        "        if mode == \"single\":\n",
        "            df_pred = pd.read_csv(\"/content/CS60075-Team-2-Task-1/our_approach_results/test_sub_transf_{}_df.csv\".format(num), header = None)\n",
        "        else:\n",
        "            df_pred = pd.read_csv(\"/content/CS60075-Team-2-Task-1/our_approach_results/test_sub_multi_transf_{}_df.csv\".format(num), header = None)\n",
        "\n",
        "        if idx_ == 0:\n",
        "            pred = np.array(df_pred[1].tolist())\n",
        "        else:\n",
        "            pred += np.array(df_pred[1].tolist())\n",
        "\n",
        "    pred = pred/len(num_list)\n",
        "\n",
        "    return pearsonr(pred, df3['complexity'].values)[0], mean_squared_error(df3['complexity'].values, pred)\n",
        "\n",
        "max_pearson_score = 0\n",
        "\n",
        "for num_list in combs:\n",
        "    score, mse = get_avg_pearsonr(num_list)\n",
        "    if score > max_pearson_score:\n",
        "        max_pearson_score = score\n",
        "        best_combination = num_list\n",
        "        best_mse = mse\n",
        "\n",
        "print(\"For Single Word:\")\n",
        "\n",
        "print(\"BERT-BASE-UNCASED\")\n",
        "print(get_avg_pearsonr([1]))\n",
        "print(\"BIBLE+EUROPARL+BIOMED (AVG.)\")\n",
        "print(get_avg_pearsonr([3,4,8]))\n",
        "print(\"BEST COMBINATION (AVG.)\")\n",
        "print(max_pearson_score, best_mse, best_combination)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "511 511\n",
            "For Single Word:\n",
            "BERT-BASE-UNCASED\n",
            "(0.7650780116283583, 0.0070086787816512255)\n",
            "BIBLE+EUROPARL+BIOMED (AVG.)\n",
            "(0.7531109102943394, 0.007511880093797559)\n",
            "BEST COMBINATION (AVG.)\n",
            "0.7844852289871022 0.006590037238785794 [1, 4, 5, 7, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBzSZifBvgVH"
      },
      "source": [
        "# For CodaLab Submission, we use \"BEST COMBINATION (AVG.)\"\n",
        "if os.path.exists(\"CodaLab_submissions\") == False:\n",
        "    os.mkdir(\"CodaLab_submissions\")\n",
        "\n",
        "def get_submission(num_list, mode):\n",
        "    for idx_, num in enumerate(num_list):\n",
        "        if mode == \"single\":\n",
        "            df_pred = pd.read_csv(\"/content/CS60075-Team-2-Task-1/our_approach_results/test_sub_transf_{}_df.csv\".format(num), header = None)\n",
        "        else:\n",
        "            df_pred = pd.read_csv(\"/content/CS60075-Team-2-Task-1/our_approach_results/test_sub_multi_transf_{}_df.csv\".format(num), header = None)\n",
        "\n",
        "        if idx_ == 0:\n",
        "            pred = np.array(df_pred[1].tolist())\n",
        "        else:\n",
        "            pred += np.array(df_pred[1].tolist())\n",
        "\n",
        "    pred = pred/len(num_list)\n",
        "    df_pred[1] = pred\n",
        "    df_pred.to_csv(\"CodaLab_submissions/{}_sub.csv\".format(mode), index = False, header = False)\n",
        "    os.chdir(\"CodaLab_submissions\")\n",
        "    os.system(\"zip {}_sub {}_sub.csv\".format(mode, mode))\n",
        "    os.chdir(\"../\")\n",
        "\n",
        "mode = 'single'\n",
        "get_submission([1,4,5,7,9], mode)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYzu5vNtlqvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f473b1-6578-42b4-ae03-f3f771bd1918"
      },
      "source": [
        "#using N predictions - max\n",
        "def get_max_pearsonr(num_list):\n",
        "\n",
        "    for idx_, num in enumerate(num_list):\n",
        "        if mode == \"single\":\n",
        "            df_pred = pd.read_csv(\"/content/CS60075-Team-2-Task-1/our_approach_results/test_sub_transf_{}_df.csv\".format(num), header = None)\n",
        "        else:\n",
        "            df_pred = pd.read_csv(\"/content/CS60075-Team-2-Task-1/our_approach_results/test_sub_multi_transf_{}_df.csv\".format(num), header = None)\n",
        "\n",
        "        if idx_ == 0:\n",
        "            pred = np.array(df_pred[1].tolist())\n",
        "        else:\n",
        "            pred = np.maximum(pred, np.array(df_pred[1].tolist()))\n",
        "\n",
        "    return pearsonr(pred, df3['complexity'].values)[0], mean_squared_error(df3['complexity'].values, pred)\n",
        "\n",
        "max_pearson_score = 0\n",
        "\n",
        "for num_list in combs:\n",
        "    score, mse = get_max_pearsonr(num_list)\n",
        "    if score > max_pearson_score:\n",
        "        max_pearson_score = score\n",
        "        best_combination = num_list\n",
        "        best_mse = mse\n",
        "\n",
        "print(\"For Single Word:\")\n",
        "print(\"BIBLE+EUROPARL+BIOMED (MAX.)\")\n",
        "print(get_max_pearsonr([3,4,8]))\n",
        "print(\"BEST COMBINATION (MAX.)\")\n",
        "print(max_pearson_score, best_mse, best_combination)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Single Word:\n",
            "BIBLE+EUROPARL+BIOMED (MAX.)\n",
            "(0.7506306158220971, 0.0075779619399341126)\n",
            "BEST COMBINATION (MAX.)\n",
            "0.7741643933910725 0.007095375229286552 [1, 4, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtaVxs7PYmIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fd5f8f-81ba-4d29-9fd4-86f4b06be94d"
      },
      "source": [
        "from scipy.stats import pearsonr \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "mode = \"multi\"\n",
        "\n",
        "#using N predictions - avg\n",
        "\n",
        "df3 = pd.read_csv('/content/lcp_{}_test.tsv'.format(mode), delimiter = \"\\t\", quoting = csv.QUOTE_NONE, encoding = 'utf-8', keep_default_na=False)\n",
        "\n",
        "all_num_list = [1,2,3,4,5,6,7,8,9]\n",
        "combs = list(combinations(all_num_list))\n",
        "\n",
        "combs = [list(item) for item in combs if len(item) != 0]\n",
        "print(len(combs), 2**(len(all_num_list)) - 1)\n",
        "\n",
        "max_pearson_score = 0\n",
        "\n",
        "for num_list in combs:\n",
        "    score, mse = get_avg_pearsonr(num_list)\n",
        "    if score > max_pearson_score:\n",
        "        max_pearson_score = score\n",
        "        best_combination = num_list\n",
        "        best_mse = mse\n",
        "\n",
        "print(\"For MWE:\")\n",
        "\n",
        "print(\"BERT-BASE-UNCASED\")\n",
        "print(get_avg_pearsonr([1]))\n",
        "print(\"BIBLE+EUROPARL+BIOMED (AVG.)\")\n",
        "print(get_avg_pearsonr([3,4,8]))\n",
        "print(\"BEST COMBINATION (AVG.)\")\n",
        "print(max_pearson_score, best_mse, best_combination)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "511 511\n",
            "For MWE:\n",
            "BERT-BASE-UNCASED\n",
            "(0.7909368193711438, 0.009047349532241303)\n",
            "BIBLE+EUROPARL+BIOMED (AVG.)\n",
            "(0.7978236514863208, 0.009563137233250642)\n",
            "BEST COMBINATION (AVG.)\n",
            "0.8357710734659074 0.007806866562567975 [8, 9, 2, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAmpiEKUu_fh",
        "outputId": "1a5c3f7a-53e1-4ec0-c08e-e656b2ade1ee"
      },
      "source": [
        "#using N predictions - max\n",
        "\n",
        "max_pearson_score = 0\n",
        "\n",
        "for num_list in combs:\n",
        "    score, mse = get_max_pearsonr(num_list)\n",
        "    if score > max_pearson_score:\n",
        "        max_pearson_score = score\n",
        "        best_combination = num_list\n",
        "        best_mse = mse\n",
        "\n",
        "print(\"For MWE:\")\n",
        "print(\"BIBLE+EUROPARL+BIOMED (MAX.)\")\n",
        "print(get_max_pearsonr([3,4,8]))\n",
        "print(\"BEST COMBINATION (MAX.)\")\n",
        "print(max_pearson_score, best_mse, best_combination)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For MWE:\n",
            "BIBLE+EUROPARL+BIOMED (MAX.)\n",
            "(0.7880711274730215, 0.009163948196757494)\n",
            "BEST COMBINATION (MAX.)\n",
            "0.818642109361608 0.00905053839308693 [1, 2, 3, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVRMkpyq49be"
      },
      "source": [
        "# For CodaLab Submission, we use \"BEST COMBINATION (AVG.)\"\n",
        "if os.path.exists(\"CodaLab_submissions\") == False:\n",
        "    os.mkdir(\"CodaLab_submissions\")\n",
        "\n",
        "mode = 'multi'\n",
        "get_submission([8,9,2,6], mode)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7yQuS55NLG2"
      },
      "source": [
        "##Baselines\n",
        "\n",
        "Using a regressor (linear, SVR or boosting based) over the following features -\n",
        "\n",
        "1.  Using several [huggingface models](https://huggingface.co/models), which were pre-trained on either Wikipedia, one of the three corpora mentioned in [CompLex Paper](https://arxiv.org/pdf/2003.07008.pdf), and also other domains like scientific papers, Legal docs, financial docs, political docs etc.\n",
        "\n",
        "> Motivation: Several annotators annotate the complexity scores. We can simulate this by using many language models pre-trained on several corpora\n",
        "\n",
        "> Let us consider a pre-trained transformer language model `M`. Given a sentence and the tokens in the sentence whose complexity is to be found, we mask each such token, and given the masked sentence as input, get the probability of predicting the actual token, and multiply probabilities for all tokens. This can be used as a feature.\n",
        "\n",
        "> E.g. Sentence - \"I just love mowing the lawn with a lawn mower.\"\n",
        "       Tokens - \"lawn mower\"\n",
        "       First, 'lawn' is masked, and probability to predict 'lawn' is found (P1), same for mower (P2). Then, resultant feature value = `P1 * P2`\n",
        "\n",
        "\n",
        "2.   Handcrafted features - word frequency (using `word_freq` library), word length, number of syllables are the most significant. Some others include word readability, sentence readability\n",
        "\n",
        "3. GloVe embeddings of the tokens - `50 dim` and `100 dim` embeddings are used.\n",
        "\n",
        "4. Corpus to which the sentence belongs (categorical feature - one hot)\n",
        "\n",
        "5. Complexity of words in a previous CWI task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21x2syMl-U9y"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "mode = 'single' # just change this to 'multi' for the other set of baselines\n",
        "df1 = pd.read_csv(\"/content/train/lcp_{}_train.tsv\".format(mode), delimiter = \"\\t\", quoting = csv.QUOTE_NONE, encoding = 'utf-8', keep_default_na=False)\n",
        "df2 = pd.read_csv(\"/content/train/lcp_{}_trial.tsv\".format(mode), delimiter = \"\\t\", quoting = csv.QUOTE_NONE, encoding = 'utf-8', keep_default_na=False)\n",
        "df3 = pd.read_csv(\"/content/lcp_{}_test.tsv\".format(mode), delimiter = \"\\t\", quoting = csv.QUOTE_NONE, encoding = 'utf-8', keep_default_na=False)\n",
        "y_train = df1['complexity']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpWIonCcvYB0"
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_trial = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "\n",
        "def add_word_len(df_orig, df_feats):\n",
        "    if \"word_len\" in df_feats.columns.tolist():\n",
        "        return df_feats\n",
        "    df_feats['word_len'] = df_orig['token'].apply(lambda x: len(x))\n",
        "    return df_feats\n",
        " \n",
        "df_train = add_word_len(df1, df_train)\n",
        "df_trial = add_word_len(df2, df_trial)\n",
        "df_test = add_word_len(df3, df_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5AN0oV26StW"
      },
      "source": [
        "import syllables\n",
        " \n",
        "def add_word_num_syll(df_orig, df_feats):\n",
        "    if \"num_syll\" in df_feats.columns.tolist():\n",
        "        return df_feats\n",
        "    df_feats['num_syll'] = df_orig['token'].apply(lambda x: syllables.estimate(x))\n",
        "    return df_feats\n",
        " \n",
        "df_train = add_word_num_syll(df1, df_train)\n",
        "df_trial = add_word_num_syll(df2, df_trial)\n",
        "df_test = add_word_num_syll(df3, df_test)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5iB-Lpqa47I"
      },
      "source": [
        "from wordfreq import word_frequency\n",
        " \n",
        "def add_word_freq(df_orig, df_feats):\n",
        "    if \"word_freq\" in df_feats.columns.tolist():\n",
        "        return df_feats\n",
        "    df_feats['word_freq'] = df_orig['token'].apply(lambda x: word_frequency(x, 'en'))\n",
        "    return df_feats\n",
        "df_train = add_word_freq(df1, df_train)\n",
        "df_trial = add_word_freq(df2, df_trial)\n",
        "df_test = add_word_freq(df3, df_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jny5QXjfWtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a34d8d9-9169-4fb2-a713-24530728f0cf"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "load_glove = True\n",
        "import os\n",
        "if load_glove:\n",
        "    if os.path.exists('/content/glove.6B.50d.txt') == False:\n",
        "        os.system(\"wget http://nlp.stanford.edu/data/glove.6B.zip\")\n",
        "        os.system(\"unzip glove.6B.zip\")\n",
        "        os.system(\"rm glove.6B.zip\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfSrmzF_hRNF"
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "if load_glove:\n",
        "    embeddings_dict = {}\n",
        "    with open(\"glove.6B.50d.txt\", 'r') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], \"float32\")\n",
        "            embeddings_dict[word] = vector\n",
        " \n",
        "def glove_emb(x):\n",
        "    sum = np.array([0.]*50)\n",
        "    for t in x:\n",
        "        if t in embeddings_dict:\n",
        "            sum+=np.array(embeddings_dict[t].tolist())\n",
        "    return sum\n",
        " \n",
        "def add_word_glove(df_orig, df_feats):\n",
        " \n",
        "    for feat in df_feats.columns.tolist():\n",
        "        if 'glove_' in feat:\n",
        "            return df_feats\n",
        " \n",
        "    dim = 50\n",
        "    glove_emb_list = []\n",
        " \n",
        "    tok_list = df_orig['token'].apply(lambda x: x.split(\" \"))\n",
        " \n",
        "    for tok in tok_list:\n",
        "        glove_emb_list.append(glove_emb(tok))\n",
        " \n",
        "    glove_emb_arr = np.array(glove_emb_list)    \n",
        " \n",
        "    for i in range(dim):\n",
        "        df_feats['glove_{}'.format(i)] = glove_emb_arr[:, i].tolist()\n",
        " \n",
        "    return df_feats\n",
        " \n",
        "df_train = add_word_glove(df1, df_train)\n",
        "df_trial = add_word_glove(df2, df_trial)\n",
        "df_test = add_word_glove(df3, df_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOO-w1H0nRA1"
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "if load_glove:\n",
        "    embeddings_dict = {}\n",
        "    with open(\"glove.6B.100d.txt\", 'r') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], \"float32\")\n",
        "            embeddings_dict[word] = vector\n",
        " \n",
        "    def glove100_emb(x):\n",
        "        sum = np.array([0.]*100)\n",
        "        for t in x:\n",
        "            if t in embeddings_dict:\n",
        "                sum+=np.array(embeddings_dict[t].tolist())\n",
        "        return sum\n",
        " \n",
        "def add_word_glove100(df_orig, df_feats):\n",
        " \n",
        "    for feat in df_feats.columns.tolist():\n",
        "        if 'glove100_' in feat:\n",
        "            return df_feats\n",
        " \n",
        "    dim = 100\n",
        "    glove_emb_list = []\n",
        " \n",
        "    tok_list = df_orig['token'].apply(lambda x: x.split(\" \"))\n",
        " \n",
        "    for tok in tok_list:\n",
        "        glove_emb_list.append(glove100_emb(tok))\n",
        " \n",
        "    glove_emb_arr = np.array(glove_emb_list)    \n",
        " \n",
        "    for i in range(dim):\n",
        "        df_feats['glove100_{}'.format(i)] = glove_emb_arr[:, i].tolist()\n",
        " \n",
        "    return df_feats\n",
        " \n",
        "df_train = add_word_glove100(df1, df_train)\n",
        "df_trial = add_word_glove100(df2, df_trial)\n",
        "df_test = add_word_glove100(df3, df_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgEHLVTxpU3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39a6d87-8583-4f08-ac9b-bbb66c2a6ab0"
      },
      "source": [
        "corpus_type_dict = {'bible':1, 'biomed': 2, 'europarl': 3}\n",
        " \n",
        "def add_corpus_type_util(df_orig, df_feats):\n",
        "    for col in df_orig.columns:\n",
        "        if 'corpus' in col:\n",
        "            print(col)\n",
        "            corpus_col = col\n",
        "            break\n",
        " \n",
        "    for i in range(df_feats.shape[0]):\n",
        "        id_ = corpus_type_dict[df_orig[corpus_col][i]]\n",
        "        df_feats['corpus_type_{}'.format(id_)][i] = 1\n",
        "    return df_feats\n",
        " \n",
        "def add_corpus_type(df_orig, df_feats):\n",
        "    # for col in df_feats.columns.tolist():\n",
        "        # if \"corpus_type\" in col:\n",
        "        #     return df_feats\n",
        " \n",
        "    df_feats['corpus_type_1'] = 0\n",
        "    df_feats['corpus_type_2'] = 0\n",
        "    df_feats['corpus_type_3'] = 0\n",
        "    df_feats = add_corpus_type_util(df_orig, df_feats)\n",
        "    return df_feats\n",
        " \n",
        "df_train = add_corpus_type(df1, df_train)\n",
        "df_trial = add_corpus_type(df2, df_trial)\n",
        "df_test = add_corpus_type(df3, df_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "subcorpus\n",
            "corpus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GUgIXEphYuo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc8c409-19cb-4be7-875b-6e7fb48baa50"
      },
      "source": [
        "print(df_train.shape, df_trial.shape, df_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7662, 156) (421, 156) (917, 156)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlMCFKFbN6rN"
      },
      "source": [
        "## Regression followed by evaluation of baselines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYy1eu-8aSAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c979344-a6cd-4a35-b74b-a389f8227f2e"
      },
      "source": [
        "#@title Regression model\n",
        "# all_model_names = dict_['all_models']\n",
        "# df_train = rearrange_cols(df_train)\n",
        "# df_trial = rearrange_cols(df_trial)\n",
        " \n",
        "print(df_train.shape, df_trial.shape)\n",
        " \n",
        "import numpy as np\n",
        "\n",
        "#all other regression kodles gave inferior results. Hence, we only report variants of only xgboost. \n",
        "reg_model = \"xgb\" #@param [\"lin_reg\", \"lin_reg_SS\", \"svr\", \"lars\", \"bayesian_ridge\", \"grad_boost\", \"xgb\", \"lightgbm\", \"catboost\"]\n",
        "# num_feats =  24#@param {type:\"integer\"}\n",
        "# omit = \"15,18,1,9,4,16,10,13,14,20,22,23,24,25,26,28,29,30,33,34,35,37,38,39,40,41,42,43,46\" #@param {type:\"string\"}\n",
        "# omit_all = False #@param {type:\"boolean\"}\n",
        " \n",
        "#15,18,1,9,4,16,10,13,14,20,22,23,24,25,26,28,29,30,33,34,35,37,38,39,40,41,42,43,46\n",
        " \n",
        "is_word_len = True\n",
        "is_num_syll = True\n",
        "is_word_freq = True\n",
        "\n",
        "is_glove = False\n",
        "is_glove100 = False\n",
        "is_corpus_type = True\n",
        " \n",
        "cols = df_train.columns.tolist()\n",
        " \n",
        "# omit_list = [\"feat_\" + it_ for it_ in omit.split(\",\")]\n",
        " \n",
        "# if omit_all:\n",
        "#     omit_list = np.arange(len(all_model_names)).tolist()\n",
        "#     omit_list = [\"feat_\" + str(it_) for it_ in omit_list]\n",
        " \n",
        "omit_list = []\n",
        "\n",
        "if is_word_len == False:\n",
        "    omit_list.append('word_len')\n",
        " \n",
        "if is_num_syll == False:\n",
        "    omit_list.append('num_syll')\n",
        " \n",
        "if is_word_freq == False:\n",
        "    omit_list.append('word_freq')\n",
        " \n",
        "if is_corpus_type == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'corpus_type_' in it_])\n",
        " \n",
        "if is_glove == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'glove_' in it_])\n",
        " \n",
        "if is_glove100 == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'glove100_' in it_])\n",
        " \n",
        "cols = [it_ for it_ in cols if it_ not in omit_list]\n",
        " \n",
        "# print(cols)\n",
        " \n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor, plot_importance\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Lars, BayesianRidge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        " \n",
        "if reg_model == 'lin_reg':\n",
        "    reg = LinearRegression(normalize = True).fit(df_train[cols], y_train)\n",
        "elif reg_model == \"lin_reg_SS\":\n",
        "    reg = make_pipeline(StandardScaler(), LinearRegression(normalize = False)).fit(df_train[cols], y_train)\n",
        "elif reg_model == \"lars\":\n",
        "    reg = Lars().fit(df_train[cols], y_train) \n",
        "elif reg_model == \"bayesian_ridge\":\n",
        "    reg = BayesianRidge().fit(df_train[cols], y_train) \n",
        "elif reg_model == \"grad_boost\":\n",
        "    reg = GradientBoostingRegressor(random_state = 0).fit(df_train[cols], y_train) \n",
        "elif reg_model == 'xgb':\n",
        "    reg = XGBRegressor(objective='reg:squarederror').fit(df_train[cols], y_train)\n",
        "elif reg_model == 'lightgbm':\n",
        "    reg = LGBMRegressor().fit(df_train[cols], y_train)\n",
        "elif reg_model == 'catboost':\n",
        "    reg = CatBoostRegressor(verbose=0, n_estimators=100).fit(df_train[cols], y_train)\n",
        "else:\n",
        "    reg = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2)).fit(df_train[cols], y_train)\n",
        "\n",
        "print(\"Training for {}\".format(mode))\n",
        "\n",
        "print(\"xgb-A\")\n",
        "print(reg.score(df_train[cols], y_train))\n",
        "\n",
        "\n",
        "is_glove = True\n",
        "is_glove100 = True\n",
        "\n",
        "cols2 = df_train.columns.tolist()\n",
        "\n",
        "omit_list = []\n",
        "\n",
        "if is_word_len == False:\n",
        "    omit_list.append('word_len')\n",
        " \n",
        "if is_num_syll == False:\n",
        "    omit_list.append('num_syll')\n",
        " \n",
        "if is_word_freq == False:\n",
        "    omit_list.append('word_freq')\n",
        " \n",
        "if is_corpus_type == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'corpus_type_' in it_])\n",
        " \n",
        "if is_glove == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'glove_' in it_])\n",
        " \n",
        "if is_glove100 == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'glove100_' in it_])\n",
        " \n",
        "cols2 = [it_ for it_ in cols2 if it_ not in omit_list]\n",
        "\n",
        "if reg_model == 'lin_reg':\n",
        "    reg2 = LinearRegression(normalize = True).fit(df_train[cols2], y_train)\n",
        "elif reg_model == \"lin_reg_SS\":\n",
        "    reg2 = make_pipeline(StandardScaler(), LinearRegression(normalize = False)).fit(df_train[cols2], y_train)\n",
        "elif reg_model == \"lars\":\n",
        "    reg2 = Lars().fit(df_train[cols2], y_train) \n",
        "elif reg_model == \"bayesian_ridge\":\n",
        "    reg2 = BayesianRidge().fit(df_train[cols2], y_train) \n",
        "elif reg_model == \"grad_boost\":\n",
        "    reg2 = GradientBoostingRegressor(random_state = 0).fit(df_train[cols2], y_train) \n",
        "elif reg_model == 'xgb':\n",
        "    reg2 = XGBRegressor(objective='reg:squarederror').fit(df_train[cols2], y_train)\n",
        "elif reg_model == 'lightgbm':\n",
        "    reg2 = LGBMRegressor().fit(df_train[cols2], y_train)\n",
        "elif reg_model == 'catboost':\n",
        "    reg2 = CatBoostRegressor(verbose=0, n_estimators=100).fit(df_train[cols2], y_train)\n",
        "else:\n",
        "    reg2 = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2)).fit(df_train[cols2], y_train)\n",
        "\n",
        "print(\"xgb-B\")\n",
        "print(reg2.score(df_train[cols2], y_train))\n",
        "\n",
        "\n",
        "# (7662, 156) (421, 156)\n",
        "# # Training for single\n",
        "# xgb-A\n",
        "# 0.5671758212308615\n",
        "# xgb-B\n",
        "# 0.6584015081722792\n",
        "\n",
        "# (1517, 156) (99, 156)\n",
        "# Training for multi\n",
        "# xgb-A\n",
        "# 0.6351654987267665\n",
        "# xgb-B\n",
        "# 0.8110159696453578"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1517, 156) (99, 156)\n",
            "Training for multi\n",
            "xgb-A\n",
            "0.6351654987267665\n",
            "xgb-B\n",
            "0.8110159696453578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgm8_LWX-kCq"
      },
      "source": [
        "pred_trial = reg.predict(df_trial[cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZtXd4tA-vFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf160981-17a2-4b78-be4d-3db28c80d4f2"
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "pearsonr(pred_trial, df2['complexity'])\n",
        "# xgb-A\n",
        "# single word - (0.7541664516924756, 1.5292613326833054e-78)\n",
        "# MWE - (0.6616908776591793, 8.906698459235827e-14)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6616908776591793, 8.906698459235827e-14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG_XEdMEgpAZ"
      },
      "source": [
        "## single xgb-A\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idon1RJ60rLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b8d9db9e-5688-4e39-9f31-1623a6e118f9"
      },
      "source": [
        "if reg_model == \"xgb\":\n",
        "    plot_importance(reg, height=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OgCUqtDKAtm"
      },
      "source": [
        "def rearrange_cols(df):\n",
        "    cols = df.columns.tolist()\n",
        "    new_cols = []\n",
        "    for col in cols:\n",
        "        if 'feat_' in col:\n",
        "            new_cols.append(col)\n",
        "\n",
        "    for col in cols:\n",
        "        if 'feat_' not in col:\n",
        "            new_cols.append(col)    \n",
        "\n",
        "    df = df[new_cols]\n",
        "\n",
        "    dict_ = {}\n",
        "\n",
        "    for i, col in enumerate(new_cols):\n",
        "        if 'feat_' in col:\n",
        "            dict_[col] = 'feat_' + str(i)\n",
        "        else:\n",
        "            dict_[col] = col\n",
        "\n",
        "    print(dict_)\n",
        "    df = df.rename(columns = dict_)\n",
        "    return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAfgo9NRVoBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96fb5b8f-0ff0-4d1a-c98f-55c3564de075"
      },
      "source": [
        "print(\"{}: For xgb-A during testing \".format(mode))\n",
        "df_test = rearrange_cols(df_test)\n",
        "pred_test = reg.predict(df_test[cols])\n",
        "print(\"Pearson Corr\")\n",
        "print(pearsonr(pred_test, df3['complexity'])[0])\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"MSE\")\n",
        "print(mean_squared_error(df3['complexity'], pred_test))\n",
        "\n",
        "# single: For xgb-A during testing \n",
        "# {'word_len': 'word_len', 'num_syll': 'num_syll', 'word_freq': 'word_freq', 'glove_0': 'glove_0', 'glove_1': 'glove_1', 'glove_2': 'glove_2', 'glove_3': 'glove_3', 'glove_4': 'glove_4', 'glove_5': 'glove_5', 'glove_6': 'glove_6', 'glove_7': 'glove_7', 'glove_8': 'glove_8', 'glove_9': 'glove_9', 'glove_10': 'glove_10', 'glove_11': 'glove_11', 'glove_12': 'glove_12', 'glove_13': 'glove_13', 'glove_14': 'glove_14', 'glove_15': 'glove_15', 'glove_16': 'glove_16', 'glove_17': 'glove_17', 'glove_18': 'glove_18', 'glove_19': 'glove_19', 'glove_20': 'glove_20', 'glove_21': 'glove_21', 'glove_22': 'glove_22', 'glove_23': 'glove_23', 'glove_24': 'glove_24', 'glove_25': 'glove_25', 'glove_26': 'glove_26', 'glove_27': 'glove_27', 'glove_28': 'glove_28', 'glove_29': 'glove_29', 'glove_30': 'glove_30', 'glove_31': 'glove_31', 'glove_32': 'glove_32', 'glove_33': 'glove_33', 'glove_34': 'glove_34', 'glove_35': 'glove_35', 'glove_36': 'glove_36', 'glove_37': 'glove_37', 'glove_38': 'glove_38', 'glove_39': 'glove_39', 'glove_40': 'glove_40', 'glove_41': 'glove_41', 'glove_42': 'glove_42', 'glove_43': 'glove_43', 'glove_44': 'glove_44', 'glove_45': 'glove_45', 'glove_46': 'glove_46', 'glove_47': 'glove_47', 'glove_48': 'glove_48', 'glove_49': 'glove_49', 'glove100_0': 'glove100_0', 'glove100_1': 'glove100_1', 'glove100_2': 'glove100_2', 'glove100_3': 'glove100_3', 'glove100_4': 'glove100_4', 'glove100_5': 'glove100_5', 'glove100_6': 'glove100_6', 'glove100_7': 'glove100_7', 'glove100_8': 'glove100_8', 'glove100_9': 'glove100_9', 'glove100_10': 'glove100_10', 'glove100_11': 'glove100_11', 'glove100_12': 'glove100_12', 'glove100_13': 'glove100_13', 'glove100_14': 'glove100_14', 'glove100_15': 'glove100_15', 'glove100_16': 'glove100_16', 'glove100_17': 'glove100_17', 'glove100_18': 'glove100_18', 'glove100_19': 'glove100_19', 'glove100_20': 'glove100_20', 'glove100_21': 'glove100_21', 'glove100_22': 'glove100_22', 'glove100_23': 'glove100_23', 'glove100_24': 'glove100_24', 'glove100_25': 'glove100_25', 'glove100_26': 'glove100_26', 'glove100_27': 'glove100_27', 'glove100_28': 'glove100_28', 'glove100_29': 'glove100_29', 'glove100_30': 'glove100_30', 'glove100_31': 'glove100_31', 'glove100_32': 'glove100_32', 'glove100_33': 'glove100_33', 'glove100_34': 'glove100_34', 'glove100_35': 'glove100_35', 'glove100_36': 'glove100_36', 'glove100_37': 'glove100_37', 'glove100_38': 'glove100_38', 'glove100_39': 'glove100_39', 'glove100_40': 'glove100_40', 'glove100_41': 'glove100_41', 'glove100_42': 'glove100_42', 'glove100_43': 'glove100_43', 'glove100_44': 'glove100_44', 'glove100_45': 'glove100_45', 'glove100_46': 'glove100_46', 'glove100_47': 'glove100_47', 'glove100_48': 'glove100_48', 'glove100_49': 'glove100_49', 'glove100_50': 'glove100_50', 'glove100_51': 'glove100_51', 'glove100_52': 'glove100_52', 'glove100_53': 'glove100_53', 'glove100_54': 'glove100_54', 'glove100_55': 'glove100_55', 'glove100_56': 'glove100_56', 'glove100_57': 'glove100_57', 'glove100_58': 'glove100_58', 'glove100_59': 'glove100_59', 'glove100_60': 'glove100_60', 'glove100_61': 'glove100_61', 'glove100_62': 'glove100_62', 'glove100_63': 'glove100_63', 'glove100_64': 'glove100_64', 'glove100_65': 'glove100_65', 'glove100_66': 'glove100_66', 'glove100_67': 'glove100_67', 'glove100_68': 'glove100_68', 'glove100_69': 'glove100_69', 'glove100_70': 'glove100_70', 'glove100_71': 'glove100_71', 'glove100_72': 'glove100_72', 'glove100_73': 'glove100_73', 'glove100_74': 'glove100_74', 'glove100_75': 'glove100_75', 'glove100_76': 'glove100_76', 'glove100_77': 'glove100_77', 'glove100_78': 'glove100_78', 'glove100_79': 'glove100_79', 'glove100_80': 'glove100_80', 'glove100_81': 'glove100_81', 'glove100_82': 'glove100_82', 'glove100_83': 'glove100_83', 'glove100_84': 'glove100_84', 'glove100_85': 'glove100_85', 'glove100_86': 'glove100_86', 'glove100_87': 'glove100_87', 'glove100_88': 'glove100_88', 'glove100_89': 'glove100_89', 'glove100_90': 'glove100_90', 'glove100_91': 'glove100_91', 'glove100_92': 'glove100_92', 'glove100_93': 'glove100_93', 'glove100_94': 'glove100_94', 'glove100_95': 'glove100_95', 'glove100_96': 'glove100_96', 'glove100_97': 'glove100_97', 'glove100_98': 'glove100_98', 'glove100_99': 'glove100_99', 'corpus_type_1': 'corpus_type_1', 'corpus_type_2': 'corpus_type_2', 'corpus_type_3': 'corpus_type_3'}\n",
        "# Pearson Corr\n",
        "# 0.7183345614030864\n",
        "# MSE\n",
        "# 0.007844652346026881\n",
        "\n",
        "# multi: For xgb-A during testing \n",
        "# {'word_len': 'word_len', 'num_syll': 'num_syll', 'word_freq': 'word_freq', 'glove_0': 'glove_0', 'glove_1': 'glove_1', 'glove_2': 'glove_2', 'glove_3': 'glove_3', 'glove_4': 'glove_4', 'glove_5': 'glove_5', 'glove_6': 'glove_6', 'glove_7': 'glove_7', 'glove_8': 'glove_8', 'glove_9': 'glove_9', 'glove_10': 'glove_10', 'glove_11': 'glove_11', 'glove_12': 'glove_12', 'glove_13': 'glove_13', 'glove_14': 'glove_14', 'glove_15': 'glove_15', 'glove_16': 'glove_16', 'glove_17': 'glove_17', 'glove_18': 'glove_18', 'glove_19': 'glove_19', 'glove_20': 'glove_20', 'glove_21': 'glove_21', 'glove_22': 'glove_22', 'glove_23': 'glove_23', 'glove_24': 'glove_24', 'glove_25': 'glove_25', 'glove_26': 'glove_26', 'glove_27': 'glove_27', 'glove_28': 'glove_28', 'glove_29': 'glove_29', 'glove_30': 'glove_30', 'glove_31': 'glove_31', 'glove_32': 'glove_32', 'glove_33': 'glove_33', 'glove_34': 'glove_34', 'glove_35': 'glove_35', 'glove_36': 'glove_36', 'glove_37': 'glove_37', 'glove_38': 'glove_38', 'glove_39': 'glove_39', 'glove_40': 'glove_40', 'glove_41': 'glove_41', 'glove_42': 'glove_42', 'glove_43': 'glove_43', 'glove_44': 'glove_44', 'glove_45': 'glove_45', 'glove_46': 'glove_46', 'glove_47': 'glove_47', 'glove_48': 'glove_48', 'glove_49': 'glove_49', 'glove100_0': 'glove100_0', 'glove100_1': 'glove100_1', 'glove100_2': 'glove100_2', 'glove100_3': 'glove100_3', 'glove100_4': 'glove100_4', 'glove100_5': 'glove100_5', 'glove100_6': 'glove100_6', 'glove100_7': 'glove100_7', 'glove100_8': 'glove100_8', 'glove100_9': 'glove100_9', 'glove100_10': 'glove100_10', 'glove100_11': 'glove100_11', 'glove100_12': 'glove100_12', 'glove100_13': 'glove100_13', 'glove100_14': 'glove100_14', 'glove100_15': 'glove100_15', 'glove100_16': 'glove100_16', 'glove100_17': 'glove100_17', 'glove100_18': 'glove100_18', 'glove100_19': 'glove100_19', 'glove100_20': 'glove100_20', 'glove100_21': 'glove100_21', 'glove100_22': 'glove100_22', 'glove100_23': 'glove100_23', 'glove100_24': 'glove100_24', 'glove100_25': 'glove100_25', 'glove100_26': 'glove100_26', 'glove100_27': 'glove100_27', 'glove100_28': 'glove100_28', 'glove100_29': 'glove100_29', 'glove100_30': 'glove100_30', 'glove100_31': 'glove100_31', 'glove100_32': 'glove100_32', 'glove100_33': 'glove100_33', 'glove100_34': 'glove100_34', 'glove100_35': 'glove100_35', 'glove100_36': 'glove100_36', 'glove100_37': 'glove100_37', 'glove100_38': 'glove100_38', 'glove100_39': 'glove100_39', 'glove100_40': 'glove100_40', 'glove100_41': 'glove100_41', 'glove100_42': 'glove100_42', 'glove100_43': 'glove100_43', 'glove100_44': 'glove100_44', 'glove100_45': 'glove100_45', 'glove100_46': 'glove100_46', 'glove100_47': 'glove100_47', 'glove100_48': 'glove100_48', 'glove100_49': 'glove100_49', 'glove100_50': 'glove100_50', 'glove100_51': 'glove100_51', 'glove100_52': 'glove100_52', 'glove100_53': 'glove100_53', 'glove100_54': 'glove100_54', 'glove100_55': 'glove100_55', 'glove100_56': 'glove100_56', 'glove100_57': 'glove100_57', 'glove100_58': 'glove100_58', 'glove100_59': 'glove100_59', 'glove100_60': 'glove100_60', 'glove100_61': 'glove100_61', 'glove100_62': 'glove100_62', 'glove100_63': 'glove100_63', 'glove100_64': 'glove100_64', 'glove100_65': 'glove100_65', 'glove100_66': 'glove100_66', 'glove100_67': 'glove100_67', 'glove100_68': 'glove100_68', 'glove100_69': 'glove100_69', 'glove100_70': 'glove100_70', 'glove100_71': 'glove100_71', 'glove100_72': 'glove100_72', 'glove100_73': 'glove100_73', 'glove100_74': 'glove100_74', 'glove100_75': 'glove100_75', 'glove100_76': 'glove100_76', 'glove100_77': 'glove100_77', 'glove100_78': 'glove100_78', 'glove100_79': 'glove100_79', 'glove100_80': 'glove100_80', 'glove100_81': 'glove100_81', 'glove100_82': 'glove100_82', 'glove100_83': 'glove100_83', 'glove100_84': 'glove100_84', 'glove100_85': 'glove100_85', 'glove100_86': 'glove100_86', 'glove100_87': 'glove100_87', 'glove100_88': 'glove100_88', 'glove100_89': 'glove100_89', 'glove100_90': 'glove100_90', 'glove100_91': 'glove100_91', 'glove100_92': 'glove100_92', 'glove100_93': 'glove100_93', 'glove100_94': 'glove100_94', 'glove100_95': 'glove100_95', 'glove100_96': 'glove100_96', 'glove100_97': 'glove100_97', 'glove100_98': 'glove100_98', 'glove100_99': 'glove100_99', 'corpus_type_1': 'corpus_type_1', 'corpus_type_2': 'corpus_type_2', 'corpus_type_3': 'corpus_type_3'}\n",
        "# Pearson Corr\n",
        "# 0.7621009466596799\n",
        "# MSE\n",
        "# 0.01030796500067259"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "multi: For xgb-A during testing \n",
            "{'word_len': 'word_len', 'num_syll': 'num_syll', 'word_freq': 'word_freq', 'glove_0': 'glove_0', 'glove_1': 'glove_1', 'glove_2': 'glove_2', 'glove_3': 'glove_3', 'glove_4': 'glove_4', 'glove_5': 'glove_5', 'glove_6': 'glove_6', 'glove_7': 'glove_7', 'glove_8': 'glove_8', 'glove_9': 'glove_9', 'glove_10': 'glove_10', 'glove_11': 'glove_11', 'glove_12': 'glove_12', 'glove_13': 'glove_13', 'glove_14': 'glove_14', 'glove_15': 'glove_15', 'glove_16': 'glove_16', 'glove_17': 'glove_17', 'glove_18': 'glove_18', 'glove_19': 'glove_19', 'glove_20': 'glove_20', 'glove_21': 'glove_21', 'glove_22': 'glove_22', 'glove_23': 'glove_23', 'glove_24': 'glove_24', 'glove_25': 'glove_25', 'glove_26': 'glove_26', 'glove_27': 'glove_27', 'glove_28': 'glove_28', 'glove_29': 'glove_29', 'glove_30': 'glove_30', 'glove_31': 'glove_31', 'glove_32': 'glove_32', 'glove_33': 'glove_33', 'glove_34': 'glove_34', 'glove_35': 'glove_35', 'glove_36': 'glove_36', 'glove_37': 'glove_37', 'glove_38': 'glove_38', 'glove_39': 'glove_39', 'glove_40': 'glove_40', 'glove_41': 'glove_41', 'glove_42': 'glove_42', 'glove_43': 'glove_43', 'glove_44': 'glove_44', 'glove_45': 'glove_45', 'glove_46': 'glove_46', 'glove_47': 'glove_47', 'glove_48': 'glove_48', 'glove_49': 'glove_49', 'glove100_0': 'glove100_0', 'glove100_1': 'glove100_1', 'glove100_2': 'glove100_2', 'glove100_3': 'glove100_3', 'glove100_4': 'glove100_4', 'glove100_5': 'glove100_5', 'glove100_6': 'glove100_6', 'glove100_7': 'glove100_7', 'glove100_8': 'glove100_8', 'glove100_9': 'glove100_9', 'glove100_10': 'glove100_10', 'glove100_11': 'glove100_11', 'glove100_12': 'glove100_12', 'glove100_13': 'glove100_13', 'glove100_14': 'glove100_14', 'glove100_15': 'glove100_15', 'glove100_16': 'glove100_16', 'glove100_17': 'glove100_17', 'glove100_18': 'glove100_18', 'glove100_19': 'glove100_19', 'glove100_20': 'glove100_20', 'glove100_21': 'glove100_21', 'glove100_22': 'glove100_22', 'glove100_23': 'glove100_23', 'glove100_24': 'glove100_24', 'glove100_25': 'glove100_25', 'glove100_26': 'glove100_26', 'glove100_27': 'glove100_27', 'glove100_28': 'glove100_28', 'glove100_29': 'glove100_29', 'glove100_30': 'glove100_30', 'glove100_31': 'glove100_31', 'glove100_32': 'glove100_32', 'glove100_33': 'glove100_33', 'glove100_34': 'glove100_34', 'glove100_35': 'glove100_35', 'glove100_36': 'glove100_36', 'glove100_37': 'glove100_37', 'glove100_38': 'glove100_38', 'glove100_39': 'glove100_39', 'glove100_40': 'glove100_40', 'glove100_41': 'glove100_41', 'glove100_42': 'glove100_42', 'glove100_43': 'glove100_43', 'glove100_44': 'glove100_44', 'glove100_45': 'glove100_45', 'glove100_46': 'glove100_46', 'glove100_47': 'glove100_47', 'glove100_48': 'glove100_48', 'glove100_49': 'glove100_49', 'glove100_50': 'glove100_50', 'glove100_51': 'glove100_51', 'glove100_52': 'glove100_52', 'glove100_53': 'glove100_53', 'glove100_54': 'glove100_54', 'glove100_55': 'glove100_55', 'glove100_56': 'glove100_56', 'glove100_57': 'glove100_57', 'glove100_58': 'glove100_58', 'glove100_59': 'glove100_59', 'glove100_60': 'glove100_60', 'glove100_61': 'glove100_61', 'glove100_62': 'glove100_62', 'glove100_63': 'glove100_63', 'glove100_64': 'glove100_64', 'glove100_65': 'glove100_65', 'glove100_66': 'glove100_66', 'glove100_67': 'glove100_67', 'glove100_68': 'glove100_68', 'glove100_69': 'glove100_69', 'glove100_70': 'glove100_70', 'glove100_71': 'glove100_71', 'glove100_72': 'glove100_72', 'glove100_73': 'glove100_73', 'glove100_74': 'glove100_74', 'glove100_75': 'glove100_75', 'glove100_76': 'glove100_76', 'glove100_77': 'glove100_77', 'glove100_78': 'glove100_78', 'glove100_79': 'glove100_79', 'glove100_80': 'glove100_80', 'glove100_81': 'glove100_81', 'glove100_82': 'glove100_82', 'glove100_83': 'glove100_83', 'glove100_84': 'glove100_84', 'glove100_85': 'glove100_85', 'glove100_86': 'glove100_86', 'glove100_87': 'glove100_87', 'glove100_88': 'glove100_88', 'glove100_89': 'glove100_89', 'glove100_90': 'glove100_90', 'glove100_91': 'glove100_91', 'glove100_92': 'glove100_92', 'glove100_93': 'glove100_93', 'glove100_94': 'glove100_94', 'glove100_95': 'glove100_95', 'glove100_96': 'glove100_96', 'glove100_97': 'glove100_97', 'glove100_98': 'glove100_98', 'glove100_99': 'glove100_99', 'corpus_type_1': 'corpus_type_1', 'corpus_type_2': 'corpus_type_2', 'corpus_type_3': 'corpus_type_3'}\n",
            "Pearson Corr\n",
            "0.7621009466596799\n",
            "MSE\n",
            "0.01030796500067259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GylUs-5vNwG8"
      },
      "source": [
        "pred_trial = reg2.predict(df_trial[cols2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhJvY533NwG8",
        "outputId": "c5b69b6a-6983-4021-bfc2-9436d99e1f4e"
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "pearsonr(pred_trial, df2['complexity'])\n",
        "\n",
        "#single - (0.780464095108704, 1.6970151126820922e-87)\n",
        "#multi - (0.7280055473020886, 1.3759185734050741e-17)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7280055473020886, 1.3759185734050741e-17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xtNfOTmhSWD"
      },
      "source": [
        "## single xgb-B\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYwg4BVvBBK"
      },
      "source": [
        "## MWE xgb B\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UKWLZjEtNwG9",
        "outputId": "35c33364-fb47-4eda-a275-c62e1fbc639c"
      },
      "source": [
        "if reg_model == \"xgb\":\n",
        "    plot_importance(reg2, height=1, max_num_features=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miN6wEzFNwG-",
        "outputId": "4e6476c9-7ae7-4a6f-af14-535bb5c88633"
      },
      "source": [
        "print(\"{}: For xgb-B during testing \".format(mode))\n",
        "df_test = rearrange_cols(df_test)\n",
        "pred_test = reg2.predict(df_test[cols2])\n",
        "print(\"Pearson Corr\")\n",
        "print(pearsonr(pred_test, df3['complexity'])[0])\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"MSE\")\n",
        "print(mean_squared_error(df3['complexity'], pred_test))\n",
        "\n",
        "#single: For xgb-B during testing \n",
        "# {'word_len': 'word_len', 'num_syll': 'num_syll', 'word_freq': 'word_freq', 'glove_0': 'glove_0', 'glove_1': 'glove_1', 'glove_2': 'glove_2', 'glove_3': 'glove_3', 'glove_4': 'glove_4', 'glove_5': 'glove_5', 'glove_6': 'glove_6', 'glove_7': 'glove_7', 'glove_8': 'glove_8', 'glove_9': 'glove_9', 'glove_10': 'glove_10', 'glove_11': 'glove_11', 'glove_12': 'glove_12', 'glove_13': 'glove_13', 'glove_14': 'glove_14', 'glove_15': 'glove_15', 'glove_16': 'glove_16', 'glove_17': 'glove_17', 'glove_18': 'glove_18', 'glove_19': 'glove_19', 'glove_20': 'glove_20', 'glove_21': 'glove_21', 'glove_22': 'glove_22', 'glove_23': 'glove_23', 'glove_24': 'glove_24', 'glove_25': 'glove_25', 'glove_26': 'glove_26', 'glove_27': 'glove_27', 'glove_28': 'glove_28', 'glove_29': 'glove_29', 'glove_30': 'glove_30', 'glove_31': 'glove_31', 'glove_32': 'glove_32', 'glove_33': 'glove_33', 'glove_34': 'glove_34', 'glove_35': 'glove_35', 'glove_36': 'glove_36', 'glove_37': 'glove_37', 'glove_38': 'glove_38', 'glove_39': 'glove_39', 'glove_40': 'glove_40', 'glove_41': 'glove_41', 'glove_42': 'glove_42', 'glove_43': 'glove_43', 'glove_44': 'glove_44', 'glove_45': 'glove_45', 'glove_46': 'glove_46', 'glove_47': 'glove_47', 'glove_48': 'glove_48', 'glove_49': 'glove_49', 'glove100_0': 'glove100_0', 'glove100_1': 'glove100_1', 'glove100_2': 'glove100_2', 'glove100_3': 'glove100_3', 'glove100_4': 'glove100_4', 'glove100_5': 'glove100_5', 'glove100_6': 'glove100_6', 'glove100_7': 'glove100_7', 'glove100_8': 'glove100_8', 'glove100_9': 'glove100_9', 'glove100_10': 'glove100_10', 'glove100_11': 'glove100_11', 'glove100_12': 'glove100_12', 'glove100_13': 'glove100_13', 'glove100_14': 'glove100_14', 'glove100_15': 'glove100_15', 'glove100_16': 'glove100_16', 'glove100_17': 'glove100_17', 'glove100_18': 'glove100_18', 'glove100_19': 'glove100_19', 'glove100_20': 'glove100_20', 'glove100_21': 'glove100_21', 'glove100_22': 'glove100_22', 'glove100_23': 'glove100_23', 'glove100_24': 'glove100_24', 'glove100_25': 'glove100_25', 'glove100_26': 'glove100_26', 'glove100_27': 'glove100_27', 'glove100_28': 'glove100_28', 'glove100_29': 'glove100_29', 'glove100_30': 'glove100_30', 'glove100_31': 'glove100_31', 'glove100_32': 'glove100_32', 'glove100_33': 'glove100_33', 'glove100_34': 'glove100_34', 'glove100_35': 'glove100_35', 'glove100_36': 'glove100_36', 'glove100_37': 'glove100_37', 'glove100_38': 'glove100_38', 'glove100_39': 'glove100_39', 'glove100_40': 'glove100_40', 'glove100_41': 'glove100_41', 'glove100_42': 'glove100_42', 'glove100_43': 'glove100_43', 'glove100_44': 'glove100_44', 'glove100_45': 'glove100_45', 'glove100_46': 'glove100_46', 'glove100_47': 'glove100_47', 'glove100_48': 'glove100_48', 'glove100_49': 'glove100_49', 'glove100_50': 'glove100_50', 'glove100_51': 'glove100_51', 'glove100_52': 'glove100_52', 'glove100_53': 'glove100_53', 'glove100_54': 'glove100_54', 'glove100_55': 'glove100_55', 'glove100_56': 'glove100_56', 'glove100_57': 'glove100_57', 'glove100_58': 'glove100_58', 'glove100_59': 'glove100_59', 'glove100_60': 'glove100_60', 'glove100_61': 'glove100_61', 'glove100_62': 'glove100_62', 'glove100_63': 'glove100_63', 'glove100_64': 'glove100_64', 'glove100_65': 'glove100_65', 'glove100_66': 'glove100_66', 'glove100_67': 'glove100_67', 'glove100_68': 'glove100_68', 'glove100_69': 'glove100_69', 'glove100_70': 'glove100_70', 'glove100_71': 'glove100_71', 'glove100_72': 'glove100_72', 'glove100_73': 'glove100_73', 'glove100_74': 'glove100_74', 'glove100_75': 'glove100_75', 'glove100_76': 'glove100_76', 'glove100_77': 'glove100_77', 'glove100_78': 'glove100_78', 'glove100_79': 'glove100_79', 'glove100_80': 'glove100_80', 'glove100_81': 'glove100_81', 'glove100_82': 'glove100_82', 'glove100_83': 'glove100_83', 'glove100_84': 'glove100_84', 'glove100_85': 'glove100_85', 'glove100_86': 'glove100_86', 'glove100_87': 'glove100_87', 'glove100_88': 'glove100_88', 'glove100_89': 'glove100_89', 'glove100_90': 'glove100_90', 'glove100_91': 'glove100_91', 'glove100_92': 'glove100_92', 'glove100_93': 'glove100_93', 'glove100_94': 'glove100_94', 'glove100_95': 'glove100_95', 'glove100_96': 'glove100_96', 'glove100_97': 'glove100_97', 'glove100_98': 'glove100_98', 'glove100_99': 'glove100_99', 'corpus_type_1': 'corpus_type_1', 'corpus_type_2': 'corpus_type_2', 'corpus_type_3': 'corpus_type_3'}\n",
        "# Pearson Corr\n",
        "# 0.7409080585929776\n",
        "# MSE\n",
        "# 0.007306418164386233\n",
        "\n",
        "# multi: For xgb-B during testing \n",
        "# {'word_len': 'word_len', 'num_syll': 'num_syll', 'word_freq': 'word_freq', 'glove_0': 'glove_0', 'glove_1': 'glove_1', 'glove_2': 'glove_2', 'glove_3': 'glove_3', 'glove_4': 'glove_4', 'glove_5': 'glove_5', 'glove_6': 'glove_6', 'glove_7': 'glove_7', 'glove_8': 'glove_8', 'glove_9': 'glove_9', 'glove_10': 'glove_10', 'glove_11': 'glove_11', 'glove_12': 'glove_12', 'glove_13': 'glove_13', 'glove_14': 'glove_14', 'glove_15': 'glove_15', 'glove_16': 'glove_16', 'glove_17': 'glove_17', 'glove_18': 'glove_18', 'glove_19': 'glove_19', 'glove_20': 'glove_20', 'glove_21': 'glove_21', 'glove_22': 'glove_22', 'glove_23': 'glove_23', 'glove_24': 'glove_24', 'glove_25': 'glove_25', 'glove_26': 'glove_26', 'glove_27': 'glove_27', 'glove_28': 'glove_28', 'glove_29': 'glove_29', 'glove_30': 'glove_30', 'glove_31': 'glove_31', 'glove_32': 'glove_32', 'glove_33': 'glove_33', 'glove_34': 'glove_34', 'glove_35': 'glove_35', 'glove_36': 'glove_36', 'glove_37': 'glove_37', 'glove_38': 'glove_38', 'glove_39': 'glove_39', 'glove_40': 'glove_40', 'glove_41': 'glove_41', 'glove_42': 'glove_42', 'glove_43': 'glove_43', 'glove_44': 'glove_44', 'glove_45': 'glove_45', 'glove_46': 'glove_46', 'glove_47': 'glove_47', 'glove_48': 'glove_48', 'glove_49': 'glove_49', 'glove100_0': 'glove100_0', 'glove100_1': 'glove100_1', 'glove100_2': 'glove100_2', 'glove100_3': 'glove100_3', 'glove100_4': 'glove100_4', 'glove100_5': 'glove100_5', 'glove100_6': 'glove100_6', 'glove100_7': 'glove100_7', 'glove100_8': 'glove100_8', 'glove100_9': 'glove100_9', 'glove100_10': 'glove100_10', 'glove100_11': 'glove100_11', 'glove100_12': 'glove100_12', 'glove100_13': 'glove100_13', 'glove100_14': 'glove100_14', 'glove100_15': 'glove100_15', 'glove100_16': 'glove100_16', 'glove100_17': 'glove100_17', 'glove100_18': 'glove100_18', 'glove100_19': 'glove100_19', 'glove100_20': 'glove100_20', 'glove100_21': 'glove100_21', 'glove100_22': 'glove100_22', 'glove100_23': 'glove100_23', 'glove100_24': 'glove100_24', 'glove100_25': 'glove100_25', 'glove100_26': 'glove100_26', 'glove100_27': 'glove100_27', 'glove100_28': 'glove100_28', 'glove100_29': 'glove100_29', 'glove100_30': 'glove100_30', 'glove100_31': 'glove100_31', 'glove100_32': 'glove100_32', 'glove100_33': 'glove100_33', 'glove100_34': 'glove100_34', 'glove100_35': 'glove100_35', 'glove100_36': 'glove100_36', 'glove100_37': 'glove100_37', 'glove100_38': 'glove100_38', 'glove100_39': 'glove100_39', 'glove100_40': 'glove100_40', 'glove100_41': 'glove100_41', 'glove100_42': 'glove100_42', 'glove100_43': 'glove100_43', 'glove100_44': 'glove100_44', 'glove100_45': 'glove100_45', 'glove100_46': 'glove100_46', 'glove100_47': 'glove100_47', 'glove100_48': 'glove100_48', 'glove100_49': 'glove100_49', 'glove100_50': 'glove100_50', 'glove100_51': 'glove100_51', 'glove100_52': 'glove100_52', 'glove100_53': 'glove100_53', 'glove100_54': 'glove100_54', 'glove100_55': 'glove100_55', 'glove100_56': 'glove100_56', 'glove100_57': 'glove100_57', 'glove100_58': 'glove100_58', 'glove100_59': 'glove100_59', 'glove100_60': 'glove100_60', 'glove100_61': 'glove100_61', 'glove100_62': 'glove100_62', 'glove100_63': 'glove100_63', 'glove100_64': 'glove100_64', 'glove100_65': 'glove100_65', 'glove100_66': 'glove100_66', 'glove100_67': 'glove100_67', 'glove100_68': 'glove100_68', 'glove100_69': 'glove100_69', 'glove100_70': 'glove100_70', 'glove100_71': 'glove100_71', 'glove100_72': 'glove100_72', 'glove100_73': 'glove100_73', 'glove100_74': 'glove100_74', 'glove100_75': 'glove100_75', 'glove100_76': 'glove100_76', 'glove100_77': 'glove100_77', 'glove100_78': 'glove100_78', 'glove100_79': 'glove100_79', 'glove100_80': 'glove100_80', 'glove100_81': 'glove100_81', 'glove100_82': 'glove100_82', 'glove100_83': 'glove100_83', 'glove100_84': 'glove100_84', 'glove100_85': 'glove100_85', 'glove100_86': 'glove100_86', 'glove100_87': 'glove100_87', 'glove100_88': 'glove100_88', 'glove100_89': 'glove100_89', 'glove100_90': 'glove100_90', 'glove100_91': 'glove100_91', 'glove100_92': 'glove100_92', 'glove100_93': 'glove100_93', 'glove100_94': 'glove100_94', 'glove100_95': 'glove100_95', 'glove100_96': 'glove100_96', 'glove100_97': 'glove100_97', 'glove100_98': 'glove100_98', 'glove100_99': 'glove100_99', 'corpus_type_1': 'corpus_type_1', 'corpus_type_2': 'corpus_type_2', 'corpus_type_3': 'corpus_type_3'}\n",
        "# Pearson Corr\n",
        "# 0.8148691195161334\n",
        "# MSE\n",
        "# 0.008319163653201444"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "multi: For xgb-B during testing \n",
            "{'word_len': 'word_len', 'num_syll': 'num_syll', 'word_freq': 'word_freq', 'glove_0': 'glove_0', 'glove_1': 'glove_1', 'glove_2': 'glove_2', 'glove_3': 'glove_3', 'glove_4': 'glove_4', 'glove_5': 'glove_5', 'glove_6': 'glove_6', 'glove_7': 'glove_7', 'glove_8': 'glove_8', 'glove_9': 'glove_9', 'glove_10': 'glove_10', 'glove_11': 'glove_11', 'glove_12': 'glove_12', 'glove_13': 'glove_13', 'glove_14': 'glove_14', 'glove_15': 'glove_15', 'glove_16': 'glove_16', 'glove_17': 'glove_17', 'glove_18': 'glove_18', 'glove_19': 'glove_19', 'glove_20': 'glove_20', 'glove_21': 'glove_21', 'glove_22': 'glove_22', 'glove_23': 'glove_23', 'glove_24': 'glove_24', 'glove_25': 'glove_25', 'glove_26': 'glove_26', 'glove_27': 'glove_27', 'glove_28': 'glove_28', 'glove_29': 'glove_29', 'glove_30': 'glove_30', 'glove_31': 'glove_31', 'glove_32': 'glove_32', 'glove_33': 'glove_33', 'glove_34': 'glove_34', 'glove_35': 'glove_35', 'glove_36': 'glove_36', 'glove_37': 'glove_37', 'glove_38': 'glove_38', 'glove_39': 'glove_39', 'glove_40': 'glove_40', 'glove_41': 'glove_41', 'glove_42': 'glove_42', 'glove_43': 'glove_43', 'glove_44': 'glove_44', 'glove_45': 'glove_45', 'glove_46': 'glove_46', 'glove_47': 'glove_47', 'glove_48': 'glove_48', 'glove_49': 'glove_49', 'glove100_0': 'glove100_0', 'glove100_1': 'glove100_1', 'glove100_2': 'glove100_2', 'glove100_3': 'glove100_3', 'glove100_4': 'glove100_4', 'glove100_5': 'glove100_5', 'glove100_6': 'glove100_6', 'glove100_7': 'glove100_7', 'glove100_8': 'glove100_8', 'glove100_9': 'glove100_9', 'glove100_10': 'glove100_10', 'glove100_11': 'glove100_11', 'glove100_12': 'glove100_12', 'glove100_13': 'glove100_13', 'glove100_14': 'glove100_14', 'glove100_15': 'glove100_15', 'glove100_16': 'glove100_16', 'glove100_17': 'glove100_17', 'glove100_18': 'glove100_18', 'glove100_19': 'glove100_19', 'glove100_20': 'glove100_20', 'glove100_21': 'glove100_21', 'glove100_22': 'glove100_22', 'glove100_23': 'glove100_23', 'glove100_24': 'glove100_24', 'glove100_25': 'glove100_25', 'glove100_26': 'glove100_26', 'glove100_27': 'glove100_27', 'glove100_28': 'glove100_28', 'glove100_29': 'glove100_29', 'glove100_30': 'glove100_30', 'glove100_31': 'glove100_31', 'glove100_32': 'glove100_32', 'glove100_33': 'glove100_33', 'glove100_34': 'glove100_34', 'glove100_35': 'glove100_35', 'glove100_36': 'glove100_36', 'glove100_37': 'glove100_37', 'glove100_38': 'glove100_38', 'glove100_39': 'glove100_39', 'glove100_40': 'glove100_40', 'glove100_41': 'glove100_41', 'glove100_42': 'glove100_42', 'glove100_43': 'glove100_43', 'glove100_44': 'glove100_44', 'glove100_45': 'glove100_45', 'glove100_46': 'glove100_46', 'glove100_47': 'glove100_47', 'glove100_48': 'glove100_48', 'glove100_49': 'glove100_49', 'glove100_50': 'glove100_50', 'glove100_51': 'glove100_51', 'glove100_52': 'glove100_52', 'glove100_53': 'glove100_53', 'glove100_54': 'glove100_54', 'glove100_55': 'glove100_55', 'glove100_56': 'glove100_56', 'glove100_57': 'glove100_57', 'glove100_58': 'glove100_58', 'glove100_59': 'glove100_59', 'glove100_60': 'glove100_60', 'glove100_61': 'glove100_61', 'glove100_62': 'glove100_62', 'glove100_63': 'glove100_63', 'glove100_64': 'glove100_64', 'glove100_65': 'glove100_65', 'glove100_66': 'glove100_66', 'glove100_67': 'glove100_67', 'glove100_68': 'glove100_68', 'glove100_69': 'glove100_69', 'glove100_70': 'glove100_70', 'glove100_71': 'glove100_71', 'glove100_72': 'glove100_72', 'glove100_73': 'glove100_73', 'glove100_74': 'glove100_74', 'glove100_75': 'glove100_75', 'glove100_76': 'glove100_76', 'glove100_77': 'glove100_77', 'glove100_78': 'glove100_78', 'glove100_79': 'glove100_79', 'glove100_80': 'glove100_80', 'glove100_81': 'glove100_81', 'glove100_82': 'glove100_82', 'glove100_83': 'glove100_83', 'glove100_84': 'glove100_84', 'glove100_85': 'glove100_85', 'glove100_86': 'glove100_86', 'glove100_87': 'glove100_87', 'glove100_88': 'glove100_88', 'glove100_89': 'glove100_89', 'glove100_90': 'glove100_90', 'glove100_91': 'glove100_91', 'glove100_92': 'glove100_92', 'glove100_93': 'glove100_93', 'glove100_94': 'glove100_94', 'glove100_95': 'glove100_95', 'glove100_96': 'glove100_96', 'glove100_97': 'glove100_97', 'glove100_98': 'glove100_98', 'glove100_99': 'glove100_99', 'corpus_type_1': 'corpus_type_1', 'corpus_type_2': 'corpus_type_2', 'corpus_type_3': 'corpus_type_3'}\n",
            "Pearson Corr\n",
            "0.8148691195161334\n",
            "MSE\n",
            "0.008319163653201444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NBoUxtp4Yyj"
      },
      "source": [
        "## xgb-C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybbzuZvp7hmK"
      },
      "source": [
        "all_model_names = ['gsarti/biobert-nli',\n",
        " 'bert-base-uncased',\n",
        " 'lukabor/europarl-mlm',\n",
        " 'nlpaueb/legal-bert-base-uncased',\n",
        " 'ProsusAI/finbert',\n",
        " 'SpanBERT/spanbert-large-cased',\n",
        " 'emilyalsentzer/Bio_ClinicalBERT',\n",
        " 'bert-base-cased',\n",
        " 'nlpaueb/legal-bert-small-uncased',\n",
        " 'bert-large-uncased',\n",
        " 'bert-large-cased',\n",
        " 'allenai/scibert_scivocab_uncased',\n",
        " 'allenai/scibert_scivocab_cased',\n",
        " 'lordtt13/COVID-SciBERT',\n",
        " 'gsarti/scibert-nli',\n",
        " 'bert-large-uncased-whole-word-masking',\n",
        " 'bert-large-cased-whole-word-masking',\n",
        " 'zhiheng-huang/bert-large-uncased-whole-word-masking-embedding-relative-key-query',\n",
        " 'dmis-lab/biobert-base-cased-v1.1-squad',\n",
        " 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmXvLjkcOzu4",
        "outputId": "ba1b18bc-65b2-4bfd-fa75-80c0a8145099"
      },
      "source": [
        "len(all_model_names)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJlHM_Z2WH7o"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoModelWithLMHead,AutoModelForMaskedLM\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm, trange\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "def find_sub_list(sl,l):\n",
        "    sll=len(sl)\n",
        "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
        "        if l[ind:ind+sll]==sl:\n",
        "            return ind,ind+sll-1\n",
        "\n",
        "    for idx in range(sll):\n",
        "        word = sl[idx]\n",
        "        if '#' in word or 'Ä ' in word:\n",
        "            sl[idx] = word.replace('#', '').replace('Ä ', '')\n",
        "\n",
        "    for idx in range(len(l)):\n",
        "        word = l[idx]\n",
        "        if '#' in word or 'Ä ' in word:\n",
        "            l[idx] = word.replace('#', '').replace('Ä ', '')\n",
        "\n",
        "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
        "        if l[ind:ind+sll]==sl:\n",
        "            return ind,ind+sll-1\n",
        "\n",
        "    for ind in range(len(l)):\n",
        "        if sl[0] in l[ind]:\n",
        "            return ind,ind\n",
        "\n",
        "    for ind in range(len(l)):\n",
        "        if l[ind] in sl[0]:\n",
        "            return ind,ind\n",
        "\n",
        "    sl = [it_.lower() for it_ in sl]\n",
        "\n",
        "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
        "        if l[ind:ind+sll]==sl:\n",
        "            return ind,ind+sll-1\n",
        "\n",
        "    for idx in range(sll):\n",
        "        word = sl[idx]\n",
        "        if '#' in word or 'Ä ' in word:\n",
        "            sl[idx] = word.replace('#', '').replace('Ä ', '')\n",
        "\n",
        "    for idx in range(len(l)):\n",
        "        word = l[idx]\n",
        "        if '#' in word or 'Ä ' in word:\n",
        "            l[idx] = word.replace('#', '').replace('Ä ', '')\n",
        "\n",
        "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
        "        if l[ind:ind+sll]==sl:\n",
        "            return ind,ind+sll-1\n",
        "\n",
        "    for ind in range(len(l)):\n",
        "        if sl[0] in l[ind]:\n",
        "            return ind,ind\n",
        "\n",
        "    for ind in range(len(l)):\n",
        "        if l[ind] in sl[0]:\n",
        "            return ind,ind\n",
        "\n",
        "def get_probability_util(model, token_ids, mask_id, ent_tok_id):\n",
        "    model.eval()\n",
        "    # init softmax to get probabilities later on\n",
        "    sm = torch.nn.Softmax(dim=0)\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "    masked_position = (token_ids.squeeze() == mask_id).nonzero().item()\n",
        "    # forward\n",
        "    output = model(token_ids.cuda())\n",
        "    last_hidden_state = output[0].squeeze(0)\n",
        "    # only get output for masked token\n",
        "    # output is the size of the vocabulary\n",
        "    mask_hidden_state = last_hidden_state[masked_position]\n",
        "    # convert to probabilities (softmax)\n",
        "    # giving a probability for each item in the vocabulary\n",
        "    probs = sm(mask_hidden_state)\n",
        "\n",
        "    # get probability of token\n",
        "    return probs[ent_tok_id].item()\n",
        "\n",
        "def get_probability(model_name, df):\n",
        "\n",
        "    prob_list = []\n",
        "\n",
        "    sentences = df['sentence'].tolist()\n",
        "    entities = df['token'].tolist()\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    model = AutoModelForMaskedLM.from_pretrained(model_name).cuda()\n",
        "\n",
        "    mask_id = tokenizer.mask_token_id\n",
        "\n",
        "    for idx_ in trange(len(sentences)):\n",
        "        sentence = sentences[idx_]\n",
        "        entity = entities[idx_]\n",
        "\n",
        "        token_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
        "        # print(idx_, token_ids)\n",
        "\n",
        "        if \"roberta\" in model_name.lower():\n",
        "            sentence = sentence.replace('\"', '')\n",
        "            # sentence = sentence.replace(\"'\", \"\")\n",
        "            sentence = sentence.replace('<', '')\n",
        "            sentence = sentence.replace('>', '')\n",
        "            sentence = sentence.replace('(', '')\n",
        "            sentence = sentence.replace(')', '')\n",
        "            sentence = \" \" + sentence\n",
        "            entity = \" \" + entity\n",
        "\n",
        "        sentence_ids = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        sent_tokens = tokenizer.convert_ids_to_tokens(sentence_ids)\n",
        "\n",
        "        ent_ids = tokenizer.encode(entity, add_special_tokens=False)\n",
        "        ent_tokens = tokenizer.convert_ids_to_tokens(ent_ids)\n",
        "\n",
        "        # print(idx_, sent_tokens, ent_tokens)\n",
        "\n",
        "        start, end = find_sub_list(ent_tokens, sent_tokens)\n",
        "\n",
        "        # print(idx_, sent_tokens, ent_tokens)\n",
        "        # print(start, end)\n",
        "\n",
        "        prob = 1\n",
        "\n",
        "        for i in range(start, end + 1):\n",
        "            # 1 is added to accomodate the special tokens\n",
        "            ent_tok_id = token_ids[0][i + 1].item()\n",
        "            # print(ent_tok_id)\n",
        "            token_ids[0][i + 1] = mask_id     \n",
        "            # print(token_ids)\n",
        "            prob *= get_probability_util(model, token_ids, mask_id, ent_tok_id)\n",
        "            \n",
        "            token_ids[0][i + 1] = ent_tok_id\n",
        "        prob_list.append(prob)\n",
        "    print(len(prob_list))\n",
        "    print(prob_list[0:5])\n",
        "    return prob_list"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P154dDodoFvh"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "dict_ = {}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r36tJ201vjG4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "613c6c806daf46319d1e602da47b30fb",
            "3c57941002394b38b42ed09d9665dc8b",
            "83ac602760ff4ddc91f10e837ac4f8cb",
            "3d18f5061089470aa44ed39fba0f4331",
            "defd1856a09241d193ac24d3c5ed9a5b",
            "cbe3b124e7fd4a21947678be2d74be88",
            "92ca26ce609740aeb460eff00179b97e",
            "57aed8b86d5f466b8a3fe3ecb663c875",
            "71ddf4d9012942d98bced49225cc7d7b",
            "4b52d2ea9fb24dd1ac1a8767dd93a95a",
            "9b037f766ba44f418c5f4c0d269e3237",
            "10eb283847cd4aed86f71aced67c816c",
            "935a09d4bdba4a7b81970e07b8734fe3",
            "67608dc2caa54df5bc732b9d6771e2e2",
            "a9b55b1f29dc4fc4b11580015d267728",
            "e030dbc357794b61bb4a66687cede582",
            "63ba42eae1644f39b9ed4a79af995bb3",
            "feecb300e7e74f81b1073a619d101329",
            "ec61ff17f4a34ff3b47394d2cc3abf80",
            "ad2bb51d8b3848d2a12a9c0e3a023e88",
            "058c74b86a6440ac87739e5fca3cc240",
            "b7650415994b4ee8a115a368d01faa77",
            "9d778e72c2274afebf820d827db2fe59",
            "07668001abac4ca5a3387ffb7bebca98",
            "a54515ac1299487cbdfa8e7be31df5a6",
            "d6feaea78e8945838ddc1867f4240ae5",
            "edd91820e5754ddc8da842e90d8521d7",
            "f41528a9fefd482492fba6f6c4a8fa6f",
            "0b4f86be822445d28dec93dc7156171b",
            "2a4e6ea6761d407f98bac65ae4d5c117",
            "7c144550f8b74c629c8f01fa0d06fc7e",
            "9434fe9f5a4d4a5fb03b9627fe20a898",
            "9dfaa7106a81463cb573b0203f7a100a",
            "322d0b9f9dce49459b64fb9be273e980",
            "6759e5fbf7e94190bbba7f8fdc9293ef",
            "ca0371bc4dfc4b758b0fd58b0ef65ea8",
            "423474da0f0f4faebdc5a21495d30887",
            "7a082e8dab62403b990a23f1291b03de",
            "18d5a6f36921467caf14320531d5dc24",
            "e36d9c63516f4ae88268e8a82f38ba81",
            "3814d5a79a204e91bb1f6eef44c9127c",
            "836d534ab9dd41e1a49464c78ebc246b",
            "58be044fa8a44fd5937d68c527f330e6",
            "1f74e8ccf7614eeab175d22974a73826",
            "f26049eda0434f3495dc7d8de40a02f1",
            "70bbc3b9b5ab429aa9f647cc48d1a21b",
            "94611d5444cc43caab867e4636d4904c",
            "92a1deeda5414e0ea51d4f7b524f55b8",
            "c79b251b6a9943ff813f76614dedf009",
            "62aff14e81d040d88b8e8ed87c290b6d",
            "5ab590a13a3d42efa7df5133fdf3c925",
            "a139164f62684b9f88cfe7d92ea68118",
            "d185b4b587f84b41b7508937179a3ee8",
            "e308fc7c1f3b4608be7c454b3c50dcc3",
            "db9b43a3dd0f4df5aac5b28006c41622",
            "6c95f1e470e8431aabfb51c499d659f1",
            "e68c8f4583974059bfd2caab5c122087",
            "3e33a8ce22bc43fda1044e39da1cc1ad",
            "8f187c9a99f74dd5b35b38c54ac27b99",
            "e25fe10433e34cdebcafbcdea8ac7847",
            "e73ecf83e0bf4aa0a0fb78a79980fc91",
            "51cdae16da2649ca84667adbb71dbd91",
            "6932d62bca9c439bbe2f09ba5b8ce6f4",
            "e634524740ab402d8634d6e0776a1954",
            "674686b1eb624b46ab87783fe263afaf",
            "44dfbf7592a94b7d9e70b1b91a60d2e6",
            "e3025872ddde45bdb0f96b1df0b11c9b",
            "b9e833f275ca43ab9aa97a3bfd3c4df0",
            "fda51ff6eb6b4d63b4b8c8fc58211228",
            "b2a35cda03654af3b8af9abe65b5fd03",
            "3b331b9e574045d5a2b9f9e510d5fce8",
            "a7b42c9cdc5e43a0991a1dd69536eb79",
            "8e159abbd0ed4cee8eb05151c95f8460",
            "76ace7e2de4944ca9ae1db8af516616e",
            "9c239732924346baaf0e0eae26f76636",
            "569dd0283197484e88a5b2e2f0c3586a",
            "5c49fe9ab2714b0e997d846438aaa93a",
            "76fff07eab4b491daf0327eafe6b0165",
            "e818bf45330847919931bfee9a12f9c4",
            "fff937f7af3a43dc8b659683b0ea7ece",
            "991b018c9f3f43f397cc0fa8830c539d",
            "a280a20b174c42d29c1c397ad995351e",
            "d00d6b65b52b4863b2e52925cc71cab4",
            "d85c0ae9c4f949108d9febfc6cf805d9",
            "2566157c49e2494fab6cbb610f1544e5",
            "5253e59126d1435e98cd5ec70216fc60",
            "50e37b338e94425588624f8ef1a55661",
            "353ec56bd03f4193a6fee30ea7ce4623",
            "1ac70212f7f44486a74fc1f372e66447",
            "c8a80cb4c336492f8ab12f0f18fd4ec5",
            "3f1d7f6911b84763b51fecf916efa92c",
            "98bdba9f1e3b402f9b507f8be2d98e73",
            "95527021bdb742448084c4b693806ef0",
            "fb91f480bbcc4bf69989beaccdec8730",
            "7215d2356e7e4936aae2cfd1acab1e4f",
            "e699e8b42b6b45aab24b0083e1e56c83",
            "156748ac21c34d4f90d4a99588fb155f",
            "3bcd33f9747e4de79ce36fc3159f0b2d",
            "156e6f68ca804eb6ad3f45e5d6217413",
            "dcae2102735947a8b8f35b80bb11d362",
            "06df8274cd8e442b8c08efb17a54605f",
            "4ae6dabed9ff44ed839f2f3f291834b1",
            "fc69878798344780b6b60ff677d2ce2d",
            "5b423e1b551a462ab1f44ee74abccdbd",
            "23310760df854e5eaddad6e0ea6313e7",
            "42b955e6abd8412dbf39909f1f6a7be8",
            "d86f982e5be14c6aac7b18cf831a7ccb",
            "78d2003f7c3f4a46a360713231793e4b",
            "6ad3df69308b4011a89fec3241cc2ef3",
            "fdf4f943ba484db69a84bf8857bfca96",
            "f0c8071ba266483abd013741364d119d",
            "4a731b99cb57424b98df259815687fe3",
            "0fe2785d14a943caa9841f36ff2e3b8e",
            "f0c6a391b42048dfb8fc33bbf5931a93",
            "7a1b06c7970043d5b21edeb340c08c68",
            "c149c874623842c28b513a6b3bbd3372",
            "945327b64c3d4099afc6d749fbcbd506",
            "d0d400e9e9b842db8087a08654b48026",
            "674dfbe7b4f34bdea267ffcb132dc448",
            "3fcecd77349a4f2685c2aaaa9438fa17",
            "295bf42a22474fc6bba8d648ffc6b418",
            "ce62385ebe1a4a67bb25f92c84868205",
            "d6c7732c5b404f1ca18383aa7292778c",
            "27f464b82ccc400bb05379d276ebe00f",
            "b48bbdfbbff1499580fbfcae47f0ec52",
            "57389ac1c2ee4d2b939e97636c737df9",
            "a5e969d0758b4b99bf267c8b43026189",
            "d568660c8fe9403fb0d66c0e26553de1",
            "cb755f25cc8d4d418252fa01861a7379",
            "f11ffdeabdc24b288ca9d91e064c8aa2",
            "56d7cb9cb8114223bec9801a4a43d0da",
            "c75335563c074307947522ea6ad1a2f3",
            "a695bd6f189d45e993cf50ab07d22f39",
            "6b6f4ae9c85448f5926fd3871e4ae7bc",
            "1bd9e17519cd49358fdffb2eb9d6c2b5",
            "23f309d1551e48e1abbb0fe3d8a35948"
          ]
        },
        "outputId": "81dce860-f9a1-4f14-b720-4740d80f2359"
      },
      "source": [
        "\n",
        "num_cols = 0\n",
        "model_names = all_model_names\n",
        "\n",
        "# else:\n",
        "#     num_cols = len([col for col in df_train.columns.tolist() if 'feat_' in col])\n",
        "#     model_names = all_model_names[num_cols:]\n",
        "#     num_cols_2 = len([col for col in df_trial.columns.tolist() if 'feat_' in col])\n",
        "#     model_names_2 = all_model_names[num_cols_2:]        \n",
        "\n",
        "#for train\n",
        "\n",
        "# df1 = pd.read_csv(\"train/lcp_single_train.tsv\", delimiter = \"\\t\", quoting = csv.QUOTE_NONE, encoding = 'utf-8', keep_default_na=False)\n",
        "print(df1.shape)\n",
        "\n",
        "# df_train = pd.DataFrame()\n",
        "\n",
        "print(len(model_names))\n",
        "\n",
        "dict_['all_models'] = all_model_names\n",
        "\n",
        "for i, model_name in enumerate(model_names):\n",
        "    df_train['feat_{}'.format(i + num_cols)] = get_probability(model_name, df1)\n",
        "    # df_trial['feat_{}'.format(i + num_cols)] = get_probability(model_name, df2)\n",
        "    dict_['df_train'] = df_train\n",
        "    # dict_['df_trial'] = df_trial\n",
        "\n",
        "    #temporarily saving predictions, as RAM may overflow.\n",
        "\n",
        "    with open('temp_{}_feats.pickle'.format(len(all_model_names)), 'wb') as handle:\n",
        "        pickle.dump(dict_, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# model_names = [\"abhi1nandy2/Europarl-roberta-base\"]\n",
        "\n",
        "#for trial\n",
        "\n",
        "# df2 = pd.read_csv(\"train/lcp_single_trial.tsv\", delimiter = \"\\t\", quoting = csv.QUOTE_NONE, encoding = 'utf-8', keep_default_na=False)\n",
        "print(df2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7662, 5)\n",
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at gsarti/biobert-nli and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "613c6c806daf46319d1e602da47b30fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[2.6074101697304286e-05, 2.885876347136218e-05, 2.7515745387063362e-05, 1.0047720934380777e-05, 6.855758783785859e-06]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71ddf4d9012942d98bced49225cc7d7b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.002421183744445443, 0.055070795118808746, 0.024478180333971977, 0.010927158407866955, 0.003082938026636839]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63ba42eae1644f39b9ed4a79af995bb3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.0015147313242778182, 0.01628728024661541, 0.013230348937213421, 0.0021223491057753563, 8.455393253825605e-05]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a54515ac1299487cbdfa8e7be31df5a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.0016568971332162619, 0.0344432033598423, 0.0011638745199888945, 0.007871001958847046, 0.00020879667135886848]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertForMaskedLM: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dfaa7106a81463cb573b0203f7a100a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[8.425719897786621e-06, 3.8664802559651434e-05, 6.487671635113657e-05, 7.780381565680727e-05, 2.5798088245210238e-05]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3814d5a79a204e91bb1f6eef44c9127c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[5.67090592085151e-06, 0.00010710698552429676, 3.5516484786057845e-05, 3.307579390821047e-05, 9.3585304057342e-06]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c79b251b6a9943ff813f76614dedf009",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.001015085494145751, 0.00025810886290855706, 9.901203884510323e-05, 0.00024401819973718375, 0.000449586397735402]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e68c8f4583974059bfd2caab5c122087",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.0020597786642611027, 0.05135064572095871, 0.007921440526843071, 0.01481676660478115, 0.0022758899722248316]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "674686b1eb624b46ab87783fe263afaf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.011314021423459053, 0.009388329461216927, 9.59443932515569e-05, 0.0029393909499049187, 0.00014666904462501407]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e159abbd0ed4cee8eb05151c95f8460",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.013786123134195805, 0.03579673543572426, 0.004317647777497768, 0.040594592690467834, 0.005472439806908369]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "991b018c9f3f43f397cc0fa8830c539d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.008909960277378559, 0.03561357781291008, 0.022292686626315117, 0.01717386767268181, 0.0060047865845263]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ac70212f7f44486a74fc1f372e66447",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.0046761599369347095, 0.02023259223648899, 0.01250299004882649, 0.039072904636579864, 0.004834415123936564]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "156748ac21c34d4f90d4a99588fb155f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.0005266939988359809, 0.30380367730268887, 0.6885636576293876, 0.265634775459624, 0.07853406270575736]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23310760df854e5eaddad6e0ea6313e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.004115112125873566, 0.00023491588660515782, 0.0005326802817683801, 0.004080165740962954, 3.0273354957757834e-06]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at gsarti/scibert-nli and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fe2785d14a943caa9841f36ff2e3b8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[9.106857032747939e-05, 1.3230591422714724e-09, 2.939712808812256e-10, 4.376261934254106e-09, 2.2364006144870556e-09]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "295bf42a22474fc6bba8d648ffc6b418",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.002248629229143262, 0.04083339869976044, 0.0031083272770047188, 0.05984349921345711, 0.0070277731865644455]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb755f25cc8d4d418252fa01861a7379",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7662.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7662\n",
            "[0.000663375249132514, 0.06123064085841179, 0.0025398647412657738, 0.08009705692529678, 0.009833876974880695]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI2wKfSJxf1X"
      },
      "source": [
        "for i, model_name in enumerate(model_names):\n",
        "    # df_train['feat_{}'.format(i + num_cols)] = get_probability(model_name, df1)\n",
        "    df_trial['feat_{}'.format(i + num_cols)] = get_probability(model_name, df2)\n",
        "    # dict_['df_train'] = df_train\n",
        "    dict_['df_trial'] = df_trial\n",
        "\n",
        "    #temporarily saving predictions, as RAM may overflow.\n",
        "\n",
        "    with open('temp_{}_feats.pickle'.format(len(all_model_names)), 'wb') as handle:\n",
        "        pickle.dump(dict_, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jqeW1vjQ5m2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701,
          "referenced_widgets": [
            "86fe5c073bd94e739d74cdc44382e94d",
            "28eae147cc7448d0b8aa7efe2507f02c",
            "7656a3453ab64648b090891f0b9f2bf6",
            "2537e877664b442ba8efd12ab563de14",
            "be306d3793b9405eaede74f429917303",
            "cdb0ab4e68f54ba9a4284e630329b3cd",
            "5db9a0d3d5ff46a995aa7eb0bd58cabf",
            "edf99566d90347cbb8788c37b59b7d38",
            "842d1b06f7624464954203fb630a4a46",
            "d8e30f6cc3f64281bce9ea3974cce84a",
            "07ae6c76eafa4077846b4544d26fff52",
            "8f96c02a3d6a45ebb38f0e39f2d8ac7d",
            "c2f3ad6020c548628679f5acbba8d61d",
            "a8ba1198e5554ebdabed33770781887a",
            "57102e5731f84ec0bc6dde49ab52d3f1",
            "3696d9cf629f4282a327690017398ad6",
            "765c5d6055034d3cab4189b56ac7d5fb",
            "b1aa81f13d954cbaa19cd3c17aba3944",
            "888cd25d91944426a94532028fc01ffb",
            "f2e69c390fb4447abe4205d9124f9df5",
            "9c860045fba844d0abd86ff315c95a05",
            "5280c650801348eeaedbbeec0d892a6a",
            "ed63131aa9c24536b29c996d21eb16fa",
            "df58851b69964172ad8f238fa0cfed63",
            "c1432f432ec3457fadf897239d40024a",
            "85a06207a10d4c2cbf2c220d27eba1b2",
            "170964149ff74a2f851c54ec63a3a513",
            "71cee4a5a7bf45a08e7b0f39731a48e2",
            "4fd389de63ec47669edea3d0a9234896",
            "177f0b91a1334a70984153e9c3bd49c9",
            "df0bc0f166a84d48a26bb98f706e647a",
            "936f54d27cea4f92baf288ba18ee7eba",
            "1f459ff3fa2f4a35a20b1476154bbf85",
            "32995de1bfa14a0cbf3f17b5811b8a6a",
            "a6f2b4efc1444df380e3a269e12e9256",
            "b9173054f4c346d399a0a79be9c61add",
            "ccd2ad864a0e4e019963cc96b82cd567",
            "e03a90b3680f451ab6aae47761fa6b4f",
            "7acaf10cc42446c29c62963d70aae7ef",
            "66d8b1b1fecc4d9dbdda77f781b9e1b2"
          ]
        },
        "outputId": "e0147170-7ad0-4b93-dce1-16aaca7169fd"
      },
      "source": [
        "if 'df_test' in dict_:\n",
        "    print('Already present')\n",
        "    num_cols = len([col for col in df_test.columns.tolist() if 'feat_' in col])\n",
        "    model_names = all_model_names[num_cols:]\n",
        "else:\n",
        "    num_cols = 0\n",
        "    model_names = all_model_names\n",
        "    df_test = pd.DataFrame()  \n",
        "\n",
        "# model_names = model_names[-2:]\n",
        "\n",
        "print(\"{} Models\".format(len(model_names)))\n",
        "    \n",
        "#for test\n",
        "\n",
        "df3 = pd.read_csv(\"lcp_{}_test.tsv\".format(mode), delimiter = \"\\t\", quoting = csv.QUOTE_NONE, encoding = 'utf-8', keep_default_na=False)\n",
        "print(len(df3))\n",
        "for i, model_name in enumerate(model_names):\n",
        "    df_test['feat_{}'.format(i)] = get_probability(model_name, df3)\n",
        "    dict_['df_train'] = df_train\n",
        "    dict_['df_trial'] = df_trial\n",
        "    dict_['df_test'] = df_test\n",
        "    with open('temp_{}_feats.pickle'.format(len(all_model_names)), 'wb') as handle:\n",
        "        pickle.dump(dict_, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20 Models\n",
            "917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at gsarti/biobert-nli and are newly initialized: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86fe5c073bd94e739d74cdc44382e94d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=917.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "917\n",
            "[2.8870148526038975e-05, 2.837903593899682e-05, 3.273544643889181e-05, 7.682561772526242e-06, 0.00038798508467152715]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "842d1b06f7624464954203fb630a4a46",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=917.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "917\n",
            "[0.09346431493759155, 0.890360414981842, 0.15092746913433075, 0.007650634739547968, 0.0015356893418356776]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "765c5d6055034d3cab4189b56ac7d5fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=917.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "917\n",
            "[0.004843717906624079, 0.3564364016056061, 0.04149990156292915, 0.0075255935080349445, 0.001517737633548677]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1432f432ec3457fadf897239d40024a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=917.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "917\n",
            "[0.0008421940729022026, 0.5749024748802185, 0.028398048132658005, 0.0028947521932423115, 0.0009175337618216872]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertForMaskedLM: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f459ff3fa2f4a35a20b1476154bbf85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=917.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "917\n",
            "[1.1553980584722012e-05, 6.045230747986352e-06, 3.917431604349986e-05, 1.5925684238027316e-06, 3.660839138319716e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMnHR8iXOdmY",
        "outputId": "a0c7c433-16b7-4949-e26d-43b64886869d"
      },
      "source": [
        "print(df_train.shape, df_trial.shape, df_test.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1517, 176) (99, 176) (184, 176)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAJlNM6KJENb",
        "outputId": "ddbbddc6-adfb-4cbb-e9ea-ef614918b884"
      },
      "source": [
        "#@title Regression model\n",
        "# all_model_names = dict_['all_models']\n",
        "# df_train = rearrange_cols(df_train)\n",
        "# df_trial = rearrange_cols(df_trial)\n",
        " \n",
        "print(df_train.shape, df_trial.shape)\n",
        " \n",
        "import numpy as np\n",
        "\n",
        "#all other regression kodles gave inferior results. Hence, we only report variants of only xgboost. \n",
        "reg_model = \"xgb\" #@param [\"lin_reg\", \"lin_reg_SS\", \"svr\", \"lars\", \"bayesian_ridge\", \"grad_boost\", \"xgb\", \"lightgbm\", \"catboost\"]\n",
        "# num_feats =  24#@param {type:\"integer\"}\n",
        "# omit = \"15,18,1,9,4,16,10,13,14,20,22,23,24,25,26,28,29,30,33,34,35,37,38,39,40,41,42,43,46\" #@param {type:\"string\"}\n",
        "# omit_all = False #@param {type:\"boolean\"}\n",
        " \n",
        "#15,18,1,9,4,16,10,13,14,20,22,23,24,25,26,28,29,30,33,34,35,37,38,39,40,41,42,43,46\n",
        " \n",
        "is_word_len = True\n",
        "is_num_syll = True\n",
        "is_word_freq = True\n",
        "\n",
        "is_glove = True\n",
        "is_glove100 = True\n",
        "is_corpus_type = True\n",
        " \n",
        "cols = df_train.columns.tolist()\n",
        " \n",
        "# omit_list = [\"feat_\" + it_ for it_ in omit.split(\",\")]\n",
        " \n",
        "# if omit_all:\n",
        "#     omit_list = np.arange(len(all_model_names)).tolist()\n",
        "#     omit_list = [\"feat_\" + str(it_) for it_ in omit_list]\n",
        " \n",
        "omit_list = []\n",
        "\n",
        "if is_word_len == False:\n",
        "    omit_list.append('word_len')\n",
        " \n",
        "if is_num_syll == False:\n",
        "    omit_list.append('num_syll')\n",
        " \n",
        "if is_word_freq == False:\n",
        "    omit_list.append('word_freq')\n",
        " \n",
        "if is_corpus_type == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'corpus_type_' in it_])\n",
        " \n",
        "if is_glove == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'glove_' in it_])\n",
        " \n",
        "if is_glove100 == False:\n",
        "    omit_list.extend([it_ for it_ in cols if 'glove100_' in it_])\n",
        " \n",
        "cols = [it_ for it_ in cols if it_ not in omit_list]\n",
        " \n",
        "print(len(cols))\n",
        " \n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor, plot_importance\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Lars, BayesianRidge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        " \n",
        "if reg_model == 'lin_reg':\n",
        "    reg = LinearRegression(normalize = True).fit(df_train[cols], y_train)\n",
        "elif reg_model == \"lin_reg_SS\":\n",
        "    reg = make_pipeline(StandardScaler(), LinearRegression(normalize = False)).fit(df_train[cols], y_train)\n",
        "elif reg_model == \"lars\":\n",
        "    reg = Lars().fit(df_train[cols], y_train) \n",
        "elif reg_model == \"bayesian_ridge\":\n",
        "    reg = BayesianRidge().fit(df_train[cols], y_train) \n",
        "elif reg_model == \"grad_boost\":\n",
        "    reg = GradientBoostingRegressor(random_state = 0).fit(df_train[cols], y_train) \n",
        "elif reg_model == 'xgb':\n",
        "    reg = XGBRegressor(objective='reg:squarederror').fit(df_train[cols], y_train)\n",
        "elif reg_model == 'lightgbm':\n",
        "    reg = LGBMRegressor().fit(df_train[cols], y_train)\n",
        "elif reg_model == 'catboost':\n",
        "    reg = CatBoostRegressor(verbose=0, n_estimators=100).fit(df_train[cols], y_train)\n",
        "else:\n",
        "    reg = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2)).fit(df_train[cols], y_train)\n",
        "\n",
        "print(\"Training for {}\".format(mode))\n",
        "\n",
        "print(\"xgb-C\")\n",
        "print(reg.score(df_train[cols], y_train))\n",
        "\n",
        "# (1517, 176) (99, 176)\n",
        "# 176\n",
        "# Training for multi\n",
        "# xgb-C\n",
        "# 0.8214368934323697"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1517, 176) (99, 156)\n",
            "176\n",
            "Training for multi\n",
            "xgb-C\n",
            "0.8214368934323697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSQKKfJyO_N5"
      },
      "source": [
        "pred_trial = reg.predict(df_trial[cols])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s0lwMZeO_N8",
        "outputId": "e583bebf-5ecc-495f-b47c-20bea20eaf6a"
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "pearsonr(pred_trial, df2['complexity'])\n",
        "# xgb-C\n",
        "# single word - \n",
        "# MWE - (0.7412020261247637, 1.752898987966046e-18)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7412020261247637, 1.752898987966046e-18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXywHv1mPC2D",
        "outputId": "b389cbbd-e980-4600-a17b-093b76070e8f"
      },
      "source": [
        "print(\"{}: For xgb-C during testing \".format(mode))\n",
        "df_test = rearrange_cols(df_test)\n",
        "pred_test = reg.predict(df_test[cols])\n",
        "print(\"Pearson Corr\")\n",
        "print(pearsonr(pred_test, df3['complexity'])[0])\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"MSE\")\n",
        "print(mean_squared_error(df3['complexity'], pred_test))\n",
        "\n",
        "\n",
        "\n",
        "# multi: For xgb-C during testing \n",
        "# {'feat_0': 'feat_0', 'feat_1': 'feat_1', 'feat_2': 'feat_2', 'feat_3': 'feat_3', 'feat_4': 'feat_4', 'feat_5': 'feat_5', 'feat_6': 'feat_6', 'feat_7': 'feat_7', 'feat_8': 'feat_8', 'feat_9': 'feat_9', 'feat_10': 'feat_10', 'feat_11': 'feat_11', 'feat_12': 'feat_12', 'feat_13': 'feat_13', 'feat_14': 'feat_14', 'feat_15': 'feat_15', 'feat_16': 'feat_16', 'feat_17': 'feat_17', 'feat_18': 'feat_18', 'feat_19': 'feat_19', 'word_len': 'word_len', 'num_syll': 'num_syll', 'word_freq': 'word_freq', 'glove_0': 'glove_0', 'glove_1': 'glove_1', 'glove_2': 'glove_2', 'glove_3': 'glove_3', 'glove_4': 'glove_4', 'glove_5': 'glove_5', 'glove_6': 'glove_6', 'glove_7': 'glove_7', 'glove_8': 'glove_8', 'glove_9': 'glove_9', 'glove_10': 'glove_10', 'glove_11': 'glove_11', 'glove_12': 'glove_12', 'glove_13': 'glove_13', 'glove_14': 'glove_14', 'glove_15': 'glove_15', 'glove_16': 'glove_16', 'glove_17': 'glove_17', 'glove_18': 'glove_18', 'glove_19': 'glove_19', 'glove_20': 'glove_20', 'glove_21': 'glove_21', 'glove_22': 'glove_22', 'glove_23': 'glove_23', 'glove_24': 'glove_24', 'glove_25': 'glove_25', 'glove_26': 'glove_26', 'glove_27': 'glove_27', 'glove_28': 'glove_28', 'glove_29': 'glove_29', 'glove_30': 'glove_30', 'glove_31': 'glove_31', 'glove_32': 'glove_32', 'glove_33': 'glove_33', 'glove_34': 'glove_34', 'glove_35': 'glove_35', 'glove_36': 'glove_36', 'glove_37': 'glove_37', 'glove_38': 'glove_38', 'glove_39': 'glove_39', 'glove_40': 'glove_40', 'glove_41': 'glove_41', 'glove_42': 'glove_42', 'glove_43': 'glove_43', 'glove_44': 'glove_44', 'glove_45': 'glove_45', 'glove_46': 'glove_46', 'glove_47': 'glove_47', 'glove_48': 'glove_48', 'glove_49': 'glove_49', 'glove100_0': 'glove100_0', 'glove100_1': 'glove100_1', 'glove100_2': 'glove100_2', 'glove100_3': 'glove100_3', 'glove100_4': 'glove100_4', 'glove100_5': 'glove100_5', 'glove100_6': 'glove100_6', 'glove100_7': 'glove100_7', 'glove100_8': 'glove100_8', 'glove100_9': 'glove100_9', 'glove100_10': 'glove100_10', 'glove100_11': 'glove100_11', 'glove100_12': 'glove100_12', 'glove100_13': 'glove100_13', 'glove100_14': 'glove100_14', 'glove100_15': 'glove100_15', 'glove100_16': 'glove100_16', 'glove100_17': 'glove100_17', 'glove100_18': 'glove100_18', 'glove100_19': 'glove100_19', 'glove100_20': 'glove100_20', 'glove100_21': 'glove100_21', 'glove100_22': 'glove100_22', 'glove100_23': 'glove100_23', 'glove100_24': 'glove100_24', 'glove100_25': 'glove100_25', 'glove100_26': 'glove100_26', 'glove100_27': 'glove100_27', 'glove100_28': 'glove100_28', 'glove100_29': 'glove100_29', 'glove100_30': 'glove100_30', 'glove100_31': 'glove100_31', 'glove100_32': 'glove100_32', 'glove100_33': 'glove100_33', 'glove100_34': 'glove100_34', 'glove100_35': 'glove100_35', 'glove100_36': 'glove100_36', 'glove100_37': 'glove100_37', 'glove100_38': 'glove100_38', 'glove100_39': 'glove100_39', 'glove100_40': 'glove100_40', 'glove100_41': 'glove100_41', 'glove100_42': 'glove100_42', 'glove100_43': 'glove100_43', 'glove100_44': 'glove100_44', 'glove100_45': 'glove100_45', 'glove100_46': 'glove100_46', 'glove100_47': 'glove100_47', 'glove100_48': 'glove100_48', 'glove100_49': 'glove100_49', 'glove100_50': 'glove100_50', 'glove100_51': 'glove100_51', 'glove100_52': 'glove100_52', 'glove100_53': 'glove100_53', 'glove100_54': 'glove100_54', 'glove100_55': 'glove100_55', 'glove100_56': 'glove100_56', 'glove100_57': 'glove100_57', 'glove100_58': 'glove100_58', 'glove100_59': 'glove100_59', 'glove100_60': 'glove100_60', 'glove100_61': 'glove100_61', 'glove100_62': 'glove100_62', 'glove100_63': 'glove100_63', 'glove100_64': 'glove100_64', 'glove100_65': 'glove100_65', 'glove100_66': 'glove100_66', 'glove100_67': 'glove100_67', 'glove100_68': 'glove100_68', 'glove100_69': 'glove100_69', 'glove100_70': 'glove100_70', 'glove100_71': 'glove100_71', 'glove100_72': 'glove100_72', 'glove100_73': 'glove100_73', 'glove100_74': 'glove100_74', 'glove100_75': 'glove100_75', 'glove100_76': 'glove100_76', 'glove100_77': 'glove100_77', 'glove100_78': 'glove100_78', 'glove100_79': 'glove100_79', 'glove100_80': 'glove100_80', 'glove100_81': 'glove100_81', 'glove100_82': 'glove100_82', 'glove100_83': 'glove100_83', 'glove100_84': 'glove100_84', 'glove100_85': 'glove100_85', 'glove100_86': 'glove100_86', 'glove100_87': 'glove100_87', 'glove100_88': 'glove100_88', 'glove100_89': 'glove100_89', 'glove100_90': 'glove100_90', 'glove100_91': 'glove100_91', 'glove100_92': 'glove100_92', 'glove100_93': 'glove100_93', 'glove100_94': 'glove100_94', 'glove100_95': 'glove100_95', 'glove100_96': 'glove100_96', 'glove100_97': 'glove100_97', 'glove100_98': 'glove100_98', 'glove100_99': 'glove100_99', 'corpus_type_1': 'corpus_type_1', 'corpus_type_2': 'corpus_type_2', 'corpus_type_3': 'corpus_type_3'}\n",
        "# Pearson Corr\n",
        "# 0.8173647722158658\n",
        "# MSE\n",
        "# 0.008160857728090814"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "multi: For xgb-C during testing \n",
            "{'feat_0': 'feat_0', 'feat_1': 'feat_1', 'feat_2': 'feat_2', 'feat_3': 'feat_3', 'feat_4': 'feat_4', 'feat_5': 'feat_5', 'feat_6': 'feat_6', 'feat_7': 'feat_7', 'feat_8': 'feat_8', 'feat_9': 'feat_9', 'feat_10': 'feat_10', 'feat_11': 'feat_11', 'feat_12': 'feat_12', 'feat_13': 'feat_13', 'feat_14': 'feat_14', 'feat_15': 'feat_15', 'feat_16': 'feat_16', 'feat_17': 'feat_17', 'feat_18': 'feat_18', 'feat_19': 'feat_19', 'word_len': 'word_len', 'num_syll': 'num_syll', 'word_freq': 'word_freq', 'glove_0': 'glove_0', 'glove_1': 'glove_1', 'glove_2': 'glove_2', 'glove_3': 'glove_3', 'glove_4': 'glove_4', 'glove_5': 'glove_5', 'glove_6': 'glove_6', 'glove_7': 'glove_7', 'glove_8': 'glove_8', 'glove_9': 'glove_9', 'glove_10': 'glove_10', 'glove_11': 'glove_11', 'glove_12': 'glove_12', 'glove_13': 'glove_13', 'glove_14': 'glove_14', 'glove_15': 'glove_15', 'glove_16': 'glove_16', 'glove_17': 'glove_17', 'glove_18': 'glove_18', 'glove_19': 'glove_19', 'glove_20': 'glove_20', 'glove_21': 'glove_21', 'glove_22': 'glove_22', 'glove_23': 'glove_23', 'glove_24': 'glove_24', 'glove_25': 'glove_25', 'glove_26': 'glove_26', 'glove_27': 'glove_27', 'glove_28': 'glove_28', 'glove_29': 'glove_29', 'glove_30': 'glove_30', 'glove_31': 'glove_31', 'glove_32': 'glove_32', 'glove_33': 'glove_33', 'glove_34': 'glove_34', 'glove_35': 'glove_35', 'glove_36': 'glove_36', 'glove_37': 'glove_37', 'glove_38': 'glove_38', 'glove_39': 'glove_39', 'glove_40': 'glove_40', 'glove_41': 'glove_41', 'glove_42': 'glove_42', 'glove_43': 'glove_43', 'glove_44': 'glove_44', 'glove_45': 'glove_45', 'glove_46': 'glove_46', 'glove_47': 'glove_47', 'glove_48': 'glove_48', 'glove_49': 'glove_49', 'glove100_0': 'glove100_0', 'glove100_1': 'glove100_1', 'glove100_2': 'glove100_2', 'glove100_3': 'glove100_3', 'glove100_4': 'glove100_4', 'glove100_5': 'glove100_5', 'glove100_6': 'glove100_6', 'glove100_7': 'glove100_7', 'glove100_8': 'glove100_8', 'glove100_9': 'glove100_9', 'glove100_10': 'glove100_10', 'glove100_11': 'glove100_11', 'glove100_12': 'glove100_12', 'glove100_13': 'glove100_13', 'glove100_14': 'glove100_14', 'glove100_15': 'glove100_15', 'glove100_16': 'glove100_16', 'glove100_17': 'glove100_17', 'glove100_18': 'glove100_18', 'glove100_19': 'glove100_19', 'glove100_20': 'glove100_20', 'glove100_21': 'glove100_21', 'glove100_22': 'glove100_22', 'glove100_23': 'glove100_23', 'glove100_24': 'glove100_24', 'glove100_25': 'glove100_25', 'glove100_26': 'glove100_26', 'glove100_27': 'glove100_27', 'glove100_28': 'glove100_28', 'glove100_29': 'glove100_29', 'glove100_30': 'glove100_30', 'glove100_31': 'glove100_31', 'glove100_32': 'glove100_32', 'glove100_33': 'glove100_33', 'glove100_34': 'glove100_34', 'glove100_35': 'glove100_35', 'glove100_36': 'glove100_36', 'glove100_37': 'glove100_37', 'glove100_38': 'glove100_38', 'glove100_39': 'glove100_39', 'glove100_40': 'glove100_40', 'glove100_41': 'glove100_41', 'glove100_42': 'glove100_42', 'glove100_43': 'glove100_43', 'glove100_44': 'glove100_44', 'glove100_45': 'glove100_45', 'glove100_46': 'glove100_46', 'glove100_47': 'glove100_47', 'glove100_48': 'glove100_48', 'glove100_49': 'glove100_49', 'glove100_50': 'glove100_50', 'glove100_51': 'glove100_51', 'glove100_52': 'glove100_52', 'glove100_53': 'glove100_53', 'glove100_54': 'glove100_54', 'glove100_55': 'glove100_55', 'glove100_56': 'glove100_56', 'glove100_57': 'glove100_57', 'glove100_58': 'glove100_58', 'glove100_59': 'glove100_59', 'glove100_60': 'glove100_60', 'glove100_61': 'glove100_61', 'glove100_62': 'glove100_62', 'glove100_63': 'glove100_63', 'glove100_64': 'glove100_64', 'glove100_65': 'glove100_65', 'glove100_66': 'glove100_66', 'glove100_67': 'glove100_67', 'glove100_68': 'glove100_68', 'glove100_69': 'glove100_69', 'glove100_70': 'glove100_70', 'glove100_71': 'glove100_71', 'glove100_72': 'glove100_72', 'glove100_73': 'glove100_73', 'glove100_74': 'glove100_74', 'glove100_75': 'glove100_75', 'glove100_76': 'glove100_76', 'glove100_77': 'glove100_77', 'glove100_78': 'glove100_78', 'glove100_79': 'glove100_79', 'glove100_80': 'glove100_80', 'glove100_81': 'glove100_81', 'glove100_82': 'glove100_82', 'glove100_83': 'glove100_83', 'glove100_84': 'glove100_84', 'glove100_85': 'glove100_85', 'glove100_86': 'glove100_86', 'glove100_87': 'glove100_87', 'glove100_88': 'glove100_88', 'glove100_89': 'glove100_89', 'glove100_90': 'glove100_90', 'glove100_91': 'glove100_91', 'glove100_92': 'glove100_92', 'glove100_93': 'glove100_93', 'glove100_94': 'glove100_94', 'glove100_95': 'glove100_95', 'glove100_96': 'glove100_96', 'glove100_97': 'glove100_97', 'glove100_98': 'glove100_98', 'glove100_99': 'glove100_99', 'corpus_type_1': 'corpus_type_1', 'corpus_type_2': 'corpus_type_2', 'corpus_type_3': 'corpus_type_3'}\n",
            "Pearson Corr\n",
            "0.8173647722158658\n",
            "MSE\n",
            "0.008160857728090814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTXir0u5Pbib"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}